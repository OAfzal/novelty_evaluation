[
  {
    "id": 67,
    "paper_id": "gRmWtOnTLK",
    "reference_text": "This paper considers a method for reconstructing the waveform from Mel-spectrogram or discrete acoustic tokens by generating complex spectrograms and performing reconstruction on a frame level, achieving audio generation much faster than in real time. The paper's novelty is in question, as it mainly combines existing components (multiband rectified flow and ConvNeXt V2) rather than proposing a fundamentally new approach. While this engineering solution may have merit in specific applications, the lack of novel contributions limits the paper's impact. Strengthening the theoretical foundation or providing a unique methodological contribution would be beneficial in highlighting the algorithm’s distinct value.",
    "candidate_a_text": "RFWave is an integrative approach that combines rectified flow, multi-band processing, and frame-level modeling for efficient and high-fidelity audio waveform reconstruction from Mel-spectrograms. While this specific combination is new for the task, each individual component—rectified flow (VoiceFlow), multi-band processing (Multi-Band Diffusion), and frame-level modeling (APNet2/Vocos)—has been explored in prior work. The authors' claims of being \"first\" in several aspects are somewhat overstated, as relevant works (notably VoiceFlow and PeRFlow) are omitted from citations, which may misrepresent the maturity of rectified flow in audio. The main technical contributions, such as a new sampling time point selection and overlap loss, appear to be incremental enhancements rather than conceptual breakthroughs. Overall, RFWave should be viewed as a strong compositional advance that synthesizes recent trends, and reviewers are encouraged to request direct comparisons to omitted related works for a more complete assessment of novelty.",
    "candidate_b_text": "This paper presents RFWave, a novel approach for audio waveform reconstruction using a multi-band Rectified Flow model. The integration of Rectified Flow and the use of STFT frames for parallel processing significantly improve the sampling speed, making RFWave highly efficient compared to existing diffusion-based methods. The paper includes extensive experiments comparing RFWave with existing diffusion and GAN-based models, demonstrating its superior performance in terms of quality and computational efficiency.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 2,
      "candidate_a_system": "ours",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 2,
        "consensus_score": 0.5,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          3,
          4
        ],
        "agreement_matrix": {
          "2": {
            "2": true,
            "3": true,
            "4": false
          },
          "3": {
            "2": true,
            "3": true,
            "4": false
          },
          "4": {
            "2": false,
            "3": false,
            "4": true
          }
        },
        "agreement_scores": {
          "2": 0.5,
          "3": 0.5,
          "4": 0.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 46
  },
  {
    "id": 63,
    "paper_id": "lpt4ADbacU",
    "reference_text": "This paper presents a two-step framework for multi-objective optimization (MOO) that incorporates user-defined soft and hard bounds on objectives and generates a compact set of Pareto optimal solutions for human decision makers to review. This approach creatively incorporates the concepts of hard constraints and soft preferences into Bayesian optimization formulation, providing a more nuanced way to express decision-maker preferences. The two-step framework is more user friendly, as through sparcification of the originally found Pareto optimal solutions, it is easier for human decision makers to pick the solutions to their preferences, which suggests fair practical usage. However, the algorithmic novelty is fairly limited: for the dense sampling procedure, the primary modification is the incorporation of soft-hard functions (SHFs) into the acquisition function, while the rest largely follows existing techniques from Paria et al. (2019). The sparcification procedure follows standard active learning approach. While the problem formulation is novel and interesting, I do not think there is enough methodological innovation to meet the high standard of ICLR. MoSH addresses a practical challenge in MOO by providing a way to generate a small but diverse set of solutions that respect user defined constraints, which has great potential impact to MOO applications.",
    "candidate_a_text": "This assessment reviews \"MOSH: Modeling Multi-Objective Tradeoffs with Soft and Hard Bounds,\" which introduces Soft-Hard Functions (SHFs) for explicit modeling of both soft and hard bounds in multi-objective Bayesian optimization (MOO-BO), aiming to better capture practitioner preferences. The submission integrates SHF-based utility modeling with a two-step process: dense Pareto sampling via Bayesian optimization, followed by robust submodular set selection for compact, actionable solution sets. While the explicit SHF framework is a substantive and interpretable extension over prior preference modeling approaches, the overall methodology—combining preference-based MOO, robust optimization, and submodular selection—largely builds on established techniques, with novelty primarily in their integration and the form of utility modeling. The empirical results demonstrate improved utility and compactness, though these gains may partly reflect alignment between the proposed metric and method. The assessment notes that claims of conceptual novelty are somewhat overstated, as related work on flexible preference modeling and robust set selection is not fully acknowledged, and the main contribution is a clear, practical synthesis rather than a fundamentally new paradigm.",
    "candidate_b_text": "This paper presents an interesting problem of multi-objective optimization considering soft and hard lower bounds. Perhaps the more interesting thing is the max-min framework to achieve robustness against user preference weights is novel, which might provide a new perspective of enhancing diversity in Pareto frontier search. The practical approximation using a two-step process and leveraging submodular optimization techniques is sound, as it offers a feasible solution to an otherwise intractable problem.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "Human Review 1",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 1,
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 0.5,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          1,
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": false,
            "3": true
          },
          "1": {
            "0": false,
            "1": true,
            "3": false
          },
          "3": {
            "0": true,
            "1": false,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 0.5,
          "1": 0.0,
          "3": 0.5
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 1
  },
  {
    "id": 87,
    "paper_id": "waIltEWDr8",
    "reference_text": "This paper proposes to combine B-cos networks as feature extractor and a relatively common version of few-shot learning. Masking limitations in novelty: lets be clear: The Nadaraya-Watson head is (a simplified version of) few-shot learning. It is a softmax over negative distances between support samples and the test image. While it is appreciated that Wang and Sabuncu, 2022, gave a name to their analysis in order to emphasize a predecessor of few-shot learning, using this term in this paper suggests a larger or different novelty than there actually is. It should be made prominently clear in the manuscript that the Nadaraya-Watson head is effectively few-shot learning (seemingly without sampling random subsets of classes). The evidence head is a standard few shot head. Taking the positive part is a ReLU applied on a feature map. Again, that is renaming common parts to sound uncommon / novel. Masking limitations in novelty in such a way is disliked by the reviewer. This results in a low score for presentation. By that one cannot distinguish whether the contributions are actually mostly from the B-cos network or whether the few-shot head plays any role in (a) predictive performance or (b) attribution map quality. In the worst case the B-cos network alone does all the heavy lifting.",
    "candidate_a_text": "This paper proposes a novel method that combines two existing methods—Nadaraya-Watson head for global explanations and B-cos networks for faithful local explanations—to provide both global and local explanations for neural network-based classification models. However, the novelty of the paper is limited, as the proposed method is simply a combination of two existing methods. The paper does not compare the proposed method with other explanation methods, which makes it difficult to evaluate its effectiveness against prior work.",
    "candidate_b_text": "This paper presents WASUP, an inherently interpretable neural network for image classification that combines a B-cos network with a classification head learning support vectors, classifying images based on similarity in the latent space. The proposed method could be seen as an extension of the B-cos network; however, the paper is not novel. The support vectors are, in essence, prototypes as in a ProtoPNet, and the comparison between an input image's latent representations and support vectors is also similar to the comparison between latent representations and prototypes in a ProtoPNet. The proposed method is simply a combination of a B-cos network and a ProtoPNet. Since the main ideas behind the paper are mostly explored in prior work and there is no novelty, the paper lacks significance.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "Human Review 3",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 2,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 3,
      "consensus_info": {
        "consensus_review": 2,
        "consensus_score": 1.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          3,
          4
        ],
        "agreement_matrix": {
          "2": {
            "2": true,
            "3": true,
            "4": true
          },
          "3": {
            "2": true,
            "3": true,
            "4": true
          },
          "4": {
            "2": true,
            "3": true,
            "4": true
          }
        },
        "agreement_scores": {
          "2": 1.0,
          "3": 1.0,
          "4": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 4
  },
  {
    "id": 14,
    "paper_id": "uuvujfQXZy",
    "reference_text": "This paper proposed a novel type of CBM called UCBM, which utilizes concept discovery methods to discover concepts learnt by pretrained, black-box models and convert them into CBM. The paper proposed an unsupervised concept discovery mechanism for CBMs, which is novel in the field of CBM, as the method does not need pre-defined concept sets. Additionally, a novel input-dependent concept selection mechanism is proposed to dynamically retain a sparse set for prediction; however, the idea of input-dependent concept selection is not novel, as, for example, Panousis et al. (2023) introduced a binary latent indicator to dynamically select activating concepts according to input embedding and mask out other concepts. I agree that the introduction of unsupervised concept discovery into CBM is interesting, but the missing of text representation limits the novelty.",
    "candidate_a_text": "This paper presents a novel approach to converting a black-box model into a concept bottleneck model (CBM) using unsupervised concept discovery, and proposes an input-dependent concept selection mechanism where only a sparse set of concepts relevant to the input are dynamically retained. The idea of using concept discovery for CBM is interesting and novel. However, the paper does not provide comparisons with other concept discovery methods such as [1], other methods that convert a black-box model into a CBM such as [2,3], or with CBMs trained from scratch, which limits the ability to fully assess the originality and significance of the contribution.",
    "candidate_b_text": "This paper proposes learning post-hoc Concept Bottleneck Models (CBMs) in an unsupervised manner, using an unsupervised non-negative matrix factorization to discover concept vectors, an input-dependent alignment score selection, and a sparse linear layer for class prediction. Unlike previous methods, UCBMs do not assume a set of concepts learned by black-box models, but instead discover the concept vectors in an unsupervised manner. The idea of input-dependent sparsity constraint is interesting and non-trivial. However, the proposed method has limited novelty, as it uses an existing matrix decomposition method called CRAFT for feature generation, and the novelty is limited to proposing input-dependent selection applied before learning the sparse linear layer. The paper lacks comparisons with newer methods, particularly with [2], which trains a learnable dictionary to approximate the embedding space of VLMs in a supervised manner without using a pre-defined concept set.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "Human Review 1",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 1,
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 1.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          1,
          2
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": true,
            "2": true
          },
          "1": {
            "0": true,
            "1": true,
            "2": true
          },
          "2": {
            "0": true,
            "1": true,
            "2": true
          }
        },
        "agreement_scores": {
          "0": 1.0,
          "1": 1.0,
          "2": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 3
  },
  {
    "id": 54,
    "paper_id": "6akuzEqP38",
    "reference_text": "This paper proposes a novel pipeline that enables the creation of articulated objects from arbitrary input mesh, addressing a critical research gap in 3D generation for articulated objects and contributing to an increasingly important area. The main contribution is this pipeline that enables the generation of diverse articulated objects by taking arbitrary 3D mesh as input.",
    "candidate_a_text": "The submission \"ARTICULATE ANYTHING\" presents a novel pipeline that integrates open-vocabulary segmentation, LLM-based articulation estimation, and diffusion-based generative refinement to convert any rigid 3D mesh into an articulated object, distinguishing itself from prior works that address only subsets of this problem or are limited to closed-set categories. The main technical advances include the use of GPT-4o for direct joint parameter estimation from geometry and language, and a diffusion-based optimization strategy with random part transformations to preserve part semantics. While the integration of these components into a single, open-vocabulary, category-agnostic pipeline is a substantive contribution, the individual elements (segmentation, LLM reasoning, diffusion generation) are incremental extensions of existing methods, and some claims regarding the limitations of prior work are somewhat overstated. The authors' characterization of their novelty is generally accurate for the full pipeline, but less so for individual components, and the omission of some recent related works (e.g., OpenObj, Kinematic-aware Prompting) leaves the comparison incomplete. Overall, the work represents a significant step forward in open-vocabulary articulated object modeling, though its impact is primarily in the integration and scaling of recent advances rather than in fundamental algorithmic breakthroughs.",
    "candidate_b_text": "This paper introduces an interesting method called \"Articulated Anything\" to address the problem of articulated object generation. While the method is reasonable, it essentially relies on the power of various large models and diffusion models, which may limit the novelty of the proposed framework. The performance of the proposed method is not particularly impressive, and it is difficult to observe a significant improvement compared to existing methods, such as CAGE.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "Human Review 2",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 2,
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 0.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          2
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "2": false
          },
          "2": {
            "0": false,
            "2": true
          }
        },
        "agreement_scores": {
          "0": 0.0,
          "2": 0.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 7
  },
  {
    "id": 20,
    "paper_id": "dTGH9vUVdf",
    "reference_text": "The paper introduces FreeVS, an approach to view synthesis for driving scenes that overcomes limitations of existing methods, which primarily focus on synthesizing camera views along pre-recorded vehicle trajectories. The authors proposed a \"psuedo LiDAR controlnet\" for SVD, which is easy yet effective. The benchmark of novel trajectory synthesis looks interesting to me, and the authors proposed two benchmarks for evaluating novel camera synthesis and novel trajectory synthesis. While the baseline methods are not specifically designed for the similar purpose of the paper, there are works that use virtual warping for improving the novel view quality such as [1] [2], that might be better for the baselines. This reminds me of the existing novel trajectory synthesis benchmark [3], and the authors should test their methods on such a dataset and demonstrate the absolute performance gain using the metrics of PSNR, SSIM, etc. I personally like the idea of the paper, but I still have many concerns and would provide a final rating based on the authors' responses.",
    "candidate_a_text": "FREEVS is a generative novel view synthesis (NVS) method for driving scenes that introduces a pseudo-image representation to enable pose control and 3D consistency, evaluated on challenging out-of-trajectory benchmarks with geometry consistency assessed via 3D detectors. While the pseudo-image approach is a novel technical variant, the overall paradigm—generative, pose-controllable NVS for driving scenes—has been addressed by recent works such as MagicDrive3D, WoVoGen, and MapNeRF, making the claim of being \"first\" overstated. The authors’ characterizations of prior work sometimes exaggerate their limitations, particularly regarding out-of-trajectory synthesis and pose control precision, and omit some relevant recent methods. The main technical delta lies in the specific representation and training pipeline, while the use of new benchmarks and geometry consistency metrics represents an incremental rather than fundamental advance. Reviewers should note that FREEVS’s contributions are best understood as a novel variant within a rapidly evolving field, rather than a wholly new paradigm.",
    "candidate_b_text": "This paper presents FreeVS, a Video Stable Diffusion-based generative view synthesis method for driving scenes that synthesizes high-quality camera views both on and beyond recorded trajectories. The key innovation is the clever use of pseudo-images obtained through colored point cloud projection as a unified representation for all view priors, which simplifies the learning objective for the generative model. As opposed to recent contenders that rely on gaussian splatting or nerfs to represent the scene, the authors train a diffusion model on colored LiDAR point clouds. While the method introduces two new challenging benchmarks and outperforms previous approaches, the novelty is somewhat limited as the contribution boils down to an addon for Video Stable Diffusion that has colored LiDAR point features concatenated. The method trades the gaussian and nerf artifacts with diffusion ones, and while FreeVS works better than previous attempts from novel views, for single front view, splatting still yields significantly better results.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "Human Review 4",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "ours",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 4,
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 0.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          3,
          4
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "3": false,
            "4": false
          },
          "3": {
            "1": false,
            "3": true,
            "4": false
          },
          "4": {
            "1": false,
            "3": false,
            "4": true
          }
        },
        "agreement_scores": {
          "1": 0.0,
          "3": 0.0,
          "4": 0.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 12
  },
  {
    "id": 37,
    "paper_id": "rWIrdAo2xC",
    "reference_text": "This paper proposes to train a conditional diffusion model for generating novel views of humans from given single-view images, directly supervised by proxy ground truth 3D Gaussian attributes. The method outperforms other generalizable novel view synthesis techniques like LGM, and the idea of using a neural network to constrain the distribution of target 3D Gaussian attributes makes sense and is effective. However, although the method demonstrates improvement compared to previous methods like LGM, the image quality remains limited since only one single input image is used, and another potential direction in this field is incorporating a 2D diffusion prior to enhance information, as demonstrated in Human 3Diffusion. A comparison to these baselines is needed.",
    "candidate_a_text": "This submission introduces a novel direct attribute-level supervision paradigm for 3D Gaussian Splatting (3DGS) in generalizable monocular 3D human rendering, diverging from the prevalent pixel-level (indirect) supervision used in prior works. The approach leverages a two-stage proxy attribute construction and a conditional diffusion model to directly supervise 3DGS attributes, which is a substantive technical difference from existing methods like GPS-Gaussian, Zou et al., LGM, and FreeSplat. While the use of diffusion models for 3D attribute generation is not new, its application to 3DGS attributes in this context is novel, though the underlying methodology follows established trends in the field. The authors’ claims of inefficiency and suboptimality in prior pixel-level supervision are sometimes overstated and not always empirically substantiated, and some relevant recent works are not cited or compared. Overall, the main contribution is the new supervision strategy for 3DGS, but the practical impact should be carefully evaluated with empirical results and broader comparisons to recent literature.",
    "candidate_b_text": "This paper proposes a novel method for generating novel views of humans from single-view images by leveraging 3D Gaussian Splatting. The authors propose a two-stage process to create consistent and smoothly distributed proxy ground-truth 3D Gaussian attributes, which is a novel approach to address the challenges of precise error backpropagation and local optima convergence in existing methods. The method, named HUMAN-DAD, demonstrates significant performance improvements over state-of-the-art methods through extensive experiments.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "ours",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 0.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          4
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "4": false
          },
          "4": {
            "1": false,
            "4": true
          }
        },
        "agreement_scores": {
          "1": 0.0,
          "4": 0.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 21
  },
  {
    "id": 23,
    "paper_id": "pdzHpQbGrn",
    "reference_text": "This paper studies the active test-time prompt tuning for the vision-language model and proposes a novel test-time prompt tuning method, outperforming existing test-time prompt tuning methods. The integration of active learning with test-time prompt tuning presents a novel approach. However, previous studies have explored the benefits of employing active learning for test-time adaptation, and the novelty of this paper is marginal. The active test-time adaptation, test-time prompt tuning, and data buffer are not novel and have been proposed by existing studies [1-3]. Although some studies have been discussed in this paper, the major technical improvement of this paper has not been highlighted.",
    "candidate_a_text": "This paper proposes a novel method that combines active learning and prompt tuning for test-time optimization of VLMs. The method incorporates a dynamically adjusted threshold and a class-balanced replacement policy to improve the selection of samples for active labeling. The paper provides a fair evaluation protocol for the proposed method and compares it with existing methods on multiple datasets.",
    "candidate_b_text": "This assessment finds that the submission \"Active Test Time Prompt Learning in Vision-Language Models\" (ATPL) is positioned at the intersection of test-time prompt adaptation, active learning, and distribution alignment for VLMs, and is the first to integrate active querying and class balancing at test time in a streaming, single-sample setting. The authors’ characterizations of prior work are generally accurate, though some recent related works (e.g., C-TPT, DPCore, VPTTA) are omitted, which may understate the field’s maturity. The main technical contributions—dynamic thresholding for label querying, class-aware alignment, and buffer management—are logical extensions of existing methods, with the primary novelty being their integration in this specific test-time context. While the \"first\" claim is accurate in a narrow sense, the conceptual advances are incremental, reflecting a broader trend in the field toward parameter- and label-efficient adaptation. Reviewers should recognize the submission as a well-motivated and carefully executed integration of established techniques, with its main value in the adaptation and combination of known ideas rather than in introducing fundamentally new concepts.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 1.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          2,
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "2": true,
            "3": true
          },
          "2": {
            "0": true,
            "2": true,
            "3": true
          },
          "3": {
            "0": true,
            "2": true,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 1.0,
          "2": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 7
  },
  {
    "id": 70,
    "paper_id": "7hM5597bCv",
    "reference_text": "This paper suggests improving IQL to train a value function using OOD but constrained actions, by instead using a skill prior learned by diffusion, and further proposes adaptive re-evaluation, which re-plans the trajectory if the future value function becomes worse than the current value function. However, it seems that DIAR is an incremental improvement of LDCQ, which changed the base offline algorithm from BCQ to IQL, and specifically, DIAR uses the same procedure of LDCQ for getting the latent priors, using $\\beta$-VAE for latent representation and getting the latent priors via diffusion. DAIR seems to be the IQL version of LDCQ plus Adaptive re-evaluation, and I would appreciate clarification on the differences between LDCQ and DIAR.",
    "candidate_a_text": "DIAR is positioned as an incremental extension of recent diffusion model-based offline RL methods, particularly LDCQ and IDQL, by integrating diffusion-based trajectory modeling with implicit Q-learning and introducing an adaptive revaluation mechanism for dynamic decision length adjustment. The main technical novelty lies in this adaptive revaluation, which allows the policy to adjust decision horizons dynamically—a feature not present in the most closely related prior work, though conceptually related to adaptive horizon methods in RL. Other aspects, such as alternating training between real and generated samples and the integration of diffusion models with IQL, are routine adaptations already explored in the literature, making these contributions less distinctive. The authors’ claims of consistent state-of-the-art performance and strong differentiation from prior work are not fully substantiated in the provided excerpt, and some rhetorical distinctions (e.g., “assisting” vs. “guiding” Q-learning) are not technically meaningful. Overall, while DIAR offers a modest technical advance with its adaptive revaluation mechanism, its other contributions are incremental, and a more thorough comparison to recent diffusion-based RL methods would be necessary to fully establish its impact.",
    "candidate_b_text": "This paper introduces Diffusion-model-guided Implicit Q-learning with Adaptive Revaluation (DIAR), an offline reinforcement learning approach that integrates a diffusion model to generate diverse latent trajectories, an Adaptive Revaluation mechanism for adjusting decision lengths, and a Q-network learning approach with value function guidance from the diffusion model. The idea of using diffusion models to generate diverse latent trajectories for offline RL is interesting. However, the proposed method is not novel. The idea of using diffusion models to generate diverse latent trajectories for offline RL has already been explored in the literature, and the proposed method seems to be a combination of existing techniques. The authors claim that the existing diffusion-based offline RL methods do not avoid the Q-function, which is not true; for example, the Diffuser learns a policy without any Q-function. The authors should clearly state their novelty and contributions compared to these existing methods.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "3": true
          },
          "3": {
            "0": true,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 36
  },
  {
    "id": 4,
    "paper_id": "yYQLvofQ1k",
    "reference_text": "The paper introduces VIRSCI, a multi-agent, LLM-based system designed to simulate teamwork-driven scientific research, organizing agents to mimic collaborative processes such as selecting collaborators, generating research ideas, assessing novelty, and drafting abstracts. The multi-agent approach proposed in this paper has the potential to greatly enhance the quality and breadth of scientific research, with discussion-oriented idea generation that closely mirrors real scientific processes. The 5-step approach—comprising Collaborator Selection, Topic Selection, Idea Generation, Idea Novelty Assessment, and Abstract Generation—presents a promising and robust framework for idea generation. VIRSCI, as a multi-agent system for scientific collaboration, shows clear advantages over single-agent methods. While VIRSCI may generate highly unique or novel ideas, these are less valuable if experimental designs cannot support them within practical constraints.",
    "candidate_a_text": "The paper presents a novel approach to scientific idea generation using a multi-agent system, addressing the collaborative nature of scientific research. VIRSCI consists of a team of agents that collaborate to generate, evaluate, and refine research ideas, and is evaluated using real-world data with improved performance over single-agent systems. The findings suggest that multi-agent collaboration can enhance the novelty and impact of generated scientific ideas. The use of real-world data and the comparison with single-agent systems demonstrate the practical relevance and effectiveness of the proposed approach.",
    "candidate_b_text": "This paper proposes a new multi-agent system VIRSCI, designed to mimic the teamwork inherent in scientific research, and constructs the entire pipeline from team organization to final idea formation. This paper is the first to apply the LLM-based multi-agent system to the problem of scientific discovery, realizing the generation of research ideas in autonomous scientific discovery. The contributions are mainly in pioneering the use of multi-agent technology in a completely new field and demonstrating that integrating collaborative agents can lead to more innovative scientific outputs. The simulation results are consistent with key findings in Science of Science, such as that new teams tend to produce more innovative research, demonstrating VIRSCI's potential as a powerful tool for future research in this field. This is the first attempt to apply the LLM-based multi-agent system to the field of scientific exploration, which allows us to see greater possibilities of AI for science and shows that in the future, multi-agent technology may really be able to make new and valuable scientific discoveries.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "Human Review 3",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 2,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 3,
      "consensus_info": {
        "consensus_review": 2,
        "consensus_score": 0.6666666666666666,
        "num_reviews": 4,
        "consensus_type": "majority",
        "other_reviews": [
          0,
          1,
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": false,
            "2": false,
            "3": false
          },
          "1": {
            "0": false,
            "1": true,
            "2": true,
            "3": false
          },
          "2": {
            "0": false,
            "1": true,
            "2": true,
            "3": true
          },
          "3": {
            "0": false,
            "1": false,
            "2": true,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 0.0,
          "1": 0.3333333333333333,
          "2": 0.6666666666666666,
          "3": 0.3333333333333333
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 47
  },
  {
    "id": 8,
    "paper_id": "a8mKwRQQrP",
    "reference_text": "The paper introduces the GAPSI algorithm, which combines online learning techniques with inventory control theory to address complex inventory management problems. The introduction of the GAPSI algorithm represents a significant advancement in applying online learning techniques to realistic inventory management problems. This work notably contributes to practical aspects, especially in dealing with multiple products, perishability, and warehouse capacity constraints. The focus on the challenges posed by non-differentiability and the proposed solutions demonstrate a deep understanding of the complexities involved in inventory optimization. This algorithm is adapted from GAPS (Lin et al., 2024) to take into account specific aspects of inventory problems, in particular, the fact that the functions we are dealing with are not differentiable.",
    "candidate_a_text": "This paper proposes an algorithm called GAPSI to solve online inventory problems. The contribution of this paper appears limited, as the proposed algorithm primarily adapts GAPS to inventory problems. Additionally, the approach to computing the gradient $\\nabla L_t (\\theta_t)$ has been extensively studied in the field of inventory management.",
    "candidate_b_text": "This paper presents GAPSI, an algorithm that integrates the GAPS method from [1] for inventory control problems, and explains how common industry constraints such as perishability, lead times, and warehouse capacity can be mathematically modeled within the GAPS framework. However, after meticulously reading this article, I feel that the biggest issue is that it merely provides a detailed implementation guide and an empirical simulation evaluation of how the GAPS in article [1] can be applied to real inventory replenishment management. This article is primarily inclined towards empirical evaluation and presenting some implementation details regarding how the GAPS framework in article [1] can be applied to real inventory replenishment management, and I feel that this article is more like a heuristic guidance manual for inventory management that could be posted on arXiv or SSRN. My concern is that this article resembles a case study, lacking comprehensive theoretical proof and large-scale real-world practice.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "Human Review 1",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 1,
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 0.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          1
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": false
          },
          "1": {
            "0": false,
            "1": true
          }
        },
        "agreement_scores": {
          "0": 0.0,
          "1": 0.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 39
  },
  {
    "id": 48,
    "paper_id": "7X65yoKl3Y",
    "reference_text": "This paper introduces ALLoRA, a novel low-rank adaptation algorithm designed to address issues in existing LoRA approaches, specifically targeting dropout, poor optimization landscapes, and the need for scaling factors. By scaling per-sample and per-parameter gradients with a coefficient inversely proportional to the parameters' $l_2$ norm, ALLoRA aims to eliminate the need for dropout and scaling hyperparameters, and incorporates an adaptive learning rate. While the proposed method is technically precise and offers practical simplifications, the novelty of the contribution is quite marginal. Although ALLoRA represents a new variant of LoRA, the work lacks in-depth theoretical analysis to substantiate its improvements over existing methods. The paper would benefit from a more comprehensive technical discussion clarifying how ALLoRA advances beyond vanilla LoRA and related approaches, as the current presentation does not convincingly establish a significant leap in novelty.",
    "candidate_a_text": "This paper proposes ALLoRA, a variant of the popular LoRA technique for fine-tuning pre-trained language models. The contribution lies in modifying LoRA by removing dropout, individually scaling the learning rate of the LoRA parameters, and eliminating the first warmup step, with the aim of addressing limitations in LoRA's existing design choices. While the paper presents simple yet effective modifications that are well-motivated and supported by experimental results, the novelty of ALLoRA is primarily in these incremental implementation changes to the established LoRA approach. The review does not explicitly compare ALLoRA to closely related prior work beyond the original LoRA method, nor does it assess the distinctiveness of these modifications in the context of broader literature. Overall, the perceived contribution is incremental, with the main advance being practical adjustments rather than a fundamentally new technique. The review suggests that the impact of the learning rate scaling on the optimization process is not fully justified or analyzed, which limits the clarity regarding the significance of the contribution.",
    "candidate_b_text": "ALLoRA is presented as a practical extension of LoRA for parameter-efficient fine-tuning of LLMs, combining Dropout/scaling removal and per-parameter adaptive learning rates to address known LoRA limitations. While the method’s main novelty lies in this specific combination, each component—adaptive learning rates, hyperparameter simplification, and improved initialization—has clear precedent in prior work (notably LoRA+, DoRA, and AdaLomo, the latter not cited). The submission accurately situates ALLoRA within the LoRA variant landscape but omits direct engagement with some highly relevant recent methods, which weakens its novelty claims. Empirical improvements are reported, but without ablation or direct comparison to all relevant baselines, it is unclear if gains stem from the proposed method or implementation choices. Overall, ALLoRA represents an incremental advance through integration of existing ideas, and reviewers should weigh whether this synthesis constitutes a substantive contribution in the context of a mature and rapidly evolving field.",
    "candidate_a_label": "AI System: deepreviewer_partial",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "deepreviewer_partial",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {}
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 5
  },
  {
    "id": 65,
    "paper_id": "29sul3tAEa",
    "reference_text": "The paper addresses the problem of catastrophic forgetting in continual learning and introduces a pre-trained model-based continual learning framework, HyperAdapter, which utilizes a hypernetwork to generate adapters based on the current input, adapting the pre-trained model to the corresponding task. A key to the method is that HyperAdapter uses representative features from pre-trained models, eliminating the necessity to know the task identities during inference or the dependence on any rehearsal buffers. There is currently a lot of interest in avoiding catastrophic forgetting in the continual learning setting, and the authors have summarised and categorised the main approaches. However, the paper discusses the main approaches at a high level and fails to clearly describe the key novelty of the proposed approach. Additionally, the comparison of the proposed method with how people learn is repeated in a number of places, but the points around this are well known and widely documented. Removing the replication provides space to describe the novelty in more detail and room to discuss the implications of the results.",
    "candidate_a_text": "The paper proposes HyperAdapter, a novel pre-trained model-based continual learning framework that uses a hypernetwork to generate adapters based on input, adapting a pre-trained model to specific tasks without a rehearsal buffer. The idea of using hypernetworks to generate adapters for continual learning is interesting. HyperAdapter outperforms existing methods and even exceeds multi-task learning upper bounds, setting a new state-of-the-art for pre-trained model-based continual learning.",
    "candidate_b_text": "This paper introduces HyperAdapter, which leverages hypernetworks to generate task-specific adapters for pre-trained models, addressing data privacy concerns and enabling effective knowledge transfer while requiring fewer additional parameters as the number of tasks increases. However, the core idea of using hypernetworks to generate model parameters for continual learning has already been extensively explored in the literature [1-6], and this paper merely applies these existing methods in the context of prompting-based continual learning with pre-trained models, which significantly limits its novelty and contribution. Several of the innovative designs introduced, such as block-wise hyper-adapters, bear strong similarities in motivation and methodology to chunk embeddings and network partitioning discussed in [1], further constraining the novelty of the work. Additionally, one of the claimed main advantages—eliminating the necessity of knowing the task identities during inference—was previously addressed in [1] under the concept of unknown task identity inference, and the query-key matching mechanism used to address this issue is a well-established practice [7-9].",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "Human Review 3",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 3,
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 0.5,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          3,
          4
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "3": true,
            "4": false
          },
          "3": {
            "1": true,
            "3": true,
            "4": false
          },
          "4": {
            "1": false,
            "3": false,
            "4": true
          }
        },
        "agreement_scores": {
          "1": 0.5,
          "3": 0.5,
          "4": 0.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 12
  },
  {
    "id": 99,
    "paper_id": "F0GNv13ojF",
    "reference_text": "This paper investigates how to effectively leverage reward models during reinforcement learning (RL) training to enhance large language models' (LLMs) mathematical reasoning abilities. The authors identify key limitations in both Outcome-supervised and Process-supervised Reward Models, notably revealing that the latter can lead to reward hacking through unnecessary repetition of steps. To address these issues, the paper introduces two techniques—Clipping and Delta mechanisms—designed to prevent reward exploitation while preserving the benefits of process rewards, and demonstrates their effectiveness across multiple LLMs and benchmarks. While the identification of reward hacking in process-supervised settings and the systematic analysis of reward model limitations represent valuable contributions, the novelty of the proposed solutions is limited. Clipping is a well-established technique in the RL community, commonly used to stabilize training, and the concept of bounded rewards is a fundamental principle in RL. Similarly, the Delta mechanism, though presented as novel, essentially implements reward shaping, which is another well-known concept in the field, as discussed in prior work such as Ng et al. (Policy Invariance Under Reward Transformations), Harutyunyan et al. (Hindsight credit assignment), and Arjona et al. (Rudder). Overall, the paper's contribution is more incremental than innovative, primarily applying established RL techniques to the specific context of LLM reasoning. The main finding—that reward models can be exploited during training—is somewhat expected given the general challenges of reward design in RL. The paper would benefit from more clearly articulating how the proposed mechanisms differ from existing approaches to better establish their novelty.",
    "candidate_a_text": "This paper investigates the effectiveness of using reward models in the RL training of LLMs for reasoning tasks and proposes two novel reward refinement techniques, Clipping and Delta, which significantly improve the performance of RL training. The proposed Clipping and Delta mechanisms are well-motivated and effective in addressing the identified challenges, with experiments demonstrating their effectiveness in improving the performance of LLMs on reasoning tasks. However, the paper does not compare the proposed methods with other state-of-the-art approaches for improving LLM reasoning, such as those based on preference optimization or other RL algorithms, and the generalizability of the findings beyond the GSM8K and MATH benchmarks is unclear.",
    "candidate_b_text": "This submission systematically analyzes the use of process-supervised reward models (PRM/ORM) as RL rewards for LLM mathematical reasoning, focusing on training-time dynamics and identifying issues such as \"training collapse\" due to reward misspecification. The authors introduce two reward refinement techniques—Clip (a standard reward clipping adaptation) and Delta (a more novel, stepwise improvement-based reward)—to mitigate these issues, and empirically validate their effectiveness on standard math benchmarks. While the empirical focus on training-time failure modes and the Delta mechanism represent incremental advances, many of the techniques (especially Clip) are routine adaptations of established RL methods, and the claim of \"first in-depth evaluation\" is somewhat overstated given related prior work. The submission's main contribution is a detailed empirical study and practical demonstration of reward refinement, rather than fundamentally new concepts or algorithms. Overall, the work is a valuable but incremental addition to a rapidly evolving field, and its novelty should be interpreted in the context of extensive existing research on reward model robustness, reward hacking, and normalization.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {}
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 13
  },
  {
    "id": 30,
    "paper_id": "QFaj7InstQ",
    "reference_text": "This paper introduces the Item Language Model (ILM), a framework designed to bridge behavioral embeddings from recommendation systems with language understanding in Large Language Models (LLMs). The core contribution lies in adapting a Querying Transformer (QFormer) architecture with a novel item-item contrastive loss, enabling unified and interleaved processing of both behavioral and textual information for language generation tasks. The approach demonstrates innovation in its use of QFormer with item-item contrastive learning to address the modality gap between recommendation signals and language understanding. While this represents a creative step toward integrating behavioral and semantic information, the novelty is somewhat limited by the existence of related work, such as LC-Rec and BinLLM, which also aim to bridge collaborative and semantic signals within large language models. The main distinction of this paper is the specific adaptation of QFormer and the introduction of the item-item contrastive loss, which is well-justified and empirically validated. However, a more thorough comparison with these recent LLM-based recommendation systems would help to better establish the unique contributions and boundaries of novelty. Overall, the paper offers an interesting and incremental advance in the integration of recommendation and language modeling, but its novelty would be strengthened by a clearer articulation of differences from closely related approaches.",
    "candidate_a_text": "This paper proposes a novel framework called Item-Language Model (ILM) that combines the strengths of traditional recommendation systems with large language models, addressing the limitations of both approaches. The introduction of an item-item contrastive loss and a user-item contrastive loss is presented as a contribution to help preserve behavioral information while adapting to the text modality, and the two-phase training workflow is introduced to reduce the computational cost of fully fine-tuning large language models while achieving comparable performance. However, the motivation for this research is unclear, particularly regarding the benefits of joint training on language and recommendation tasks, and the authors do not provide a compelling rationale for why an item-language model is necessary or what specific advantages it offers over existing approaches that separate these tasks. The paper lacks a thorough comparison with existing state-of-the-art methods, making it difficult to assess the true originality and significance of the proposed method, and does not clearly explain the limitations of existing approaches or how the ILM overcomes them.",
    "candidate_b_text": "This paper proposes a novel approach by adapting the Querying Transformer model to align behavioral and textual data in recommendation systems, integrating collaborative filtering embeddings with large language models. Although these methods are mentioned in the related work, a more detailed comparison with other methods that integrate collaborative filtering with LLMs, such as CoLLM and OpenP5, would strengthen the paper.",
    "candidate_a_label": "AI System: deepreviewer",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "deepreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {}
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 41
  },
  {
    "id": 52,
    "paper_id": "W48CPXEpXR",
    "reference_text": "This paper investigates the potential of \"good hallucinations\" in Large Language Models (LLMs) by redefining hallucinations—traditionally considered as model errors—as possible drivers of creative problem-solving. The authors introduce a creativity metric that combines the accuracy and diversity of generated reasoning paths, and they empirically explore how different prompting strategies and temperature settings affect the creativity and correctness of LLM outputs across several reasoning and problem-solving datasets. The central contribution lies in the novel perspective of treating certain hallucinations as beneficial for creativity, rather than solely as failures to be minimized. This reframing is a fresh and interesting direction that aligns with emerging interests in the unexpected behaviors of LLMs. However, while the conceptual shift is noteworthy, the novelty is somewhat limited by the narrow operationalization of \"good hallucinations\" as divergent reasoning paths that still lead to correct answers. This definition may not fully capture the broader and more nuanced aspects of creativity, especially in domains where correctness is subjective or ill-defined. Furthermore, the proposed creativity metric, which primarily measures diversity among correct outputs, is relatively simplistic and does not engage deeply with established theories of creativity or originality. As such, while the paper’s premise is original and worth exploring, its concrete contributions are incremental, and the work would benefit from a more rigorous justification of its definitions and metrics, as well as a broader exploration of creative domains beyond logical and mathematical reasoning.",
    "candidate_a_text": "This assessment reviews a submission that reframes LLM hallucinations as potential sources of creativity, proposing systematic metrics and protocols to evaluate \"good hallucinations\"—outputs that are both creative and correct. The work is well-situated within current research trends, drawing on recent surveys and domain-specific studies (e.g., FiSTECH), and advances the field by explicitly operationalizing and empirically validating creativity-focused hallucination metrics, such as TTCT-inspired measures and semantic clustering. However, the assessment notes that the submission sometimes overstates its novelty, as similar ideas and metrics have been discussed or implemented in prior work, particularly in domain-specific contexts. The main contribution is the integration and generalization of these evaluation strategies for broader LLM use, rather than the introduction of fundamentally new concepts or methodologies. Overall, the submission is a timely and systematic, but incremental, advance that reflects and extends ongoing shifts in the field toward nuanced, creativity-aware evaluation of LLM outputs.",
    "candidate_b_text": "This paper introduces the novel concept of \"good hallucination\" in LLMs, challenging the usual negative connotation of hallucinations and highlighting their potential role in creativity. The authors propose a novel creativity metric that combines accuracy and diversity, providing a more holistic evaluation of LLM performance. However, the paper does not compare the proposed creativity metric with existing creativity assessment methods, making it difficult to evaluate the validity and reliability of the new metric.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {}
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 30
  },
  {
    "id": 31,
    "paper_id": "xYzOkOGD96",
    "reference_text": "This paper introduces a task, dataset, and model for grounded video caption generation, specifically defining the task as GROunded Video Caption Generation (GROC), creating a manually annotated test set, and proposing the VideoGLaMM model trained on a newly constructed HowToGround dataset. However, the claimed novelty of the task is not well supported. The concept of grounded video captioning is not new, as prior work such as Zhou et al. (2019) in \"Grounded Video Description\" [1] has already collected grounded video-text datasets and proposed models that leverage grounding information to improve video descriptions. In the vision-and-language community, the terms \"video description\" and \"video captioning\" are generally used interchangeably, and the distinction made in this submission does not constitute a fundamentally new task. A direct comparison of figures from this submission and from Zhou et al. (2019) further highlights the overlap. Therefore, the claim that the task is newly proposed by the authors is not justified. Regarding the model, the main change appears to be the replacement of previous LSTM-based language modules with large language models (LLMs), which, while potentially improving results, does not represent a significant innovation in model structure. The assertion that producing spatio-temporally grounded video descriptions has received little attention is also inaccurate, as several relevant works ([1], [2], [3], [4]) have addressed similar challenges. Overall, the paper’s contributions are incremental, and the novelty is limited both in terms of task definition and model design. The submission would benefit from a more thorough discussion and comparison with prior work to accurately position its contributions within the existing literature.",
    "candidate_a_text": "The paper proposes a new task of grounded video caption generation, where objects in the caption are grounded in the video via temporally consistent bounding boxes. It introduces a manually annotated test dataset and presents an automatic annotation method that leverages existing grounded still image captioning models and large language models to create a large-scale training dataset, which is a significant contribution to the field. However, while the automatic annotation method is a contribution, it is a straightforward extension of existing image-based grounded captioning and LLMs. The results of the introduced VideoGLaMM model set the state of the art for this new task.",
    "candidate_b_text": "This paper introduces a new task called grounded video caption generation, which involves generating captions for videos while also providing bounding boxes for the objects mentioned in the captions. While the paper characterizes the task as novel and notes that it has not been extensively explored in previous work, the reviewer expresses concerns regarding the degree of originality. Specifically, the reviewer argues that the proposed task is not particularly novel, as it simply combines the established tasks of video captioning and object grounding, and the motivation for doing so is not clearly justified nor shown to be significantly more challenging than the individual tasks addressed separately. The reviewer suggests that the paper would benefit from a more compelling justification for why addressing these two tasks jointly is necessary. Thus, while the effort to combine these areas and construct related datasets is acknowledged, the overall contribution is viewed as having limited novelty without a stronger rationale or demonstration of distinct new challenges introduced by the integration.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: deepreviewer_partial",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "deepreviewer_partial",
      "consensus_info": {}
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 2
  },
  {
    "id": 45,
    "paper_id": "Gh1XW314zF",
    "reference_text": "This paper introduces MG-LLM, a framework that integrates large language models (LLMs) with graph neural networks (GNNs) to perform multimodal healthcare predictions by constructing modality-specific graphs, propagating information with GNNs, aligning modalities via contrastive learning, and injecting context vectors into the LLM. While the approach is well-motivated and demonstrates improved performance over baseline models, the novelty of the framework requires clarification. The unification of multimodal graphs using contrastive learning has been widely explored in the literature, and the use of multiple types of graphs and multimodal data for healthcare prediction has been addressed in prior work such as GraphCare (ICLR 2024) and reviewed in the broader context by npj Digital Medicine (2022). However, the specific application of multimodal graphs to enhance LLMs’ understanding of multimodal healthcare information appears to be a novel aspect of this work. Additionally, the Patient Similarity Integration and Context Injection components bear resemblance to the retrieve and refine modules proposed in NeurIPS 2022, suggesting that some elements of the framework build upon existing ideas. Overall, while the integration of multimodal graphs with LLMs is a promising direction and may offer incremental novelty, the paper would benefit from a more explicit discussion of how its contributions differ from and advance beyond established methods, particularly in relation to prior work on multimodal graph learning and retrieval-augmented LLMs.",
    "candidate_a_text": "The submission, MG-LLM, proposes a unified framework that combines graph neural networks (GNNs) for explicit patient similarity and temporal modeling with large language models (LLMs) for multimodal clinical prediction, targeting the integration of heterogeneous EHR data. While prior works have either injected multimodal data into LLMs (e.g., HeLM, LLMMs) or used GNNs for patient graphs (e.g., MGNN), MG-LLM is among the first to explicitly inject GNN-derived patient context into LLMs for healthcare, though similar GNN-LLM integrations exist in other domains. The authors’ claims about novelty are somewhat overstated, as the technical advance is an incremental synthesis of established techniques rather than a foundational breakthrough, and some prior works (e.g., attention-based or NAS-based fusion) can capture complex relationships, albeit less explicitly. Empirical improvements are demonstrated, but it is unclear whether gains stem from conceptual innovation or increased model complexity and better data alignment. Overall, MG-LLM represents a logical and valuable extension of current trends in multimodal healthcare AI, with its main contribution being the explicit, unified integration of GNN-modeled patient relationships into LLM-based reasoning.",
    "candidate_b_text": "This paper introduces an innovative integration of multimodal data within a graph-based framework, addressing a significant gap in how LLMs handle diverse healthcare data types. The framework's ability to use both temporal and similarity edges in the graph structure is a notable advancement, allowing MG-LLM to capture longitudinal patient data and draw insights from similar patients, which is crucial in healthcare.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {}
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 19
  },
  {
    "id": 7,
    "paper_id": "uMEsKEiB7J",
    "reference_text": "This paper introduces NovelQA, a benchmark specifically designed to evaluate large language models (LLMs) on long-context question-answering tasks using texts that exceed 200,000 tokens and are drawn from a diverse selection of English novels. The benchmark is constructed with expert-annotated questions that require detailed comprehension of lengthy narratives, and it assesses multiple facets of understanding, including narrative comprehension, multi-hop reasoning, and detail retrieval. In terms of novelty, NovelQA represents a significant advancement over standard benchmarks by emphasizing extended context comprehension within complex narratives—a challenge that existing datasets have not adequately addressed. The inclusion of tasks that evaluate narrative coherence and multi-step reasoning further distinguishes NovelQA as a substantial contribution to long-context evaluation. Overall, the benchmark fills an important gap in the evaluation of LLMs’ abilities to manage large, complex contexts, marking a notable step forward in the field.",
    "candidate_a_text": "This paper introduces NovelQA, a benchmark designed to evaluate the performance of LLMs on extremely long and complex texts. NovelQA is the first long-context QA benchmark featuring manually crafted questions, golden answers, and evidence, with contexts exceeding 200,000 tokens. The questions are manually annotated by literature experts, ensuring high-quality, nuanced questions and answers that reflect complex human thought processes. The dataset includes a diverse range of question types, testing different comprehension abilities of LLMs, and the evaluation of current LLMs on NovelQA reveals their strengths and weaknesses, providing valuable insights for further research.",
    "candidate_b_text": "NovelQA introduces a long-context QA benchmark focused on narrative texts (English novels) with contexts exceeding 200,000 tokens, combining manual expert annotation and a public leaderboard. Its main differentiator is the intersection of ultra-long narrative contexts and manual annotation, which is relatively unique but not entirely unprecedented, as LV-Eval matches or exceeds context length and annotation quality (though not in the narrative domain), and Narrative XL covers the narrative domain (though with LLM-generated questions). The authors somewhat overstate NovelQA’s novelty, omitting direct comparison with highly relevant recent benchmarks like LV-Eval and Ada-LEval, and do not empirically demonstrate the practical impact of manual annotation versus LLM-generated questions. Many claimed contributions, such as question diversity and public leaderboard, are now standard in the field, and the submission would benefit from a more nuanced and comparative discussion of related work. Overall, NovelQA’s strongest contribution is the combination of narrative domain, ultra-long context, and manual annotation, but its novelty is incremental rather than fundamental given the current landscape.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {}
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 18
  },
  {
    "id": 28,
    "paper_id": "N2sN3LESoW",
    "reference_text": "This paper identifies that the binary format of RLHF data labels fails to reflect the actual pairwise difference of human preference and proposes to weight the pairwise samples with respect to the semantic gap in order to provide supervision signals beyond binary labels. The proposed method is simple and has a clear connection to related works. The data-dependent margin and beyond-binary motivation is a good direction for preference optimization, however what the paper presents doesn't fully exploit the potential, as there can be a much wider spectrum of margins that more faithfully match the motivation, such as length difference or response-level LM embedding distance. A more comprehensive study over these options may bring in further contribution in this direction and potentially address the non-improvement for Arena-Hard and MT-Bench.",
    "candidate_a_text": "The submission introduces GaPO, a preference optimization method for LLM alignment that replaces fixed or tunable loss margins with margins dynamically set by external semantic similarity metrics (e.g., ROUGE L, Jaccard, BERTScore), aiming to better capture the intensity of human preferences. While this is a clear technical extension of prior work such as SimPO (which uses a tunable margin) and WPO (which applies dynamic weighting), the main novelty lies in the explicit use of semantic gap metrics to modulate the loss, rather than in the overall optimization framework. The conceptual advance is modest, as the loss structure closely mirrors existing approaches, and the idea of using external metrics to adapt loss terms is common in NLP. Empirical results show a modest improvement over state-of-the-art baselines, but these gains may be influenced by implementation details or metric selection rather than the core conceptual innovation. Overall, the work represents an incremental but well-executed advance in a mature and competitive field, and reviewers should weigh the technical clarity of the extension against the limited conceptual novelty.",
    "candidate_b_text": "This paper introduces Gap-Aware Preference Optimization (GaPO), which I find to be a novel and well-motivated approach to preference optimization. The authors correctly identify a key limitation of traditional RLHF methods—their reliance on binary labels that fail to capture nuanced differences in human preferences—and address this by incorporating the degree of semantic gaps into the loss function. GaPO provides a more granular supervisory signal, allowing the model to better understand and reflect the subtleties of human perception, which is a significant contribution that addresses a critical challenge in the field. The method is differentiated from prior work by explicitly quantifying the semantic gap using metrics such as Jaccard Score, ROUGE, and BERTScore, and using this as a basis for loss margin adjustment rather than binary labels. My assessment is that the introduction of GaPO represents a strong and original contribution, particularly in its empirical demonstration of surpassing existing state-of-the-art methods on widely used benchmarks such as AlpacaEval 2.0, with GaPO-ROUGE_L achieving a notable win rate. The paper’s thorough exploration of different forms of the loss function and mapping functions, as well as its analysis of various evaluation metrics, further supports the distinctiveness and robustness of the proposed approach. Overall, the combination of a novel method, its strong empirical results against leading baselines, and its focus on addressing a key shortcoming in preference optimization underscores the significance of the contribution.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: deepreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "ours",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "deepreviewer",
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 0.6666666666666666,
        "num_reviews": 4,
        "consensus_type": "majority",
        "other_reviews": [
          0,
          2,
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": true,
            "2": false,
            "3": false
          },
          "1": {
            "0": true,
            "1": true,
            "2": true,
            "3": false
          },
          "2": {
            "0": false,
            "1": true,
            "2": true,
            "3": false
          },
          "3": {
            "0": false,
            "1": false,
            "2": false,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 0.3333333333333333,
          "1": 0.6666666666666666,
          "2": 0.3333333333333333,
          "3": 0.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 25
  },
  {
    "id": 3,
    "paper_id": "3b9SKkRAKw",
    "reference_text": "This paper introduces a novel 3D lesion inpainting method, LeFusion, which uses diffusion models to address data scarcity in medical imaging by generating synthetic lesions in lung CT and cardiac MRI scans for data augmentation in lesion segmentation tasks. The authors identify that existing lesion inpainting methods struggle to preserve anatomically accurate backgrounds alongside the inpainted lesion, and LeFusion is introduced to address this challenge with a lesion-focused diffusion loss and background preservation at inference time using RePaint. While the Introduction and Background sections seem to imply that the proposed lesion-focused loss is a novel contribution proposed for the first time by the authors, this might not be necessarily true considering that there have been other works that employ similar approaches [2, 3]; mentioning them could further strengthen the contextualisation of the approach. The paper provides multiple key contributions which not only address the research gap but also deal with modality-specific challenges related to lesion texture and shape heterogeneity, and these claims are well supported by the results.",
    "candidate_a_text": "This paper introduces a novel approach to generating lesion-containing images from healthy images, addressing data scarcity and long-tail distribution problems in medical imaging. The proposed method, LeFusion, focuses on lesion areas during the diffusion process and includes two new strategies for lesion texture synthesis: histogram-based texture control and multi-channel decomposition, enabling the generation of diverse, high-quality lesions with control over lesion size, location, and boundary. However, the proposed method may lack innovation, as it combines existing techniques such as diffusion-based inpainting and lesion mask generation, which are already well-established in medical image analysis, and may not significantly advance the current state-of-the-art in medical image synthesis. Furthermore, the paper does not compare the proposed method with the latest state-of-the-art approaches in lesion synthesis, such as those using advanced generative models like GANs or other diffusion models, making it difficult to assess the true novelty and effectiveness of the approach in comparison to existing work.",
    "candidate_b_text": "This paper presents a latent diffusion model-based method for inserting lesions into healthy medical images, incorporating several additions to address limitations of prior work or naïve approaches, such as combining forward-diffused backgrounds with reverse-diffused foregrounds, introducing intensity histogram-conditioning for lesion texture control, and techniques for further control of lesion shape and size. Overall, I find the paper to have decent technical novelty, as it incorporates many techniques—some pre-existing (like combined noised backgrounds with denoised foregrounds) and some seemingly novel (such as histogram-based textural control)—that come together to result in a strongly-performing method. The approach is relatively watertight, with these additions being lightweight and simple, and not requiring an additional network. Clear improvements over baseline methods are demonstrated, especially over Cond-Diffusion, which would be the naïve approach many would first try for this task, and the limitations of such prior methods are made clear through experiments. However, the main limitation is that the task itself is fairly niche within medical image ML, making the overall impact of the work somewhat limited in the broader context of general machine learning.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "Human Review 2",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 2,
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 1.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          2,
          3
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "2": true,
            "3": true
          },
          "2": {
            "1": true,
            "2": true,
            "3": false
          },
          "3": {
            "1": true,
            "2": false,
            "3": true
          }
        },
        "agreement_scores": {
          "1": 1.0,
          "2": 0.5,
          "3": 0.5
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 20
  },
  {
    "id": 21,
    "paper_id": "mEpqHvbD2h",
    "reference_text": "This paper studies how to use PPO to finetune the diffusion-model based policy in an offline-to-online setting. Utilizing RL method to finetune diffusion model is in great need, and the fruitful experimental results presented in this work are of great value and originality. However, based on my comprehension, the diffusion policy and PPO used in this work are of no novel changes and contributions. Combining these two together and successfully applying on real-world robotic systems is of great value and potential, but the advantage of diffusion policy to vanilla parameterization is already well-established and not the contribution of this paper, in my opinion. Sect. 6 of structural exploration is of much importance and novelty.",
    "candidate_a_text": "**Summary for Reviewer:**\n\nThis submission introduces DPPO, a framework for fine-tuning diffusion-based policies in reinforcement learning using policy gradient (PG) methods, with a focus on robotic control. While prior work has attempted PG-based optimization for diffusion policies—often finding it unstable or ineffective—DPPO demonstrates, through careful design choices (e.g., normalization, regularization, PPO-style updates), that PG can be made robust and effective, achieving strong empirical results in both simulation and real-world tasks. The main contribution is thus an empirically validated set of best practices for stable PG fine-tuning, rather than a fundamentally new algorithmic idea. The authors somewhat overstate their novelty, as similar PG approaches have been explored (though less successfully) in recent literature, and some closely related works are omitted from the discussion. Overall, DPPO represents an incremental but important advance in the field, with its primary delta being practical effectiveness and empirical robustness rather than conceptual innovation.",
    "candidate_b_text": "This paper proposes a framework for fine-tuning diffusion policy via on-policy reinforcement learning. The novelty of this paper is limited, as the idea of fine-tuning diffusion policy via RL has been explored in previous works, such as [1]. The authors claim that previous works conjectured that policy gradient (PG) methods are less efficient for diffusion policies, but there is no evidence to support this claim; to the best of my knowledge, there is no work suggesting that PG is less efficient for diffusion policies. On the contrary, [1] directly fine-tunes the diffusion policy via on-policy PG and achieves good performance. The authors should compare DPPO with other diffusion-based policies and other fine-tuning methods, such as [1], to better establish the contribution. Therefore, I do not believe that DPPO can be claimed as a state-of-the-art method.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 1.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          1,
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": true,
            "3": true
          },
          "1": {
            "0": true,
            "1": true,
            "3": false
          },
          "3": {
            "0": true,
            "1": false,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 1.0,
          "1": 0.5,
          "3": 0.5
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 21
  },
  {
    "id": 53,
    "paper_id": "Ipe4fMCBXk",
    "reference_text": "This paper presents a new method for protein design, Recombination Flow Matching (RFM), which is claimed to be the first to leverage the critical biological phenomenon of recombination for protein design by transforming larger fragments of protein backbones with rotations and translations to design novel protein structures. However, I find that the novelty claim falls short: while recombination is indeed important in evolution at the genome level, there is little evidence that it is a major driver of diversification at the protein level, and the authors do not convincingly establish that recombination at the protein level is a significant evolutionary mechanism. Furthermore, the manuscript conflates the definition of \"recombination\" used by protein engineers—using fragments from existing proteins to design new ones—with the evolutionary biology definition, and the method aligns more with the former, which is a well-established strategy with numerous prior works such as Bedbrook et al. 2017/2019, Romero et al. 2012, and Voigt et al. 2002. Therefore, the claim that RFM is the first model to leverage recombination in protein design is not accurate from a protein engineering perspective, as recombination-based design methods have been used for decades. Additionally, the evaluation metrics used to support claims of novelty are insufficient, as recombination-based methods inherently recycle domains from existing proteins, making it unlikely that substantially different functions will emerge, and the metrics employed may not adequately demonstrate true novelty in the generated protein structures.",
    "candidate_a_text": "The submission introduces Recombination Flow Matching (RFM), a generative model for protein structure design that explicitly incorporates the recombination of large protein segments, distinguishing itself from prior flow/diffusion-based models that focus on motif insertion or inpainting. RFM’s main claimed contributions are: (1) being the first to operationalize recombination as a generative operation in flow/diffusion models, (2) preserving the structural integrity of recombined segments with automated spatial arrangement, and (3) generalizing to multi-protein recombination. While the model’s explicit recombination framing and multi-segment capability represent a substantive extension within the flow/diffusion paradigm, similar capabilities (e.g., multi-motif scaffolding, automated arrangement) are already present in recent models like FADiff and FrameFlow, making the technical novelty more incremental than transformative. The authors’ characterization of prior work is generally accurate but sometimes overstates the novelty of recombination and omits relevant ML-guided recombination and latent space evolution approaches from the broader literature. Overall, RFM’s main advance is the explicit modeling of segment-level recombination in a generative framework, but reviewers should be aware that the distinction from existing motif/segment scaffolding models is partly terminological and that the broader context of evolutionary-inspired computational methods is not fully addressed.",
    "candidate_b_text": "This paper introduces the Recombination Flow Matching (RFM) model, which introduces recombinations of protein segments to the traditional flow matching model with the aim of generating more novel structures by incorporating recombination. The idea of applying biological recombination principles in protein design is innovative, drawing parallels with natural evolution and differing from other generative model methods that emphasize individual residues or entire protein backbones. The experiments indicate a performance advantage over existing methods in novelty, and the approach has potential for great impact as it addresses the problem of protein structure discovery with downstream applications in fields like drug discovery and biotechnology.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "Human Review 4",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "ours",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 4,
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 0.3333333333333333,
        "num_reviews": 4,
        "consensus_type": "majority",
        "other_reviews": [
          3,
          4,
          5
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "3": true,
            "4": false,
            "5": false
          },
          "3": {
            "1": true,
            "3": true,
            "4": false,
            "5": false
          },
          "4": {
            "1": false,
            "3": false,
            "4": true,
            "5": true
          },
          "5": {
            "1": false,
            "3": false,
            "4": true,
            "5": true
          }
        },
        "agreement_scores": {
          "1": 0.3333333333333333,
          "3": 0.3333333333333333,
          "4": 0.3333333333333333,
          "5": 0.3333333333333333
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 22
  },
  {
    "id": 43,
    "paper_id": "c4w1TqcSi0",
    "reference_text": "This paper introduces a framework based on an iterative generate, rank, select, and train paradigm to address inter-agent communication and task inference challenges within LLM-based MAS, building iSFT and iDPO on this iteration paradigm. However, the methods iSFT and iDPO seem to lack innovation. iDPO merely combines MCTS from ToT with DPO, while iSFT simply adds a step of supervised fine-tuning (SFT) after removing the prompt. These methods seem incremental rather than novel, and similar approaches can already be found, such as [1], [2], [3], [4], [5].",
    "candidate_a_text": "The paper introduces OPTIMA, a novel training framework designed to optimize LLM-based multi-agent systems for enhanced communication efficiency and task effectiveness. The proposed method is novel, particularly in its use of MCTS to generate diverse trajectories for DPO training, which I find to be a smart approach to explore different interaction paths and identify high-quality data for training. The results demonstrate that OPTIMA consistently outperforms both single-agent MAS baselines and vanilla MAS, highlighting significant improvements in communication efficiency and task performance.",
    "candidate_b_text": "**Summary for Reviewer:**\n\nOPTIMA is a multi-agent LLM framework that formally integrates multi-objective reward optimization—balancing task performance, token efficiency, and communication readability—using an iterative generate-rank-select-train paradigm and MCTS-inspired DPO data generation. While the approach is well-positioned at the intersection of multi-agent debate, process-level optimization, preference modeling, and communication efficiency, most of its components and their combinations have been explored in prior work, making the main technical delta the formal unification and application context rather than fundamentally new algorithms. The authors’ claims of novelty, particularly regarding unified optimization and MCTS-inspired DPO in MAS, are somewhat overstated, as similar ideas have appeared in related literature, though OPTIMA’s explicit reward formalism and MAS adaptation are more formalized. The empirical improvements reported are substantial, but may be partly attributable to implementation choices and task selection, and the work would benefit from more direct comparisons to closely related methods (e.g., SimPO, ReST-MCTS*). Overall, OPTIMA is a strong, contemporary integration of recent trends in the field, but its contributions are primarily incremental and formal rather than radically innovative.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          2
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "2": true
          },
          "2": {
            "1": true,
            "2": true
          }
        },
        "agreement_scores": {
          "1": 1.0,
          "2": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 8
  },
  {
    "id": 41,
    "paper_id": "lxMlenl3XU",
    "reference_text": "This paper introduces Dual Temporal Research Analysis (DTRA), a task that unifies historical research analysis with future trend forecasting, and proposes the HorizonAI framework, which leverages a knowledge graph to summarize historical papers and infer future research trends inspired by human cognitive processes. While the authors position their work as bridging a gap left by prior approaches—such as Wang et al. (2024), which focuses on LLM-assisted survey writing, and Agarwal et al. (2024), which enhances literature search—the novelty of this contribution appears limited. The main advance lies in using a knowledge graph to organize historical research and then extrapolating future trends, but this approach is less significant and distinct compared to the aforementioned works. Rather than representing a true synthesis or substantial extension of previous methods, the paper’s primary contribution is the cognitive-inspired inference of future research directions from historical summaries. As such, the work does not clearly surpass existing literature in terms of methodological innovation, and its novelty is incremental rather than transformative.",
    "candidate_a_text": "This paper introduces a novel task called Dual Temporal Research Analysis (DTRA), which integrates historical research analysis with the prediction of future trends, and proposes a corresponding framework named HorizonAI that draws inspiration from Dual-System Theory by combining temporal knowledge graphs with large language models. The review highlights that DTRA addresses a gap in existing approaches by unifying retrospective reviews and future speculation, and characterizes the integration of temporal knowledge graphs with LLMs as an innovative approach that allows for a comprehensive understanding of research trends. Additionally, the paper presents a new benchmark, ResBench, to evaluate the performance of DTRA, further establishing its contribution. Based on the strengths section, the originality lies in both the task definition and the architectural inspiration; however, the review does not contain detailed direct comparisons to prior work or an explicit assessment of whether these contributions significantly advance the field beyond stating their novelty and innovative nature. Thus, while the paper is credited with presenting a novel task and a framework inspired by cognitive theory, the level and uniqueness of its innovation relative to existing literature are not thoroughly analyzed in the review.",
    "candidate_b_text": "This paper introduces a new task, dubbed Dual Temporal Research Analysis (DTRA), which aims to combine the summarization of past research with the prediction of future trends, which is a novel approach in the field. The authors propose a framework that leverages a temporal knowledge graph for papers (PaperTKG) and large language models (LLMs) for in-depth reasoning to generate both historical narratives and future projections, which is a creative combination of existing technologies. The authors also propose a benchmark to evaluate the performance of their framework, which is a useful contribution to the research community. However, the authors do not provide a thorough comparison with existing methods for predicting future trends in research, such as citation-based methods or survey-based methods.",
    "candidate_a_label": "AI System: deepreviewer_partial",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "deepreviewer_partial",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {}
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 24
  },
  {
    "id": 5,
    "paper_id": "cRR0oDFEBC",
    "reference_text": "This paper introduces AUTOIF, a generic and automated framework designed to generate high-quality training data for enhancing the instruction-following capabilities of large language models (LLMs) by leveraging code-based verification and execution feedback. While the approach emphasizes scalability and the synthesis of both positive and negative examples for instruction alignment, the core idea of automatic instruction verification is not entirely novel. Prior works such as CodeLlama2, PLUM, LLaMA3, SelfCodeAlign, and DeepSeek-Coder-V2 have already explored code-based execution feedback and automated instruction alignment, with CodeLlama2 and LLaMA3, for example, incorporating code synthesis and validation frameworks to improve instruction-following performance. These existing efforts establish code execution as a natural and effective source of feedback for aligning LLMs. As a result, although AUTOIF may offer incremental advances in terms of scalability and data synthesis, it does not represent a fundamentally new direction in the field. The main contribution appears to be the integration and automation of these established techniques at scale, rather than the introduction of a novel conceptual framework for instruction verification.",
    "candidate_a_text": "This paper introduces AutoIF, an automated pipeline for synthesizing high-quality instruction-following training data. AutoIF addresses a significant challenge in instruction-following by providing a scalable way to generate high-quality, verifiable instruction-following data.",
    "candidate_b_text": "This paper presents a novel method called AutoIF to automatically generate instruction following training data by leveraging code verification to validate the correctness of such data. The core innovation of AutoIF is in transforming the validation of instruction following data quality into a code verification problem, requiring large language models to generate instructions, the corresponding verification code, and unit test samples to cross-validate code correctness. According to the review, this is a creative combination of ideas not explored before; AutoIF represents an innovative approach that uses LLMs not only to generate responses but also to verify the quality of their own responses. The reviewer notes that the fact that AutoIF is the first to surpass 90% accuracy in IFEval’s loose instruction accuracy further highlights the originality and effectiveness of the proposed method. The reviewer did not cite any closely related prior works implementing similar code verification methodologies for instruction following data generation, suggesting a strong level of novelty in both the idea and its implementation as presented.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: deepreviewer_partial",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "deepreviewer_partial",
      "consensus_info": {}
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 15
  },
  {
    "id": 92,
    "paper_id": "1XxNbecjXe",
    "reference_text": "This paper introduces a method for generating image inputs to Vision Language Models (VLMs) that embed \"meta-instructions,\" enabling the model to respond to any user query appended to the image with a specified \"spin,\" such as a particular sentiment or language. While the concept of providing meta-instructions through image inputs is not entirely novel—prior work, notably Bailey et al. (2023), has explored related prompt injection attacks via images—this paper offers the most thorough and comprehensive treatment of the subject to date. The general algorithm employed, which involves creating a dataset of input-output pairs and training an image via projected gradient descent to maximize the likelihood over this dataset, closely aligns with the \"Behavior Matching\" approach described by Bailey et al. (2023). As such, the methodological contribution is incremental rather than fundamentally new. However, the paper distinguishes itself through its in-depth analysis and experimental results, particularly the study of semantic changes in images resulting from various attacks, with a focus on how meta-instruction attacks can preserve the original image meaning. The transferability experiments and the breadth of evaluation across multiple VLMs further strengthen the contribution. Overall, the novelty of this work lies less in the method itself and more in the scope, depth, and clarity of its empirical investigation, as well as the new insights it provides into the vulnerabilities of VLMs to image-based prompt injection. The paper would benefit from more explicitly acknowledging the overlap with prior methods and more clearly articulating how its results advance the understanding of this threat model.",
    "candidate_a_text": "This paper introduces a novel method of embedding hidden meta-instructions in images as a way to attack visual language models, which is distinct from traditional jailbreaking or adversarial example attacks. While the approach is new, the paper could provide more insight into how the proposed attacks compare to existing forms of adversarial attacks on VLMs, highlighting the unique aspects of meta-instruction attacks.",
    "candidate_b_text": "This assessment finds that the submission addresses indirect, cross-modal prompt injection in Visual Language Models (VLMs) by embedding hidden meta-instructions in images, aiming to steer model outputs while preserving image semantics. The work is most closely related to recent studies on adversarial image prompting (e.g., Qi et al. 2024, Bagdasaryan et al. 2023), but distinguishes itself through more systematic optimization for semantic preservation and a broader range of meta-instructions beyond jailbreaking. The main substantive contributions are a rigorous, multi-metric evaluation of attack effectiveness and semantic preservation, and empirical evidence that image-based meta-instructions can be more effective than explicit text prompts. However, the assessment notes that the conceptual advances are incremental, as the core idea of cross-modal prompt injection and semantic preservation has been explored in prior work, and some novelty claims (e.g., being the first to frame VLM users as victims) are somewhat overstated. Overall, the submission’s primary strengths lie in evaluation rigor and empirical findings, while its conceptual contributions represent a natural progression of the field rather than a fundamental shift.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {}
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 26
  },
  {
    "id": 84,
    "paper_id": "YCdag94iZs",
    "reference_text": "This paper introduces a technique called MILCA, designed to perform counting and summing of features, where feature weights are predicted using a fully connected network (FCN) with a projection replacing the softmax layer to produce coefficients within a specified range. In my view, this paper lacks sufficient novelty. The counting-based approach appears to be a straightforward extension within the MIL space, and it does not introduce any new theoretical contributions either.",
    "candidate_a_text": "The authors propose a simple method for multiple instance learning (MIL) that involves feature selection and either a counting or a weighted sum of the selected features. The proposed method is very simple and can be considered a basic baseline for MIL; while it is interesting that it is competitive with state of the art methods, it is not surprising given that MIL datasets are small and the models are prone to overfitting. I don't think this simple method brings any new insights to the MIL community. The experiments show that it is competitive with state of the art methods.",
    "candidate_b_text": "MILCA is a simple, efficient Multiple Instance Learning (MIL) method that extends counting/summing approaches by introducing learned feature weights and a projection step, aiming to improve interpretability and efficiency over attention-based models. The submission positions itself as an alternative to attention-based and graph-based MIL, but the technical novelty is incremental, mainly involving a different normalization (projection vs. softmax) and learned weighting, both of which have been explored in related motif-based and aggregation methods. Empirical results show modest accuracy improvements (about 3%) and efficiency gains, particularly in high-dimensional, low-sample regimes, though these may be context-dependent and not unique to MILCA. The authors somewhat overstate the conceptual distinction between \"counting\" and \"attention,\" as both are forms of weighted aggregation, and the practical impact of their technical variations may be limited. Overall, MILCA offers a practical, interpretable, and efficient extension of existing counting-based MIL methods, with its main contribution being empirical performance rather than a fundamentally new paradigm.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 1.0,
        "num_reviews": 4,
        "consensus_type": "majority",
        "other_reviews": [
          0,
          2,
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": true,
            "2": false,
            "3": true
          },
          "1": {
            "0": true,
            "1": true,
            "2": true,
            "3": true
          },
          "2": {
            "0": false,
            "1": true,
            "2": true,
            "3": false
          },
          "3": {
            "0": true,
            "1": true,
            "2": false,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 0.6666666666666666,
          "1": 1.0,
          "2": 0.3333333333333333,
          "3": 0.6666666666666666
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 9
  },
  {
    "id": 93,
    "paper_id": "AAjCYWXC5I",
    "reference_text": "This paper introduces a zero-shot in-context adversarial learning framework for Large Language Models (LLMs) aimed at enhancing research ideation. The approach leverages a multi-agent system inspired by the academic peer review process, with distinct proposer, reviewer, and area chair roles, to iteratively refine research ideas along the axes of novelty and feasibility. This framework fills a notable gap in the field by conceptually adapting adversarial learning to the context of LLM-driven idea generation, an area that has seen limited exploration. The use of a peer review-inspired multi-agent setup to promote iterative improvement in idea generation represents a conceptually novel contribution, distinguishing the work from prior approaches that typically do not model such structured, adversarial interactions among LLM agents. Overall, the paper’s novelty lies in its creative adaptation of adversarial learning principles and academic peer review dynamics to the automated ideation process, offering a fresh perspective and a promising direction for advancing LLM-based research support systems.",
    "candidate_a_text": "This paper proposes an adversarial training approach for large language models (LLMs) to improve research ideation, involving a multi-LLM-agent interaction system where one agent generates ideas and another evaluates them using a novel relative quality ranking metric. The primary novelty claims rest on the introduction of this relative quality ranking metric for evaluating open-ended generation and the multi-LLM-agent system for zero-shot in-context adversarial learning. While the approach is presented as innovative in addressing the quality of research ideation, the review notes that the evaluation is limited to a self-constructed dataset without comparison to established benchmarks, raising questions about the generalizability and distinctiveness of the method. Additionally, the review highlights the need for a more detailed explanation of how novelty and feasibility are defined and measured within the system, as well as a more comprehensive ablation analysis to clarify each component's unique contribution. Overall, while the paper claims novelty through its ranking metric and multi-agent adversarial framework, the significance and originality of the contribution remain unclear due to the lack of detailed comparative analysis and insufficient articulation of how the approach differs from or advances beyond existing work.",
    "candidate_b_text": "This paper introduces a zero-shot in-context adversarial learning framework to enhance research ideation using multi-LLM-agent interactions, where a proposer agent, reviewer agent, and area chair agent iteratively refine research ideas along novelty and feasibility dimensions, mirroring the academic review process. The multi-agent framework is well-designed, highly engaging, and interactive. The authors also propose a relative quality ranking metric to evaluate idea generation quality, showing that this approach significantly improves the novelty and feasibility of generated research ideas.",
    "candidate_a_label": "AI System: deepreviewer_partial",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "deepreviewer_partial",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 0.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          1
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": false
          },
          "1": {
            "0": false,
            "1": true
          }
        },
        "agreement_scores": {
          "0": 0.0,
          "1": 0.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 33
  },
  {
    "id": 78,
    "paper_id": "m8Rk3HLGFx",
    "reference_text": "This paper presents a multi-view video generation approach based on an input textual prompt or monocular video, incorporating a multi-view synchronization module into a pre-trained text-to-video model to maintain appearance and geometry consistency across multiple viewpoints. The multi-view video generation is a novel task, and this paper shows some promising results in this direction, where the temporal consistency within each single view and spatial consistency across different views are maintained reasonably well. The proposed way of using multi-view images, synthetic multi-view videos, and real-world monocular videos to train the model is novel, providing an alternative approach to solve the data scarcity issue when high-quality real-world multi-view videos are hard to obtain.",
    "candidate_a_text": "This paper introduces a plug-and-play module that enhances a pre-trained text-to-video model for multi-camera video generation, ensuring consistent content across different viewpoints. To address the scarcity of high-quality training data, this paper designs a hybrid training scheme that leverages multi-camera images and monocular videos to supplement Unreal Engine-rendered multi-camera videos. The proposed method enables intriguing extensions, such as re-rendering a video from novel viewpoints.",
    "candidate_b_text": "SynCamMaster is an incremental advance in the rapidly evolving field of multi-view, 3D-consistent, camera-controllable video generation, building directly on recent works like CVD and CamCo. Its main technical contributions are the integration of a plug-and-play camera encoder and a hybrid-data training pipeline that combines multi-view images, single-view videos, and synthetic data to address data scarcity and improve generalization. While the authors claim to be the first to achieve multi-camera real-world video generation, this is not fully substantiated, as CVD and CamCo already address similar problems with comparable technical approaches. The submission’s novelty lies primarily in practical data engineering and module integration, rather than in introducing fundamentally new methodologies or problem settings. Overall, SynCamMaster offers useful implementation improvements and broader applicability, but its conceptual advances are incremental and its claims of major novelty are overstated relative to the current state of the field.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 4,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {
        "consensus_review": 4,
        "consensus_score": 0.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          6
        ],
        "agreement_matrix": {
          "4": {
            "4": true,
            "6": false
          },
          "6": {
            "4": false,
            "6": true
          }
        },
        "agreement_scores": {
          "4": 0.0,
          "6": 0.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 29
  },
  {
    "id": 25,
    "paper_id": "INzc851YaM",
    "reference_text": "The paper proposes the Preference-Attended Multi-Objective Decision Transformer (PA-MODT) to facilitate the learning across large preference spaces and handling unknown preferences during evaluation, specifically by integrating a preference-attention block into the MODT architecture to enhance preference encoding. The novelty and contributions are very limited. I think the proposed method has very limited novelty and contributions. Besides, the method’s applicability is also limited since it only suits the transformer-based architectures in MORL.",
    "candidate_a_text": "This assessment reviews a submission introducing PA-MODT, a transformer-based architecture for offline multi-objective reinforcement learning (MORL) that features a novel preference-attention block and modular design, aiming to improve preference integration and generalization over prior transformer-based MORL models. The main technical contribution is the explicit modeling of preference interactions via attention, moving beyond the simple preference concatenation used in works like PEDA, MODT, and MORvS, though similar modular and attention-based adaptations exist in related domains. While the empirical results on the D4MORL benchmark are promising, the improvements may partly reflect implementation details or routine architectural refinements rather than a conceptual breakthrough, and the claimed limitations of prior work may be somewhat overstated. The submission also offers a more comprehensive analysis of evaluation metric sensitivity, which, while incremental, adds rigor to the evaluation. Overall, the work represents a solid but incremental advance in transformer-based MORL, with its main novelty being architectural rather than a paradigm shift, and would benefit from broader comparisons and a more balanced characterization of related literature.",
    "candidate_b_text": "The paper presents an empirical analysis on how advances in transformer architecture affect model performance on MORL tasks, specifically proposing Preference-Attended Multi-Objective Decision Transformer (PA-MODT), a new architecture based on MODT to facilitate the preference encoding problem. The novelty of the proposed method and contributions are very limited. In my opinion, this paper exhibits very limited novelty and applicability, since the methods only fit the transformer-based architectures in MORL, and their properties are not clarified clearly.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "Human Review 3",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 3,
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "3": true
          },
          "3": {
            "0": true,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 30
  },
  {
    "id": 15,
    "paper_id": "vwOq7twk7L",
    "reference_text": "The paper introduces a method for image-level memorization detection, motivated by an analysis showing two key characteristics of memorized images under perturbed inference: similarity discrepancy and a large magnitude of text-conditional noise prediction. The key idea of the method seems to be using an unconditional DDIM inversion to derive latent codes and optimizing non-memorized prompt embeddings for effective perturbation.",
    "candidate_a_text": "This assessment finds that the submission addresses the important and challenging problem of image-level memorization detection in text-to-image diffusion models without requiring access to prompts or metadata, situating it as a prompt-free, inversion-based detection method. The work is most closely related to recent prompt-level detection approaches (e.g., Wen et al., Ren et al.), but extends these ideas to the more realistic image-only setting, leveraging unconditional DDIM inversion and inference perturbation. While the technical components—such as inversion, perturbation, and detection metrics—are largely adapted from prior work, the systematic combination and empirical validation for image-level detection represent a meaningful advance. The authors’ claims of being \"first\" are accurate in a narrow, systematic sense, but the conceptual gap from prior work is smaller than implied, as similar metrics and techniques are reused. Overall, the submission’s main contribution is a robust, prompt-free detection framework, with novelty arising from its integration and application of existing methods rather than from fundamentally new concepts.",
    "candidate_b_text": "This paper investigates the memorization limitation of the Stable Diffusion model to help protect the training data’s privacy and proposes a new task: image-level memorization detection, which is different from existing works that detect memorization during inference. This paper further proposes a correspondingly designed method for this new task. However, the motivation for the proposed new image-level memorization detection task is based on a misunderstanding of the related work, as the baseline methods do not need an organized prompt list and can detect potential memorized images during the inference process with good accuracy, making such lines of method actually more practical than the proposed image-level memorization detection task; thus, the proposed task is of limited practical significance. Additionally, the finding that large TCNP correlates with memorization is not novel, as it is actually the identical finding of [1] that a noise can present large TCNP even after the first step of DDIM denoising, although the paper differs in performing DDIM inversion to the clean image.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "Human Review 3",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 3,
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 0.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          2,
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "2": false,
            "3": false
          },
          "2": {
            "0": false,
            "2": true,
            "3": false
          },
          "3": {
            "0": false,
            "2": false,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 0.0,
          "2": 0.0,
          "3": 0.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 31
  },
  {
    "id": 59,
    "paper_id": "PYmrUQmMEw",
    "reference_text": "This paper introduces LLaMA-Omni, an end-to-end model architecture designed for low-latency, high-quality speech interaction with large language models (LLMs), and presents InstructS2S-200K, a large dataset of conversational, oral-style speech instructions and responses to support more natural speech-based dialogue. While the InstructS2S-200K dataset addresses a notable gap in conversational speech instruction data, the novelty of the model architecture itself is limited. The proposed system primarily combines existing components—namely, a pre-trained speech encoder, a speech adaptor, an LLM, and a streaming speech decoder—without a clear breakthrough in architectural design. Specifically, connecting a speech encoder to an LLM via a speech adaptor has been widely explored in prior research, and the streaming TTS module closely follows previous designs, particularly the approach outlined in Fang et al. (2024) [1]. As such, although LLaMA-Omni successfully assembles a functional pipeline for speech-based interactions with LLMs, it largely builds upon established methods and does not deliver significant innovation in model design. This reliance on prior work somewhat limits the paper’s impact from a research innovation standpoint, and further clarification of the unique contributions would be necessary to better establish its novelty.",
    "candidate_a_text": "This paper presents LLaMA-Omni, a novel architecture that enables low-latency and high-quality speech interaction with large language models by integrating a pre-trained speech encoder, speech adaptor, LLM, and streaming speech decoder for direct speech-to-speech generation without explicit transcription. The key innovation lies in this seamless integration, and the introduction of the InstructS2S-200K dataset further contributes a valuable resource for training and evaluating speech instruction models. The model achieves impressive low latency of 226ms, setting it apart from previous speech-language models in terms of user experience for real-time applications. However, the benefits and originality of the proposed non-autoregressive (NAR) decoder compared to existing methods like StreamSpeech are not well-defined, and the paper would benefit from more explicit comparisons to prior work and a thorough analysis of each component's contribution to better establish its uniqueness and significance.",
    "candidate_b_text": "LLaMA-Omni is positioned within the rapidly evolving field of end-to-end, low-latency speech interaction models that integrate LLMs with streaming speech processing, closely related to recent works like Mini-Omni and Moshi. While the authors claim novelty in eliminating intermediate transcription and enabling simultaneous text and speech generation, these features are already present in the most relevant prior art, making the conceptual advances largely incremental. The main technical distinction is the use of a CTC-based non-autoregressive streaming decoder with a LLaMA backbone, along with notable resource efficiency, though these improvements may stem from implementation choices rather than fundamental innovation. The introduction of the InstructS2S-200K dataset is a useful contribution, but similar datasets exist and direct comparisons are lacking. Overall, the submission is a strong instantiation of current trends, but its core contributions should be more rigorously contextualized against closely related recent works, as the claimed novelty is often overstated and the technical delta is modest.",
    "candidate_a_label": "AI System: deepreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "deepreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {}
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 32
  },
  {
    "id": 47,
    "paper_id": "jl9lHkQrrI",
    "reference_text": "This paper proposes a practical approach for fine-tuning small language models (LLMs) in the industrial asset domain by generating synthetic knowledge documents and question-answer pairs from structured tabular data, leveraging knowledge graphs and prompt engineering techniques. While the authors describe their method as a novel two-step iterative process that integrates a Knowledge Graph (KG) with an LLM to produce extensive qualitative knowledge documents, the methodological novelty appears limited. The approach primarily adapts existing techniques for industrial applications, and it is unclear whether the contribution lies in fundamentally building a new KG or in introducing a new continued fine-tuning strategy. The paper does not clearly differentiate its methodology from prior work, and there is little evidence of significant innovation beyond the practical application to a specific domain. As such, the novelty is minimal from a methodological perspective, and the work would benefit from a more explicit articulation of how its approach advances beyond established practices in LLM fine-tuning and knowledge integration.",
    "candidate_a_text": "This paper introduces a novel approach to enhance the performance of small language models in the industrial asset domain by leveraging structured tabular data. The authors propose a creative solution to enhance small LLMs using synthetic data generated from structured tables in ISO standards, and this is a novel approach in the domain of industrial applications.",
    "candidate_b_text": "This paper proposes a method to improve the performance of LLMs in industrial asset management by leveraging structured data from ISO standards, presenting a framework that integrates knowledge graphs with LLMs to enhance decision-making in specialized industrial contexts. However, the paper does not adequately contextualize its contributions within the existing body of research, making it difficult to understand the novelty and significance of the work, as well as its potential impact on the field. The related work section is sparse and lacks depth, omitting important areas such as prior uses of knowledge graphs with LLMs and existing solutions for domain-specific adaptation in industrial settings, which leaves gaps in situating the paper’s contributions within the broader research landscape.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: deepreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "deepreviewer",
      "consensus_info": {}
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 33
  },
  {
    "id": 75,
    "paper_id": "2ofVtMvRil",
    "reference_text": "This study demonstrates that predictive coding can effectively train neural networks to develop hexagonal grid representations from spatial inputs, providing a biologically plausible explanation for the emergence of grid cells in the medial entorhinal cortex. However, my major concern is that the work may lack novelty. The use of non-negative and sparse network designs to produce grid cell-like patterns has been extensively discussed, with prior work reporting that non-negative and sparse properties can generate grid cell-like patterns and theoretically demonstrating why non-negativity is the main driver of grid cell formation, which the author's paper does not address, instead of sparsity. Similar findings have also been reported elsewhere, and earlier work proves that a nonnegativity constraint on firing rates induces a symmetry-breaking mechanism favoring hexagonal firing fields, with further studies exploring the necessary conditions for generating grid cells. Prediction tasks, including path integration, that produce grid cell-like patterns have also been widely reported, especially when the input data takes a place cell-like form, and other studies have used place cell-like input and path integration tasks to train networks and generate grid cells, while some have theoretically analyzed the role of predictive learning in forming low-dimensional representations. In my understanding, tPCN is very similar to a one-step RNN (apart from the difference in local learning rules), so the fact that its training process resembles that of one-step tBPTT is not surprising; as previously noted, the key to forming grid cells lies in the predictive task, not the RNN network itself, and therefore, the similarity between tPCN and RNN does not offer significant insight into the generation of grid cells. For these reasons, I believe this paper does not offer substantial novelty or make a clear contribution to the field.",
    "candidate_a_text": "This paper makes a novel connection between predictive coding networks and grid cells by showing that predictive coding networks can extract grid cell representations from place cell inputs and that temporal predictive coding networks can learn to integrate velocity information to learn grid cell representations. However, there are many models that can learn grid cells, including attractor network models and other predictive models, so it is not clear why predictive coding networks are particularly suited for this task, and the paper does not provide a strong motivation for this connection. While the paper briefly mentions some existing models, it does not provide a comprehensive comparison to them, and a more detailed comparison—including an analysis of the computational requirements and biological plausibility of different models—would help in evaluating the originality and significance of the contribution.",
    "candidate_b_text": "This paper introduces a novel approach to modeling grid cell formation in the medial entorhinal cortex using predictive coding networks (PCNs). I find the use of predictive coding to model grid cell emergence to be a novel and compelling approach, offering a biologically plausible alternative to models that rely on backpropagation, which is unlikely to be implemented in the brain. The paper’s main contribution lies in its novel application of predictive coding to model grid cell emergence, providing a unified learning algorithm for diverse cortical representations. The authors successfully demonstrate that grid cells can arise as latent representations learned through predictive coding in both static and dynamic environments—a significant contribution to the field—and show that the learning rule of temporal predictive coding networks (tPCNs) implicitly approximates truncated backpropagation through time (BPTT). They compare their model with recurrent neural networks trained with BPTT, showing that both models can achieve similar performance in terms of path integration and grid score, while emphasizing the biological plausibility of their approach. However, I note several weaknesses that limit the clarity of the paper’s originality: the work lacks a detailed comparison with prior models, particularly recurrent neural networks and attractor networks, making it difficult to fully appreciate the unique contributions of the proposed model. While the authors mention advantages such as not requiring biologically implausible backpropagation and addressing the need for local learning rules, they do not provide an in-depth analysis of how their model mechanistically diverges from or improves upon existing approaches. This leaves the reader with an incomplete understanding of how the PCN model advances the field beyond existing models, and undermines the assessment of its true novelty and significance. Overall, I believe the paper makes a significant contribution by presenting a novel and biologically plausible model for grid cell formation, but the originality would be better established with a more thorough and mechanism-level comparison to prior work.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: deepreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "deepreviewer",
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "3": true
          },
          "3": {
            "1": true,
            "3": true
          }
        },
        "agreement_scores": {
          "1": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 14
  },
  {
    "id": 42,
    "paper_id": "4QWPCTLq20",
    "reference_text": "This paper introduces IntelLLM, a framework designed to optimize key-value (KV) cache compression for large language models (LLMs) by combining two techniques: Center of Gravity Eviction (CGE) and Remote Gap Localization (RGL). The proposed approach aims to significantly reduce memory consumption during long-sequence inference while maintaining model performance and requiring minimal modifications to existing LLM frameworks. While the integration of CGE and RGL is presented as a novel solution to the KV cache memory challenge, the overall novelty of the work is limited. Sparse attention mechanisms have already been extensively explored in prior literature, such as [1] and [2], which diminishes the originality of the proposed methods. Furthermore, the CGE component closely resembles previous approaches like H2O [3] and SnapKV [4], with only incremental differences. The feedback mechanism using sliding windows has also been well-studied in H2O [3]. As such, the main contribution appears to be a specific combination and implementation of existing ideas rather than a fundamentally new technique. The paper would benefit from a clearer articulation of how its methods differ from these established approaches to better establish its unique contribution.",
    "candidate_a_text": "This paper presents a KV cache compression method for large language models (LLMs), proposing two strategies—center of gravity eviction (CGE) and remote gap localization (RGL)—to reduce the number of retained KV pairs, and evaluates the method on two LLMs with better performance than the full KV baseline. However, the proposed method is not compared to any existing baselines, and the authors do not compare their approach to any existing KV cache compression methods, making it difficult to assess its relative performance.",
    "candidate_b_text": "IntelLLM introduces new heuristics—Center of Gravity Eviction (CGE) and Remote Gap Localization (RGL)—for token selection and long-range dependency preservation in KV cache compression for LLM inference, but these are incremental variants of established token eviction approaches. The submission overstates its novelty, as the core ideas (token selection, attention sparsity, training-free deployment) are already well-explored, and similar methods (e.g., RazorAttention, PyramidKV, L_2 Norm) achieve comparable goals without model changes or fine-tuning. Several highly relevant recent works are omitted from the discussion, and the claims of being the first to balance compression and performance or to preserve long-range dependencies are not substantiated by the literature. The main technical delta lies in the specific heuristics (CGE, RGL) and their empirical performance, rather than in a conceptual advance. Reviewers should view IntelLLM as a routine, incremental contribution and may wish to request more comprehensive comparisons and a more accurate positioning within the current research landscape.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {}
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 35
  },
  {
    "id": 79,
    "paper_id": "eiqrnVaeIw",
    "reference_text": "This paper investigates the vulnerability of pre-trained models to backdoor attacks, specifically examining how injected backdoors persist after further fine-tuning for alignment. The authors conduct experiments across models of varying sizes and evaluate multiple attack objectives to provide a comprehensive assessment of this vulnerability. However, the novelty of the work appears limited, as the problem of backdooring or poisoning pre-trained models has already been explored in prior studies such as [1] and [2], which have demonstrated that backdoors introduced during pre-training can survive subsequent fine-tuning. The methodology employed in this paper does not introduce any new attack techniques, instead relying on standard backdoor attacks using existing datasets. As a result, the main empirical finding—that pre-training backdoors can persist through fine-tuning and affect downstream model behavior—largely confirms conclusions already established in the literature. Furthermore, the paper does not provide deeper insights or novel observations, such as unique phenomena in large language models, explanations for the varying effectiveness of backdoors across different attack types, or analysis of scaling laws in poisoning pre-trained models. The lack of discussion regarding mitigation strategies, as addressed in [3], further limits the contribution. Overall, the paper’s contribution is incremental and does not clearly articulate what new aspects it addresses beyond existing work, making its novelty and impact on the field rather modest.",
    "candidate_a_text": "This paper investigates the impact of pre-training poisoning in LLMs, focusing on whether adversarial behaviors introduced during pre-training persist through post-training and fine-tuning stages. The topic of pre-training poisoning is both timely and important, and the authors conduct experiments on four distinct attack types across various model sizes to evaluate their persistence. However, the authors' method of constructing poisoned data is not realistic, as they use templates from existing instruction-following models to create poisoned dialogues, whereas pre-training data is often sourced from unstructured web pages that do not follow specific templates. The paper would benefit from a justification of their template-based data construction and a discussion of how their findings may generalize to more realistic data sources.",
    "candidate_b_text": "This submission systematically investigates whether data poisoning attacks introduced during LLM pre-training can persist through post-training alignment (SFT and DPO), focusing on multiple attack objectives such as denial-of-service, belief manipulation, jailbreaking, and prompt stealing. Its main contribution is the first comprehensive evaluation of attack persistence through alignment in text-only LLMs, showing that even very low poisoning rates (as little as 0.001%) can yield persistent attacks. The work is well-positioned at the intersection of pre-training poisoning and attack persistence, extending prior research that mostly focused on fine-tuning or post-training attacks, though the underlying attack methods are not novel. However, the novelty is somewhat overstated, as some recent works on privacy backdoors and pre-training poisoning in other modalities are omitted, and the distinction between pre-training and instruction tuning poisoning is not always clear. Overall, the paper offers a substantive and timely empirical advance, but would benefit from a more comprehensive related work discussion and a more nuanced framing of its novelty.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {}
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 36
  },
  {
    "id": 60,
    "paper_id": "Mvn5g49RrM",
    "reference_text": "This paper introduces RedCodeAgent, an LLM-based red-teaming agent designed to dynamically optimize prompts in order to attack code agents by inducing risky code execution, such as deleting critical files. The system is composed of a memory module that stores successful red-teaming experiences and a toolbox that provides various jailbreaking algorithms, with an LLM-based code substitution tool used to obfuscate code while maintaining its functionality. However, the novelty of RedCodeAgent appears to be limited, as its overall design and methodology are quite standard and largely build upon existing techniques. The agent primarily utilizes established jailbreaking algorithms to bypass code agent defenses, and the memory-plus-tool architecture is a common approach in constructing LLM-based agents. The process of iteratively attempting attacks and obfuscating code until success or abandonment does not introduce fundamentally new concepts or techniques. In essence, RedCodeAgent can be viewed as a combination of existing baseline methods and a code substitution tool, automated through an LLM with multiple attempts. As such, the approach lacks deep conceptual innovation or novel methodologies that advance the state of the art, and its contribution is primarily in integrating and automating existing components rather than introducing significant new insights or frameworks.",
    "candidate_a_text": "RedCodeAgent is an automated, adaptive red-teaming agent targeting LLM-based code agents, distinguished by its use of a memory module and real-time, multi-round prompt adaptation for attacking agents with code execution capabilities. While the authors claim to be the first to fully automate adaptive red-teaming for code agents, similar approaches (e.g., RedAgent, RedCode, ASB) are emerging in parallel, and the distinction between code LLMs and code agents is sometimes overstated. The main substantive advance is the integration of adaptivity and memory for red-teaming code agents, but the underlying techniques (memory modules, prompt optimization) are established in the literature, making the contribution incremental rather than groundbreaking. The evaluation is based on a custom, relatively small scenario set, rather than the largest available benchmarks, which limits the strength of empirical claims. Overall, RedCodeAgent is a timely and meaningful step forward, but reviewers should be cautious about strong novelty claims and look for clear evidence of substantive advances beyond routine adaptations of existing methods.",
    "candidate_b_text": "This paper proposes RedCodeAgent, an automated red-teaming agent designed to evaluate the safety of LLM-based code agents, equipped with tools for function-calling and a memory module for accumulating successful attack experiences. The novelty of the proposed method is limited. The proposed RedCodeAgent is an agent-based tool that calls other tools to jailbreak the target code agent, and similar agent-based methods have been proposed in many other fields, such as [1] in the vulnerability detection domain. The authors should clarify the key differences between these works.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {}
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 40
  },
  {
    "id": 71,
    "paper_id": "KwPUQOQIKt",
    "reference_text": "This paper introduces OmegaPRM, a divide-and-conquer Monte Carlo Tree Search (MCTS) algorithm designed to automate the collection of process supervision data for large language models (LLMs), with the goal of efficiently identifying the first error in a reasoning chain and thereby improving LLM performance on mathematical reasoning tasks. However, the novelty of OmegaPRM is limited, as the approach primarily combines established techniques—namely, MCTS and binary search. While the integration of these methods streamlines the data collection process and reduces reliance on human annotation, the core algorithmic contribution does not represent a significant departure from existing strategies in the literature. The paper would benefit from a more thorough comparison with prior work that leverages similar divide-and-conquer or search-based approaches, as well as a clearer articulation of how OmegaPRM advances beyond the straightforward combination of MCTS and binary search. Overall, the contribution is incremental, and the novelty is constrained by the reliance on well-known methods.",
    "candidate_a_text": "This paper proposes OmegaPRM, an efficient method for generating process supervision data to train Process Reward Models (PRMs) for reasoning tasks like mathematical problem-solving. OmegaPRM automates the collection of process supervision data, significantly reducing the need for costly human annotations by introducing a divide-and-conquer MCTS algorithm that efficiently identifies errors and balances positive and negative examples, resulting in a large, high-quality dataset without human intervention. However, the paper does not provide a detailed comparison with other automated process supervision methods, such as Math-Shepherd and MiPS, in terms of data quality, efficiency, and model performance, so it is unclear what the unique advantages of OmegaPRM are over these methods. While the method is validated primarily on mathematical reasoning tasks, its effectiveness in other domains is not demonstrated. A more comprehensive comparison with prior work and an analysis of the noise introduced by automated annotations would help in understanding OmegaPRM's originality and significance.",
    "candidate_b_text": "This submission presents an incremental advance in automated process supervision for LLM mathematical reasoning, primarily by scaling up fully automated process reward model (PRM) data collection using a new divide-and-conquer MCTS variant (OmegaPRM). While the work claims methodological novelty and full automation, similar MCTS-based automated pipelines (e.g., ReST-MCTS*, Math-Shepherd, HGS-PRM) already exist, and the technical distinction of the proposed MCTS variant is not fully established from the summary. The main contribution appears to be the creation of a larger-scale, fully automated process supervision dataset (1.5M+ annotations), with empirical gains on standard math reasoning benchmarks, though the qualitative improvement and source of gains (algorithmic vs. scale) are not fully isolated. The combination of weighted self-consistency decoding with process reward models is a logical extension of prior work rather than a conceptual leap. Overall, the submission is a strong incremental improvement, but its claims of novelty and automation are somewhat overstated, and more direct comparison to the latest related works would clarify its true contribution.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {}
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 6
  },
  {
    "id": 0,
    "paper_id": "v0FzmPCd1e",
    "reference_text": "This paper introduces selective attention, a method for adjusting the attention weights of tokens in transformer-based language models based on the attention they received from previous tokens. The approach also incorporates a mechanism to drop history tokens with the lowest adjusted weights and proposes a new loss term to guide training. While the method is simple, intuitive, and demonstrates strong empirical results in both accuracy and memory reduction, its level of novelty is moderate. The core idea of pruning the least important tokens in each iteration closely resembles cache-pruning strategies such as H20 (Zhang et al., 2023), TOVA (Oren et al., 2024), and related methods, with the main distinction being the application of a similar approach during training rather than inference. Although the paper introduces some novel elements, such as the new loss term, the overall contribution is incremental and would benefit from more measured claims regarding its originality. The work stands out for its effectiveness and practical impact, but the novelty primarily lies in specific implementation details rather than a fundamentally new paradigm.",
    "candidate_a_text": "The paper proposes Selective Attention, a simple yet effective mechanism that improves the efficiency and performance of transformers in language modeling. The method is parameter-free and adds negligible computation, making it easy to implement and integrate into existing transformer architectures. While the results demonstrate that transformers with Selective Attention perform equivalently to standard transformers with twice as many heads and parameters, highlighting the effectiveness of the proposed method, the paper does not compare Selective Attention with other existing methods for improving the efficiency of transformers, such as pruning, quantization, or knowledge distillation. As such, the contribution, while valuable to the field of natural language processing, lacks a thorough comparative analysis, which would provide a more comprehensive understanding of the advantages and disadvantages of Selective Attention and clarify its originality relative to prior work.",
    "candidate_b_text": "This submission introduces a parameter-free, token-level selective attention mechanism for transformers, aiming to reduce memory and compute costs without sacrificing performance. Its main novelty lies in its simplicity and plug-and-play nature, distinguishing it from prior adaptive context reduction methods that require learned parameters or complex heuristics (e.g., Dynamic Context Pruning, Adaptive KV Cache Compression). While the implementation is genuinely simpler, the conceptual goal of adaptive context reduction is not new, and the practical gap with some heuristic-based methods may be less significant than implied. The reported efficiency gains are impressive, but the lack of direct, head-to-head comparison with the most similar prior work makes it difficult to fully verify the claimed superiority. Overall, the work represents a substantive implementation advance within a rapidly evolving field, but reviewers should be mindful that the core idea is incremental rather than fundamentally novel.",
    "candidate_a_label": "AI System: deepreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "deepreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {}
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 39
  },
  {
    "id": 17,
    "paper_id": "ayupWYA1qD",
    "reference_text": "This paper introduces Toto, a foundation model designed for time series forecasting with a specific emphasis on observability metrics. The paper’s two primary contributions are the novel observability data and the newly designed foundation model. The technical novelty is limited; for instance, the probabilistic forecasting using the Student-T mixture model (SMM) is an extension, as the Student-T distribution as a prediction head has already been proposed [1]. The paper introduces a new dataset, a large dataset of proprietary observability metrics, which contains statistical characteristics absent from existing datasets.",
    "candidate_a_text": "TOTO proposes a transformer-based foundation model for time series forecasting in observability settings, introducing a proportional factorized space-time attention mechanism and a Student-T mixture model head, with large-scale pretraining on proprietary and open datasets. While the combination of these techniques and the application to observability data at scale is timely, both the factorized attention and Student-T mixture head have clear antecedents in prior work (e.g., CaFA, MTS-Mixers, SsSMM, AutoMixer), making the technical contributions largely incremental. The authors overstate the novelty of their approach by not fully acknowledging or benchmarking against closely related models, particularly AutoMixer and Predictive Observability, which have already explored similar domains and methodologies. Empirical improvements may be attributable to data scale or implementation rather than conceptual advances, and the lack of direct comparison to relevant baselines weakens claims of state-of-the-art performance. Overall, TOTO is a solid entry in the rapidly evolving field of time series foundation models, but its main advances are in the integration and scale of existing ideas rather than in fundamentally new methods.",
    "candidate_b_text": "This paper proposes a novel Transformer-based forecasting model tailored to observability, with key contributions including a novel transformer block integrating one channel-mixing attention layer followed by multiple blocks of time-wise attention, and an output head employing a mixture of Student-t distributions. The design of proportional factorized space-time attention potentially offers an expressive and efficient backbone for multivariate time series modeling. However, the technical contributions of space-time attention and Student-t mixture heads are of limited novelty and provide marginal improvement. If domain-specific training data is a contribution, details are needed on the pre-training corpus construction, ablation studies, and novelty of data selection.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "Human Review 3",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 2,
      "candidate_a_system": "ours",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 3,
      "consensus_info": {
        "consensus_review": 2,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "2": {
            "2": true,
            "3": true
          },
          "3": {
            "2": true,
            "3": true
          }
        },
        "agreement_scores": {
          "2": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 40
  },
  {
    "id": 11,
    "paper_id": "CvGqMD5OtX",
    "reference_text": "This paper introduces Chase-SQL, a framework that combines SQL queries generated by various large language model (LLM) strategies—including divide-and-conquer, few-shot learning with demonstration synthesis, and self-debugging—to enhance query quality for natural language questions. While the framework demonstrates strong empirical performance and integrates multiple established techniques, its novelty is limited. Many of the technical innovations presented have already been addressed in recent comprehensive surveys on NL2SQL, such as https://arxiv.org/pdf/2408.05109, which covers a broad spectrum of studies leveraging LLMs for similar purposes. As a result, the contributions of Chase-SQL largely reiterate established concepts in the field rather than introducing fundamentally new ideas. For example, the paper claims a \"unique instance-aware synthetic example generation\" approach; however, the use of few-shot examples has already been explored in prior work, including DIN-SQL and CodeS. Overall, while the integration of these techniques into a unified framework is well-executed, the individual components and the overall approach do not represent a significant departure from existing literature, and the paper would benefit from more clearly articulating how its methods differ from or improve upon prior work.",
    "candidate_a_text": "This paper proposes a novel framework called CHASE-SQL that leverages large language models to improve Text-to-SQL tasks by generating diverse and high-quality SQL query candidates using multi-path reasoning and an optimized candidate selection process. The paper introduces a multi-path approach for generating SQL query candidates, which enhances diversity and improves the chances of generating correct queries. The framework achieves state-of-the-art results on the BIRD benchmark, indicating the effectiveness of the proposed methods in real-world applications.",
    "candidate_b_text": "CHASE-SQL is positioned as an incremental advance in the LLM-based Text-to-SQL field, building on modular, multi-agent, and decomposition-based frameworks such as CHESS, DIN-SQL, MCS-SQL, and SQL-PaLM. Its main contributions—multi-path candidate generation, single-call divide-and-conquer decomposition, execution-plan-based reasoning, instance-aware synthetic examples, and a fine-tuned LLM for pairwise candidate selection—are primarily refinements or specific orchestrations of strategies already present in prior work. The submission tends to overstate the conceptual novelty of its methods, often lacking direct technical or empirical comparisons to the most similar existing approaches, and sometimes understates the degree of overlap with related research. Reported empirical gains may result from cumulative improvements in orchestration and prompt engineering rather than any single novel component. Overall, CHASE-SQL’s value lies in its effective integration and engineering of established techniques, rather than in introducing fundamentally new concepts to the field.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {}
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 41
  },
  {
    "id": 85,
    "paper_id": "aueXfY0Clv",
    "reference_text": "The proposed Depth Pro model employs a ViT architecture for zero-shot metric monocular depth estimation, targeting applications such as novel view synthesis. While Depth Pro benefits from pretrained ViT backbones, its architecture primarily builds on existing elements rather than introducing fundamentally new mechanisms for depth estimation, which limits its architectural novelty. The paper introduces a two-stage training approach that integrates synthetic and real-world datasets, enhancing depth boundary accuracy, and includes new metrics for evaluating depth boundaries that address a gap in existing benchmarks by focusing on boundary precision, which is critical for applications like view synthesis that demand fine details.",
    "candidate_a_text": "This paper proposes a new method for zero-shot monocular depth estimation that is efficient, fast and accurate, and is also capable of predicting metric-scale depth, which is a challenging task. The experiments demonstrate the superiority of the proposed method over the existing methods.",
    "candidate_b_text": "Depth Pro is presented as a foundation model for zero-shot, high-resolution, metric monocular depth estimation without requiring camera intrinsics, emphasizing sharp boundaries and fast inference. While the submission claims several firsts—including zero-shot focal length estimation and new boundary evaluation metrics using matting datasets—many of these contributions are incremental extensions or empirical integrations of strategies already present in recent works such as UniDepth, DMD, Metric3D v2, PatchFusion, PatchRefiner, and SM4Depth. The main substantive advance appears to be the combination of speed, sharpness, and metric accuracy in a single model, with the use of matting datasets for boundary evaluation being a modest but useful addition. However, the claim of being the \"first foundation model\" for this problem is overstated, as several recent models address similar challenges, sometimes with different technical means. Reviewers should recognize Depth Pro as a strong empirical advance within a rapidly evolving field, but should calibrate novelty claims in light of the incremental nature of most contributions and the omission of some highly relevant prior work.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 2,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {
        "consensus_review": 2,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "2": {
            "2": true,
            "3": true
          },
          "3": {
            "2": true,
            "3": true
          }
        },
        "agreement_scores": {
          "2": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 45
  },
  {
    "id": 64,
    "paper_id": "A72sZWB66Q",
    "reference_text": "This paper presents HyperDet, a novel and generalizable detection framework designed to effectively identify synthetic images by integrating shared knowledge from lightweight expert detectors and leveraging a large pretrained vision model. I find the approach novel, particularly in its incorporation of hypernetworks that generate optimized weights for specialized LoRA experts, which enhances the extraction of generalized discernible artifacts. The authors also propose an SRM filter grouping strategy to capture varying levels of pixel artifacts and introduce a novel objective function to balance pixel and semantic artifacts. However, I note that the claimed novel objective function is simply a weighted sum of the binary cross-entropy loss of the original image and the filtered image.",
    "candidate_a_text": "This paper presents a novel approach to detecting synthetic images by introducing the HyperDet framework, which leverages a collection of expert detectors and a hypernetwork to generate optimized weights for LoRA models, enhancing the detection of artifacts in images generated by various generative models. The paper introduces a novel approach by combining SRM filters with a hypernetwork to generate optimized LoRA weights, which is a creative solution to enhance the detection of synthetic images. HyperDet achieves state-of-the-art performance on the UnivFD and Fake2M datasets, demonstrating its effectiveness in distinguishing synthetic images across different generative models.",
    "candidate_b_text": "HyperDet is an incremental advance in the field of AI-generated image detection, building most directly on the MoLE paradigm by introducing a hypernetwork to generate and merge LoRA weights for expert detectors—a technical extension rather than a conceptual leap. While the use of a hypernetwork for LoRA weight generation is new in this context, other contributions such as grouping SRM filters and balancing pixel/semantic objectives are routine adaptations of established ideas. The empirical results show strong performance gains, but these may be attributable to ensembling and large-scale training rather than the specific hypernetwork mechanism. The authors’ characterizations of prior work are generally accurate, though they somewhat overstate the novelty and omit several recent, relevant feature fusion and hierarchical detection methods. Reviewers should recognize HyperDet as a solid technical extension with notable empirical results, but not as a fundamentally new direction in the field.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "3": true
          },
          "3": {
            "0": true,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 43
  },
  {
    "id": 77,
    "paper_id": "QipLSeLQRS",
    "reference_text": "This paper proposes reinforcement learning from hindsight simulation (RLHS) as a method to improve preference labeling for large language model (LLM) outputs by simulating plausible downstream consequences of LLM responses and presenting these, alongside the original outputs, to human labelers. While the problem addressed—ensuring that LLM outputs are evaluated based on their real-world impact rather than immediate surface-level appeal—is important and potentially underexplored, it is not new. The central insight that the utility of an AI system’s output is determined by its real-world consequences rather than intrinsic properties has already been explored in prior work, notably by Lang et al., as cited by the authors. As such, neither the problem setting nor this insight constitutes a novel contribution. The proposed solution of simulating outcomes and providing them to preference labelers appears, to the best of my knowledge, not to have been directly explored in previous academic papers, but it represents only an incremental advance. The approach does not introduce new algorithmic developments or theoretical findings, relying instead on LLM prompting to supply additional context to labelers. Given the lack of novelty in the problem framing, the incremental nature of the proposed solution, and the absence of strong empirical or theoretical results, I do not find the paper’s contributions to be significant or original enough to advance the field. Overall, while RLHS is a potentially interesting direction, the current work does not demonstrate sufficient novelty in either its problem setting or its proposed methodology.",
    "candidate_a_text": "This assessment reviews RLHS, a method that introduces simulated hindsight feedback to address misalignment issues (such as sycophancy and reward hacking) in LLM alignment, positioning it as a novel extension of RLHF, DPO, and RLAIF. The main technical contribution is the adaptation of hindsight simulation—previously established in dialog and robotics RL—to the domain of LLM preference optimization, which is a meaningful but not fundamentally new conceptual advance. While empirical results show reduced misalignment compared to RLHF, DPO, and RLAIF, the attribution of these gains specifically to hindsight simulation is not fully isolated from other implementation factors. The submission overstates its conceptual novelty by not citing relevant hindsight/simulation work in other RL domains, and some contributions (e.g., compatibility with PPO/DPO, Goodhart’s law analysis) are routine extensions rather than core innovations. Reviewers should recognize the substantive domain adaptation as the main delta, but weigh the omission of related RL literature and the incremental nature of the advance when assessing novelty and significance.",
    "candidate_b_text": "The paper introduces Reinforcement Learning from Hindsight Simulation (RLHS), a novel approach to mitigate misalignment in RLHF by focusing on the downstream consequences of AI actions. It identifies a critical issue in existing RLHF approaches and proposes a novel solution that is both well-reasoned and effectively presented. The results demonstrate that RLHS outperforms traditional RLHF methods in terms of user satisfaction and true utility, which is a significant contribution to the field. The reduction in misalignment and deception is particularly noteworthy and has important implications for the development of more trustworthy AI systems.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {}
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 23
  },
  {
    "id": 46,
    "paper_id": "icUCCz8pAu",
    "reference_text": "This paper introduces MultiTrust, a framework designed to enhance the safety and trustworthiness of large language models (LLMs) from multiple perspectives, including robustness, fairness, and truthfulness. MultiTrust integrates adversarial training data generation, safety auxiliary models, and an inference-time, perplexity-based routing mechanism to dynamically align base LLMs with specialized safety models, enabling the system to address several safety concerns in parallel without sacrificing general task performance. While the paper presents a novel multi-perspective approach to LLM safety by moving beyond the conventional focus on isolated safety aspects, the technical novelty of MultiTrust is somewhat limited. Both the use of synthetic data generation and inference-time routing mechanisms have been established in prior work, and the framework largely appears as a combination of these existing approaches rather than introducing substantial innovation in either area. Although the modular integration and dynamic alignment of models represent a flexible and scalable solution, the specific advances over previous methods are not sufficiently clear, and the contribution may be viewed as a relatively straightforward application of known techniques rather than a significant step forward in the field. The paper would benefit from more clearly articulating the unique aspects of its approach and providing a stronger justification for its novelty relative to established methods.",
    "candidate_a_text": "**Summary for Reviewer:**\n\nThe submission, *MultiTrust*, adapts established techniques—modular, inference-time model fusion (as in PackLLM), dynamic routing (inspired by Capsule Networks), and preference-based alignment (DPO, as in GRATH)—to the domain of LLM safety and trustworthiness, focusing on robustness, fairness, and truthfulness. Its main technical novelty lies in applying perplexity-based dynamic routing and modular fusion to safety model selection and combination, enabling flexible augmentation with new safety perspectives at inference time. However, the underlying mechanisms are not new, and the submission does not fully acknowledge conceptual overlap with PackLLM (for routing/fusion) or GRATH (for DPO-based alignment), potentially overstating its novelty. Empirical contributions include demonstrating DPO's effectiveness for safety alignment across multiple perspectives and observing cross-perspective data transfer effects, but these are incremental extensions of prior work. Overall, the work represents a reasonable integration of known methods into a new application area, but reviewers should be aware that its primary contribution is in domain adaptation and system integration rather than methodological innovation.",
    "candidate_b_text": "This paper introduces MultiTrust, a framework designed to enhance the safety and trustworthiness of Large Language Models (LLMs) across multiple dimensions, including robustness, fairness, and truthfulness. MultiTrust addresses safety and trustworthiness from multiple angles, providing a holistic approach that enhances the model's reliability in various aspects. The perplexity-based routing mechanism allows for dynamic adaptation to different safety perspectives, enabling efficient and context-specific model alignment without additional training. The framework maintains the base LLM's performance while improving trustworthiness, ensuring that the model's general capabilities are not sacrificed for safety improvements.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {}
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 45
  },
  {
    "id": 97,
    "paper_id": "obYDlJN0oU",
    "reference_text": "This paper introduces Massively Multi-Agents Role Playing (MMARP), a framework that leverages the collective responses of numerous simulated language model agents, each assigned distinct roles such as buyer or seller, to improve stock price prediction by modeling market dynamics through aggregated agent behavior. While the application of large language models (LLMs) in a market simulation context is creative, the approach demonstrates limited novelty. Similar methods have already employed LLMs in agent-based financial simulations with more sophisticated trading mechanisms, as seen in Gao et al. (2024). In contrast, the MMARP framework primarily restricts LLM agents to providing binary responses (e.g., labeling prices as cheap or expensive), which contributes minimal additional depth or innovation to the simulation of financial markets. As such, the main contribution appears incremental, and the paper does not substantially advance the state of the art in agent-based financial modeling with LLMs.",
    "candidate_a_text": "The paper proposes a Massively Multi-Agents Role Playing (MMARP) framework to simulate market dynamics using LLMs, leveraging theory-driven prompt designs and LLM-generated weights to address challenges in simulating market behavior. The paper proposes a new method to simulate market dynamics using LLMs, which is a unique approach in the field of financial modeling. However, the paper lacks a thorough comparison with existing financial market simulation models, providing only limited mention of traditional deep-learning models and LLM-based methods without a detailed analysis of how MMARP outperforms or differs from these models in terms of accuracy, computational efficiency, or applicability to real-world scenarios.",
    "candidate_b_text": "This assessment finds that the submission (MMARP) is an incremental but meaningful advance within the rapidly evolving field of LLM-based multi-agent financial market simulation. Its main technical novelty is a quantitative intersection method for price discovery using theory-driven prompts and aggregate LLM agent responses, which is more systematic than prior aggregation approaches but not a conceptual leap. The work distinguishes itself by providing more rigorous, quantitative evaluation of simulation accuracy (forecasting and profitability) compared to earlier, often more qualitative, agent-based LLM studies. However, the authors tend to overstate their novelty—especially claims of being the “first” to rigorously investigate LLM agent validity—while understating the quantitative elements present in related works. Overall, MMARP’s primary contribution is in methodological refinement and evaluation rigor, rather than in introducing a fundamentally new simulation paradigm.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {}
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 22
  },
  {
    "id": 26,
    "paper_id": "Rp3DjldbSc",
    "reference_text": "This paper introduces a conversational search dataset, ICConv, and its construction method, highlighting the novel approach of considering multiple intents within a single keyword-based query. Authors point out that ConvTrans neglected that “keyword-based query usually corresponds to multiple natural language queries under different intents”, which is an important claim to support the significance of the proposed method. Both ConvTrans and ICConv are generated by extending keywords to NL and CNL questions with T5. While the key novelty of the proposed method is generating multi-intent questions via concatenating responses as inputs (section 3.2.2) and filtering the path (section 3.4), the novelty of the other components is minimal.",
    "candidate_a_text": "The paper presents a new dataset for conversational search, which is a large-scale and high-quality dataset. However, the motivation for creating the dataset is not clear, as the paper mentions that previous datasets for conversational search either overlook the multi-intent problem and contextual information or create a biased dataset where all queries in a conversation are related to a single positive passage, but it is not clear how the proposed dataset addresses these issues. The paper does not provide any analysis or evidence to support the claim that the proposed dataset is not biased and takes the contextual information into account. Additionally, the paper does not provide any comparison between the proposed dataset and previous datasets for conversational search, so it is not clear how the proposed dataset is different from previous datasets and how it can benefit the research community.",
    "candidate_b_text": "This paper presents ICConv, a large-scale conversational search dataset comprising over 100k conversations generated through an automated pipeline, aiming to address gaps in existing datasets by accommodating multiple user intents and integrating contextual dependencies across dialogue turns. While the authors claim that their method is \"novel,\" they do not provide a statistical comparison between the features of their dataset and those of other conversational search datasets, nor do they explicitly explain how their approach differs from previous works, such as recent research [4] that also trains smaller models to simulate user-engine interactions with more rigorous workflows and metrics for quality control. The unique contributions and novel aspects of this dataset remain unclear, especially since the paper does not clarify what specifically makes the dataset more \"real-world\" or complex compared to prior datasets, and lacks concrete examples, illustrations, or comparisons to demonstrate these advantages. The authors should better articulate their distinct contributions and novel aspects to more convincingly establish the originality and significance of their work.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "Human Review 3",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 3,
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 0.5,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          3,
          4
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "3": false,
            "4": true
          },
          "3": {
            "0": false,
            "3": true,
            "4": false
          },
          "4": {
            "0": true,
            "3": false,
            "4": true
          }
        },
        "agreement_scores": {
          "0": 0.5,
          "3": 0.0,
          "4": 0.5
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 47
  },
  {
    "id": 74,
    "paper_id": "bgcdO9lmug",
    "reference_text": "This paper proposes an approach for automatic prompt engineering in scenarios where end evaluation is expensive or infeasible, leveraging intermediate feedback and a step-by-step process that incorporates chat history, reflections, and internal LLM evaluation to iteratively improve prompts. While the authors claim that their method introduces a “summarization-based” mechanism for prompt improvement at each step, this core idea closely mirrors the Reflexion framework introduced by Shinn et al. (2024) [1], which also utilizes summarization to guide prompt refinement. The novelty of the proposed approach is therefore unclear, as the main distinction appears to be its application of Reflexion to the automatic prompt engineering (APE) setting, rather than a fundamentally new technique. Furthermore, Reflexion itself has known limitations, particularly its reliance on ReAct for exemplar-query similarity, as discussed by Verma et al. (2024) [2]. The current manuscript does not sufficiently clarify how its approach differs from or extends Reflexion beyond this application context. As such, the contribution seems to be primarily an adaptation of existing methods rather than a novel algorithmic advance. The paper would benefit from explicitly articulating the differences from prior work and clearly stating whether its main contribution is the application of Reflexion to APE, which may still be a novel use case but should be presented transparently.",
    "candidate_a_text": "This paper proposes a new method for automatic prompt engineering (APE) called RePrompt, which optimizes step-by-step instructions in prompts for LLM agents using intermediate feedback from interactions and reflections. The paper does not compare RePrompt with other APE methods, making it hard to assess its relative performance, and the contributions are not well-organized.",
    "candidate_b_text": "This paper introduces REPROMPT, an innovative method for automatic prompt optimization in Large Language Model (LLM) agents, particularly in complex reasoning tasks where a final solution checker is not readily available. I find several aspects of this paper to be particularly strong. First, the core idea of REPROMPT, which is to optimize prompts through an iterative process based on interaction history, is both novel and well-motivated. This approach addresses a critical limitation of existing automatic prompt engineering (APE) methods that rely on a final solution checker, which is often unavailable in complex reasoning tasks. The analogy to 'gradient descent' is intuitive and helps to understand the iterative refinement process. The use of an LLM as a summarizer to extract key insights from interaction histories is a clever way to guide prompt optimization. Overall, the paper presents a novel approach to automatic prompt engineering that addresses a significant challenge in the field of LLM agents, offering a method that can iteratively improve prompts without relying on a final solution checker. The ability to automatically optimize prompts for these tasks has the potential to significantly enhance the capabilities of LLM agents in real-world applications.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: deepreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "deepreviewer",
      "consensus_info": {}
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 48
  },
  {
    "id": 95,
    "paper_id": "lBrLDC7qXF",
    "reference_text": "This paper introduces the CAB-KGC (Context-Aware BERT for Knowledge Graph Completion) model, which presents a novel approach by leveraging the contextual information of neighboring entities and relationships without relying on entity descriptions or negative triplet sampling, a common limitation in previous KGE and LLM-based methods. This removes the dependency on external textual information, making it applicable to a wider variety of KGs, especially those that lack entity descriptions, and leads to more efficient training and improved evaluation performance. However, the innovation in this work seems incremental, as it mainly builds on the SimKGC framework, with the only major difference in the CAB-KGC model being that it does not require head entity descriptions and employs a classification loss (cross-entropy) instead of contrastive loss for training. The introduction of the EDAS criterion also has the potential to influence future performance evaluation practices in the knowledge graph domain.",
    "candidate_a_text": "CAB-KGC is an incremental extension of recent PLM-based knowledge graph completion (KGC) models, primarily distinguished by its elimination of negative sampling and strict avoidance of entity descriptions, relying solely on structural context for tail prediction. While the authors claim novelty in context integration, several recent models (e.g., CSProm-KG, StAR, NNKGC) also incorporate KG structure/context, making CAB-KGC’s main difference one of implementation detail rather than conceptual advance. The introduction of the EDAS evaluation metric is a useful addition, but similar motivations for improved evaluation have been addressed in other recent work. The paper reports state-of-the-art results, but the attribution of improvements to specific innovations is not fully disentangled, and the field is characterized by frequent, incremental advances. Overall, CAB-KGC is a well-executed synthesis of current trends, but its novelty is moderate, and the paper would benefit from a more thorough and balanced comparison to recent structure-aware and prompt-based KGC models.",
    "candidate_b_text": "This paper proposes a novel KGE model, namely Context-Aware BERT for Knowledge Graph Completion (CAB-KGC), which utilizes contextual information from linked entities and relations within the graph to predict tail entities and eliminates the need for entity descriptions and negative triplet sampling. However, the novelty is limited, as the proposed method is quite similar to the well-known entity2vec, which also uses the surrounding entities and relationships of the head entity as contextual information to represent the entity; the primary difference is the use of BERT to encode the context rather than an encoder as in entity2vec. It is therefore necessary to explain the novelty of the proposed method. Additionally, the proposed EDAS criterion is a direct application of the EDAS method to KGE, and thus the contribution is limited.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "ours",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 1.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          3,
          4
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "3": true,
            "4": true
          },
          "3": {
            "1": true,
            "3": true,
            "4": true
          },
          "4": {
            "1": true,
            "3": true,
            "4": true
          }
        },
        "agreement_scores": {
          "1": 1.0,
          "3": 1.0,
          "4": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 10
  }
]