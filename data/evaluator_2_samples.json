[
  {
    "id": 98,
    "paper_id": "A72sZWB66Q",
    "reference_text": "This paper presents HyperDet, a novel and generalizable detection framework designed to effectively identify synthetic images by integrating shared knowledge from lightweight expert detectors and leveraging a large pretrained vision model. I find the approach novel, particularly in its incorporation of hypernetworks that generate optimized weights for specialized LoRA experts, which enhances the extraction of generalized discernible artifacts. The authors also propose an SRM filter grouping strategy to capture varying levels of pixel artifacts and introduce a novel objective function to balance pixel and semantic artifacts. However, I note that the claimed novel objective function is simply a weighted sum of the binary cross-entropy loss of the original image and the filtered image.",
    "candidate_a_text": "This paper presents HyperDet, a novel and effective framework for detecting synthesized images with high generalization capabilities. While the proposed method combines low-level and semantic features and uses a mixture of experts (MoE) for selection, the paper lacks sufficient motivation and insight into why this combination is novel and significant. Simply combining existing techniques without providing a compelling rationale or analysis of the advantages over prior work may not meet the bar for novelty and significance required by ICLR.",
    "candidate_b_text": "HyperDet is an incremental advance in the field of AI-generated image detection, building most directly on the MoLE paradigm by introducing a hypernetwork to generate and merge LoRA weights for expert detectors—a technical extension rather than a conceptual leap. While the use of a hypernetwork for LoRA weight generation is new in this context, other contributions such as grouping SRM filters and balancing pixel/semantic objectives are routine adaptations of established ideas. The empirical results show strong performance gains, but these may be attributable to ensembling and large-scale training rather than the specific hypernetwork mechanism. The authors’ characterizations of prior work are generally accurate, though they somewhat overstate the novelty and omit several recent, relevant feature fusion and hierarchical detection methods. Reviewers should recognize HyperDet as a solid technical extension with notable empirical results, but not as a fundamentally new direction in the field.",
    "candidate_a_label": "Human Review 3",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": 3,
      "candidate_a_type": "human",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "3": true
          },
          "3": {
            "0": true,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 0
  },
  {
    "id": 40,
    "paper_id": "PYmrUQmMEw",
    "reference_text": "This paper introduces LLaMA-Omni, an end-to-end model architecture designed for low-latency, high-quality speech interaction with large language models (LLMs), and presents InstructS2S-200K, a large dataset of conversational, oral-style speech instructions and responses to support more natural speech-based dialogue. While the InstructS2S-200K dataset addresses a notable gap in conversational speech instruction data, the novelty of the model architecture itself is limited. The proposed system primarily combines existing components—namely, a pre-trained speech encoder, a speech adaptor, an LLM, and a streaming speech decoder—without a clear breakthrough in architectural design. Specifically, connecting a speech encoder to an LLM via a speech adaptor has been widely explored in prior research, and the streaming TTS module closely follows previous designs, particularly the approach outlined in Fang et al. (2024) [1]. As such, although LLaMA-Omni successfully assembles a functional pipeline for speech-based interactions with LLMs, it largely builds upon established methods and does not deliver significant innovation in model design. This reliance on prior work somewhat limits the paper’s impact from a research innovation standpoint, and further clarification of the unique contributions would be necessary to better establish its novelty.",
    "candidate_a_text": "LLaMA-Omni is positioned within the rapidly evolving field of end-to-end, low-latency speech interaction models that integrate LLMs with streaming speech processing, closely related to recent works like Mini-Omni and Moshi. While the authors claim novelty in eliminating intermediate transcription and enabling simultaneous text and speech generation, these features are already present in the most relevant prior art, making the conceptual advances largely incremental. The main technical distinction is the use of a CTC-based non-autoregressive streaming decoder with a LLaMA backbone, along with notable resource efficiency, though these improvements may stem from implementation choices rather than fundamental innovation. The introduction of the InstructS2S-200K dataset is a useful contribution, but similar datasets exist and direct comparisons are lacking. Overall, the submission is a strong instantiation of current trends, but its core contributions should be more rigorously contextualized against closely related recent works, as the claimed novelty is often overstated and the technical delta is modest.",
    "candidate_b_text": "This paper introduces LLama-Omni, an innovative end-to-end model architecture for real-time speech interaction with large language models (LLMs). The method is similar to previous work such as SALMONN, except for the TTS module, which is replaced by a vocoder in this study. However, the authors do not sufficiently discuss the differences between the proposed method and SALMONN.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {}
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 1
  },
  {
    "id": 42,
    "paper_id": "pbDqZBn2X2",
    "reference_text": "This paper proposes a cost-aware diffusion solver (CADO) for combinatorial optimization and a fine-tuning framework based on reinforcement learning for diffusion models in this domain. To the best of my knowledge, current techniques using diffusion models as well as RL fine-tuning are not common in combinatorial optimization, and this paper provides a detailed open-source implementation that serves as a baseline for subsequent similar studies. However, the innovation of the method is relatively low; the method of training and fine-tuning is very simple, which is slightly lacking as the innovation point of this paper. I do not see the authors' approach as a significant change from existing algorithms based on reinforcement learning fine-tuning. The method of supervised learning and fine-tuning is more like a trick than sufficient to support the innovation of the article, and taking feasible punishment and optimization goal as reinforcement learning reward is a very simple idea in the field of combinatorial optimization. There is no obvious groundbreaking in addressing the difficult problems in combinatorial optimization, and I am still not sure why this framework is necessary or what necessary adjustments have been made to ensure its applicability to combinatorial optimization problems.",
    "candidate_a_text": "The paper introduces CADO, a framework that combines supervised learning (SL) pre-training and reinforcement learning (RL) fine-tuning for large-scale combinatorial optimization (CO) problems. However, the novelty of the proposed approach is limited, as it combines existing techniques in a straightforward way. The use of RL for fine-tuning is not new, and the paper does not provide a clear motivation for why this particular combination of SL and RL is superior to other possible approaches.",
    "candidate_b_text": "This paper proposes a new Cost-Aware Diffusion solver for combinatorial Optimization (CADO) method via RL finetuning. Overall, the method is really simple, and lacks a strong sense of novelty. In two-phase training, the first phase is the same as DIFUSCO, and the second phase is just adoption of the existing decoder and RL algorithm. The proposed method incorporates the cost information and the decoder, which enhance the overall performance with significant efficacy, but the approach does not present a substantial departure from existing methods.",
    "candidate_a_label": "AI System: deepreviewer",
    "candidate_b_label": "Human Review 3",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 2,
      "candidate_a_system": "deepreviewer",
      "candidate_a_type": "ai",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 3,
      "consensus_info": {
        "consensus_review": 2,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "2": {
            "2": true,
            "3": true
          },
          "3": {
            "2": true,
            "3": true
          }
        },
        "agreement_scores": {
          "2": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 2
  },
  {
    "id": 47,
    "paper_id": "e8c7XDRJcg",
    "reference_text": "The paper presents three methods to perform Unsupervised Modality Adaptation (UMA): Student-Teacher (ST), Contrastive Alignment (CA), and Cross-modal Transfer Through Time (C3T). Unsupervised Modality Adaptation is frequently used for cross-modal learning in many applications and cannot be regarded as a new contribution of this paper. Compared to ST and CA, the Cross-modal Transfer Through Time (C3T) performs pseudo label generation and alignment in temporal sequences, while other operations, including feature learning, RGB-IMU alignment, and classification, follow the same procedures, so the novelty of the proposed method needs to be reconsidered. The experiment comparison is not reliable since the proposed approach is not compared with related frameworks, and there are many existing works as listed in Section 2. I suggest considering refining the key innovations and redefining the key representations for innovation.",
    "candidate_a_text": "The paper investigates an unsupervised modality adaptation method for the action recognition model, proposing Cross-modal Transfer Through Time (C3T), which performs alignment on each temporal step rather than on video-level feature representation as in Contrastive Alignment (CA). The novelty is minor, which is only on doing the alignment per temporal step, without proposing a new alignment method or an architectural change to current state-of-the-arts. The lack of state-of-the-art comparison also makes it hard to justify the significance of the novelty besides its improvement upon Student-Teacher (ST) and CA methods.",
    "candidate_b_text": "This assessment finds that the submission addresses Unsupervised Modality Adaptation (UMA) for Human Action Recognition (HAR), formalizing a strict setting where no target modality labels are available during training—a meaningful but incremental specialization over prior cross-modal transfer work. The proposed C3T method combines contrastive alignment and teacher-student paradigms, introducing temporal convolutions and shared self-attention for cross-modal temporal alignment; however, these are technical variations rather than fundamentally new concepts, as similar mechanisms exist in prior transformer-based models. The authors’ claims of novelty are somewhat overstated, particularly regarding the unexplored nature of UMA and the assertion that all prior methods require labeled data in both modalities, since some recent works (e.g., IMU2CLIP, ImageBind) do support unsupervised or zero-shot transfer. The strongest differentiation lies in the explicit formalization and systematic evaluation of UMA in HAR, as well as the robustness analysis to temporal noise, though empirical gains may stem from implementation details rather than conceptual advances. Overall, the submission is well-situated within the evolving literature on cross-modal transfer and multimodal HAR, but its technical contributions are incremental, and a more nuanced comparison to closely related works is warranted.",
    "candidate_a_label": "Human Review 3",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": 3,
      "candidate_a_type": "human",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "3": true
          },
          "3": {
            "1": true,
            "3": true
          }
        },
        "agreement_scores": {
          "1": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 3
  },
  {
    "id": 85,
    "paper_id": "N2sN3LESoW",
    "reference_text": "This paper identifies that the binary format of RLHF data labels fails to reflect the actual pairwise difference of human preference and proposes to weight the pairwise samples with respect to the semantic gap in order to provide supervision signals beyond binary labels. The proposed method is simple and has a clear connection to related works. The data-dependent margin and beyond-binary motivation is a good direction for preference optimization, however what the paper presents doesn't fully exploit the potential, as there can be a much wider spectrum of margins that more faithfully match the motivation, such as length difference or response-level LM embedding distance. A more comprehensive study over these options may bring in further contribution in this direction and potentially address the non-improvement for Arena-Hard and MT-Bench.",
    "candidate_a_text": "In this work, the authors propose Gap-Aware Preference Optimization (GaPO), a novel approach that integrates the degree of semantic gaps into preference optimization. Results on different datasets show that GaPO could surpass existing methods, including DPO and SimPO. When GaPO is combined with the scale norm, a hyperparameter γ is introduced, which is considered the contribution from SimPO, making it difficult to evaluate the independent validity of EF.",
    "candidate_b_text": "This paper introduces Gap-Aware Preference Optimization (GaPO), which I find to be a novel and well-motivated approach to preference optimization. The authors correctly identify a key limitation of traditional RLHF methods—their reliance on binary labels that fail to capture nuanced differences in human preferences—and address this by incorporating the degree of semantic gaps into the loss function. GaPO provides a more granular supervisory signal, allowing the model to better understand and reflect the subtleties of human perception, which is a significant contribution that addresses a critical challenge in the field. The method is differentiated from prior work by explicitly quantifying the semantic gap using metrics such as Jaccard Score, ROUGE, and BERTScore, and using this as a basis for loss margin adjustment rather than binary labels. My assessment is that the introduction of GaPO represents a strong and original contribution, particularly in its empirical demonstration of surpassing existing state-of-the-art methods on widely used benchmarks such as AlpacaEval 2.0, with GaPO-ROUGE_L achieving a notable win rate. The paper’s thorough exploration of different forms of the loss function and mapping functions, as well as its analysis of various evaluation metrics, further supports the distinctiveness and robustness of the proposed approach. Overall, the combination of a novel method, its strong empirical results against leading baselines, and its focus on addressing a key shortcoming in preference optimization underscores the significance of the contribution.",
    "candidate_a_label": "Human Review 2",
    "candidate_b_label": "AI System: deepreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": 2,
      "candidate_a_type": "human",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "deepreviewer",
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 0.6666666666666666,
        "num_reviews": 4,
        "consensus_type": "majority",
        "other_reviews": [
          0,
          2,
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": true,
            "2": false,
            "3": false
          },
          "1": {
            "0": true,
            "1": true,
            "2": true,
            "3": false
          },
          "2": {
            "0": false,
            "1": true,
            "2": true,
            "3": false
          },
          "3": {
            "0": false,
            "1": false,
            "2": false,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 0.3333333333333333,
          "1": 0.6666666666666666,
          "2": 0.3333333333333333,
          "3": 0.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 4
  },
  {
    "id": 18,
    "paper_id": "jCNRcHrfLo",
    "reference_text": "This paper introduces a novel approach, Hierarchical Prompts with Context-Aware Calibration (HiCA), to enhance Open Vocabulary Object Detection (OVD). HiCA improves generalization by utilizing hierarchical prompts that map object regions through both coarse- and fine-grained knowledge, capturing shared information across base and novel classes. Additionally, context-aware calibration refines detection by linking contextual information with object categories, reducing background interference. Despite the emphasis on enhancing detection for novel classes in OVD, the improvement shown in Tables 1 and 4 is relatively minor, and most modifications do not outperform simpler, template-based methods for novel classes, which raises concerns about the practicality and overall impact of the proposed approach for new class detection.",
    "candidate_a_text": "This paper proposes hierarchical prompts with context-aware calibration (HiCA) for open-vocabulary object detection, leveraging both coarse-grained superclass knowledge and fine-grained category knowledge to improve generalization to novel classes while utilizing the visual context of the image to enhance these effects. However, I find that the proposed hierarchical prompts method is quite similar to the learnable multi-modal prompts method in [1], where multiple learnable text tokens are also used to prompt the text encoder for generating text embeddings. While the authors do not use learnable visual prompts as in [1], I still think the proposed hierarchical prompts method is an incremental work based on [1]. The originality of the method appears limited by this similarity, and a comparison experiment with [1] is necessary to better establish the specific contribution.",
    "candidate_b_text": "The submission introduces HiCA, a method for open-vocabulary object detection that combines explicit hierarchical prompts (superclass/class) with context-aware calibration via unsupervised visual context clustering and a distribution generation layer, all within a prompt learning framework. While the technical implementation—particularly the use of hierarchical prompts and unsupervised context clustering for calibration—is novel, the underlying conceptual ideas of leveraging semantic hierarchies and contextual information are well-established in recent literature (e.g., HierKD, DetCLIPv3, HTRPN). The authors tend to overstate their novelty, underrepresenting the sophistication and relevance of prior work that already integrates hierarchy and context, albeit through different mechanisms such as distillation or generative modeling. The main delta lies in the specific combination and technical realization of these ideas within prompt learning, rather than in a fundamentally new conceptual advance. Reviewers should note that, in this mature and rapidly evolving field, most recent contributions—including this one—are incremental and technical, and direct comparison to the most relevant recent works is needed to fairly assess the true contribution.",
    "candidate_a_label": "AI System: deepreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "deepreviewer",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 0.5,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          1,
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": false,
            "3": true
          },
          "1": {
            "0": false,
            "1": true,
            "3": false
          },
          "3": {
            "0": true,
            "1": false,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 0.5,
          "1": 0.0,
          "3": 0.5
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 5
  },
  {
    "id": 78,
    "paper_id": "uuvujfQXZy",
    "reference_text": "This paper proposed a novel type of CBM called UCBM, which utilizes concept discovery methods to discover concepts learnt by pretrained, black-box models and convert them into CBM. The paper proposed an unsupervised concept discovery mechanism for CBMs, which is novel in the field of CBM, as the method does not need pre-defined concept sets. Additionally, a novel input-dependent concept selection mechanism is proposed to dynamically retain a sparse set for prediction; however, the idea of input-dependent concept selection is not novel, as, for example, Panousis et al. (2023) introduced a binary latent indicator to dynamically select activating concepts according to input embedding and mask out other concepts. I agree that the introduction of unsupervised concept discovery into CBM is interesting, but the missing of text representation limits the novelty.",
    "candidate_a_text": "This paper proposes learning post-hoc Concept Bottleneck Models (CBMs) in an unsupervised manner, using an unsupervised non-negative matrix factorization to discover concept vectors, an input-dependent alignment score selection, and a sparse linear layer for class prediction. Unlike previous methods, UCBMs do not assume a set of concepts learned by black-box models, but instead discover the concept vectors in an unsupervised manner. The idea of input-dependent sparsity constraint is interesting and non-trivial. However, the proposed method has limited novelty, as it uses an existing matrix decomposition method called CRAFT for feature generation, and the novelty is limited to proposing input-dependent selection applied before learning the sparse linear layer. The paper lacks comparisons with newer methods, particularly with [2], which trains a learnable dictionary to approximate the embedding space of VLMs in a supervised manner without using a pre-defined concept set.",
    "candidate_b_text": "This paper presents a novel approach to converting a black-box model into a concept bottleneck model (CBM) using unsupervised concept discovery, and proposes an input-dependent concept selection mechanism where only a sparse set of concepts relevant to the input are dynamically retained. The idea of using concept discovery for CBM is interesting and novel. However, the paper does not provide comparisons with other concept discovery methods such as [1], other methods that convert a black-box model into a CBM such as [2,3], or with CBMs trained from scratch, which limits the ability to fully assess the originality and significance of the contribution.",
    "candidate_a_label": "Human Review 1",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": 1,
      "candidate_a_type": "human",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 1.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          1,
          2
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": true,
            "2": true
          },
          "1": {
            "0": true,
            "1": true,
            "2": true
          },
          "2": {
            "0": true,
            "1": true,
            "2": true
          }
        },
        "agreement_scores": {
          "0": 1.0,
          "1": 1.0,
          "2": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 6
  },
  {
    "id": 87,
    "paper_id": "vwOq7twk7L",
    "reference_text": "The paper introduces a method for image-level memorization detection, motivated by an analysis showing two key characteristics of memorized images under perturbed inference: similarity discrepancy and a large magnitude of text-conditional noise prediction. The key idea of the method seems to be using an unconditional DDIM inversion to derive latent codes and optimizing non-memorized prompt embeddings for effective perturbation.",
    "candidate_a_text": "This paper presents a new method for identifying whether an image was part of the diffusion model training set, without access to the prompt used for generation. As far as the authors know, they are the first to identify this task. The authors propose for the first time to experiment with inference with perturbed prompts for the task at hand, and they introduce Inversion-based Inference Perturbation (IIP) as a novel method that out-performs competitors on an extensive test suite. However, regarding the novelty of the task, I note that [1] and [2] engage in membership inference without using prompts, as far as I know, and I ask the authors to clarify how their proposed task of image-level memorization detection differs from membership inference, particularly in light of the cited works that perform membership inference without prompts.",
    "candidate_b_text": "This paper proposes a method to detect if an image has been memorized by a diffusion model, even without knowing the prompt used to generate it. The problem of detecting memorized images without knowing the prompt is a novel and important problem. The proposed method is simple and effective, and the experiments show that it outperforms the baselines in all settings. The paper lacks a comparison with the method proposed by Wen et al. (2024) for detecting memorized prompts; it would be helpful to include a comparison with this method, both in terms of effectiveness and efficiency, to provide a more comprehensive evaluation of the proposed approach.",
    "candidate_a_label": "Human Review 2",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": 2,
      "candidate_a_type": "human",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 0.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          2,
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "2": false,
            "3": false
          },
          "2": {
            "0": false,
            "2": true,
            "3": false
          },
          "3": {
            "0": false,
            "2": false,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 0.0,
          "2": 0.0,
          "3": 0.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 7
  },
  {
    "id": 59,
    "paper_id": "XTxdDEFR6D",
    "reference_text": "This paper introduces LLM4Solver, a framework that leverages large language models (LLMs) to assist in algorithm design for combinatorial optimization, specifically targeting Mixed Integer Linear Programs. The approach involves using an LLM to generate algorithmic components in a programming language, which are subsequently refined through evolutionary algorithms. The authors claim that this method surpasses state-of-the-art human-designed and learning-based heuristics in terms of solution quality and efficiency across various benchmarks. However, the novelty of the approach appears limited, as similar uses of LLMs for algorithm design and optimization have already been explored in recent literature. Notably, works such as \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model,\" \"LLaMoCo: Instruction tuning of large language models for optimization code generation,\" \"LLaMEA: A large language model evolutionary algorithm for automatically generating metaheuristics,\" \"ReEvo: Large Language Models as Hyper-Heuristics with Reflective Evolution,\" \"Autonomous multi-objective optimization using large language model,\" and \"OptiMUS: Optimization Modeling Using MIP Solvers and large language models\" have addressed related ideas. While LLM4Solver demonstrates promising results, the core concept of prompting LLMs to generate code for optimization tasks is not particularly novel, and the paper primarily compares itself to the work of Kuang et al. without sufficiently situating its contributions relative to the broader body of recent work. The main contribution seems to be the specific integration of LLM-generated code with evolutionary refinement, but this incremental advance does not substantially differentiate the approach from existing methods. To more convincingly establish its novelty, the paper would benefit from expanded experimental comparisons and a clearer articulation of how its framework advances beyond prior LLM-based optimization techniques.",
    "candidate_a_text": "LLM4Solver applies the established paradigm of combining large language models (LLMs) with evolutionary search to the new domain of *exact* mixed-integer programming (MIP) solver algorithm design, evaluating on the challenging MIPLIB 2017 benchmark. While the methodology—LLM-driven code/algorithm generation with derivative-free optimization—is very similar to recent works like AEL, ReEvo, and AutoSAT, LLM4Solver’s main contribution is its focus on full solver algorithms for exact MIP, rather than heuristics or metaheuristics for routing or packing. The authors’ claims of being “first” are accurate for this specific application domain, but not for the general approach, and the distinction between “heuristic” and “algorithm” is sometimes overstated. Some relevant related works (e.g., DeepACO, Sym-NCO) are omitted, and the empirical gains may be partly attributable to benchmark choice. Overall, the work represents an incremental but well-executed advance in a rapidly evolving field, with its primary novelty in application scope rather than fundamental methodology.",
    "candidate_b_text": "This paper introduces LLM4Solver, a novel framework that leverages large language models (LLMs) to automatically design high-quality algorithms for combinatorial optimization (CO) solvers, specifically focusing on diving heuristics within branch-and-bound (B&B) algorithms. I find the core idea of using LLMs to generate algorithmic components for CO solvers to be both novel and promising, representing a significant achievement in demonstrating that LLMs can effectively tackle the complex task of algorithm design, which has traditionally been challenging for machine learning methods. Unlike many neural network-based approaches, LLM4Solver produces interpretable heuristics with code comments, making it easier for domain experts to understand and improve the underlying logic and search patterns, which I consider another major strength. The multi-objective extension of the framework, allowing for heuristics that generalize across different problem types, addresses a key limitation of many existing approaches and stands out as a valuable contribution. The empirical results compellingly demonstrate that LLM4Solver outperforms both human-designed heuristics and a state-of-the-art learning-based method in terms of solution quality, solving efficiency, and cross-benchmark generalization, with ablation studies showing the necessity of combining LLMs and evolutionary algorithms for high performance. Overall, I believe that this paper makes a significant contribution to the field of automated algorithm design and has the potential for significant impact, as the framework’s ability to generate high-quality, interpretable heuristics with improved generalization capabilities represents a substantial step forward.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: deepreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "deepreviewer",
      "consensus_info": {}
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 8
  },
  {
    "id": 75,
    "paper_id": "miIE56qM10",
    "reference_text": "This paper introduces an approach that trains an external lightweight model to mitigate inherent biases in LLMs, such as overconfidence and underconfidence. While the proposed model demonstrates enhanced performance and generalization capabilities across multiple models and datasets, the novelty is limited by the fact that existing work has explored training an external calibrator specifically for LLMs. The paper proposes a post-processing calibration method that requires task-specific training data, but the baselines used for comparison are confidence elicitation techniques (pre-processing methods) that do not require training data, making the comparison potentially unfair. Established post-processing techniques like isotonic regression, Platt scaling, and recalibration with Bayesian neural networks should be considered, and the authors should cite relevant work, include applicable baselines, and justify any inapplicable baselines.",
    "candidate_a_text": "This paper proposes a novel approach to uncertainty estimation in LLMs by training a corrector model to fix the miscalibration of logit-based uncertainty scores. The method is novel and addresses a significant challenge in uncertainty estimation for LLMs. The method can be integrated with various logit-based uncertainty methods, and the empirical results show consistent improvements on TriviaQA and SciQA.",
    "candidate_b_text": "This paper focuses on uncertainty estimation of LLMs and proposes to introduce an external corrector for refining uncertainty estimation, which is a Roberta-based regression model predicting a value added to the uncertainty score estimated by baselines. However, Liu et al. [3] generated their training set in a manner similar to this work and introduced a calibration mechanism to adjust logits, reducing the novelty of the proposed data construction process. Additionally, Ulmer et al. [4] propose an external model to estimate the confidence of LLM outputs, closely resembling the proposed method, which also trains an external model for confidence prediction. This potentially diminishes the novelty of the external corrector.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "Human Review 2",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "openreviewer",
      "candidate_a_type": "ai",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 2,
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 1.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          2,
          3
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "2": true,
            "3": true
          },
          "2": {
            "1": true,
            "2": true,
            "3": true
          },
          "3": {
            "1": true,
            "2": true,
            "3": true
          }
        },
        "agreement_scores": {
          "1": 1.0,
          "2": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 9
  },
  {
    "id": 70,
    "paper_id": "6akuzEqP38",
    "reference_text": "This paper proposes a novel pipeline that enables the creation of articulated objects from arbitrary input mesh, addressing a critical research gap in 3D generation for articulated objects and contributing to an increasingly important area. The main contribution is this pipeline that enables the generation of diverse articulated objects by taking arbitrary 3D mesh as input.",
    "candidate_a_text": "The submission \"ARTICULATE ANYTHING\" presents a novel pipeline that integrates open-vocabulary segmentation, LLM-based articulation estimation, and diffusion-based generative refinement to convert any rigid 3D mesh into an articulated object, distinguishing itself from prior works that address only subsets of this problem or are limited to closed-set categories. The main technical advances include the use of GPT-4o for direct joint parameter estimation from geometry and language, and a diffusion-based optimization strategy with random part transformations to preserve part semantics. While the integration of these components into a single, open-vocabulary, category-agnostic pipeline is a substantive contribution, the individual elements (segmentation, LLM reasoning, diffusion generation) are incremental extensions of existing methods, and some claims regarding the limitations of prior work are somewhat overstated. The authors' characterization of their novelty is generally accurate for the full pipeline, but less so for individual components, and the omission of some recent related works (e.g., OpenObj, Kinematic-aware Prompting) leaves the comparison incomplete. Overall, the work represents a significant step forward in open-vocabulary articulated object modeling, though its impact is primarily in the integration and scaling of recent advances rather than in fundamental algorithmic breakthroughs.",
    "candidate_b_text": "This paper proposes a pipeline to convert static meshes into articulated objects by first segmenting the object into parts using existing methods (Part123), estimating the joint parameters by prompting GPT-4o, and refining the model using a 2D diffusion model to recover the missing geometry. The main contribution of this work is the engineering effort to prompt GPT-4o for estimating joint parameters and recovering missing geometry using a 2D diffusion model. However, the proposed method heavily relies on the 3D segmentation method Part123 and the vision-language model GPT-4o, and the authors did not compare their method with other methods that predict joint parameters, such as ANCSH and OPD, or with other methods for recovering missing geometry, such as completing the contour, which is a common technique used in computer vision.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 0.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          2
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "2": false
          },
          "2": {
            "0": false,
            "2": true
          }
        },
        "agreement_scores": {
          "0": 0.0,
          "2": 0.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 10
  },
  {
    "id": 41,
    "paper_id": "aueXfY0Clv",
    "reference_text": "The proposed Depth Pro model employs a ViT architecture for zero-shot metric monocular depth estimation, targeting applications such as novel view synthesis. While Depth Pro benefits from pretrained ViT backbones, its architecture primarily builds on existing elements rather than introducing fundamentally new mechanisms for depth estimation, which limits its architectural novelty. The paper introduces a two-stage training approach that integrates synthetic and real-world datasets, enhancing depth boundary accuracy, and includes new metrics for evaluating depth boundaries that address a gap in existing benchmarks by focusing on boundary precision, which is critical for applications like view synthesis that demand fine details.",
    "candidate_a_text": "This paper presents a foundation model for zero-shot metric monocular depth estimation that is capable of producing metric depth maps with absolute scale on arbitrary images without requiring metadata such as camera intrinsics. The model's ability to produce metric depth maps with absolute scale on arbitrary images without requiring metadata such as camera intrinsics is a significant advancement in the field of monocular depth estimation. The high-resolution output and fast processing time make it suitable for real-time applications. The model's superior performance in sharp delineation of object boundaries and focal length estimation across multiple datasets demonstrates its robustness and accuracy.",
    "candidate_b_text": "This paper introduces a foundational model for single-image depth estimation, trained on a large collection of datasets, resulting in high-resolution depth maps with sharp object boundaries and enabling the estimation of camera intrinsic parameters. Although effective, the proposed method's novelty is somewhat constrained as it leverages existing approaches; the loss functions and training strategy draw heavily from DPT (Ranftl et al., 2022), and the metric depth estimation follows ideas from Metric3D (Yin et al., 2023). The contributions of this work are significant, with the pre-trained model holding substantial potential for a range of downstream tasks, but more discussion on the unique aspects would strengthen the paper.",
    "candidate_a_label": "AI System: deepreviewer",
    "candidate_b_label": "Human Review 3",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 2,
      "candidate_a_system": "deepreviewer",
      "candidate_a_type": "ai",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 3,
      "consensus_info": {
        "consensus_review": 2,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "2": {
            "2": true,
            "3": true
          },
          "3": {
            "2": true,
            "3": true
          }
        },
        "agreement_scores": {
          "2": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 11
  },
  {
    "id": 43,
    "paper_id": "e8c7XDRJcg",
    "reference_text": "The paper presents three methods to perform Unsupervised Modality Adaptation (UMA): Student-Teacher (ST), Contrastive Alignment (CA), and Cross-modal Transfer Through Time (C3T). Unsupervised Modality Adaptation is frequently used for cross-modal learning in many applications and cannot be regarded as a new contribution of this paper. Compared to ST and CA, the Cross-modal Transfer Through Time (C3T) performs pseudo label generation and alignment in temporal sequences, while other operations, including feature learning, RGB-IMU alignment, and classification, follow the same procedures, so the novelty of the proposed method needs to be reconsidered. The experiment comparison is not reliable since the proposed approach is not compared with related frameworks, and there are many existing works as listed in Section 2. I suggest considering refining the key innovations and redefining the key representations for innovation.",
    "candidate_a_text": "This paper proposes a cross-modal transfer method for human action recognition, based on the assumption that there is a shared latent representation space for different modalities, and includes three variants: student-teacher, contrastive alignment, and cross-modal transfer through time. The novelty of the paper is limited, as the assumption of a shared latent representation space for different modalities has been proposed by many previous works. While the idea of aligning modalities in a common latent space is well-established, the paper needs to more clearly articulate the specific novel contributions beyond the existing literature on shared latent spaces. For example, the 'cross-modal transfer through time' (C3T) method should be explained in more detail, highlighting how it differs from existing temporal alignment techniques, and the paper should emphasize the unique aspects of its approach.",
    "candidate_b_text": "The paper investigates an unsupervised modality adaptation method for the action recognition model, proposing Cross-modal Transfer Through Time (C3T), which performs alignment on each temporal step rather than on video-level feature representation as in Contrastive Alignment (CA). The novelty is minor, which is only on doing the alignment per temporal step, without proposing a new alignment method or an architectural change to current state-of-the-arts. The lack of state-of-the-art comparison also makes it hard to justify the significance of the novelty besides its improvement upon Student-Teacher (ST) and CA methods.",
    "candidate_a_label": "AI System: deepreviewer",
    "candidate_b_label": "Human Review 3",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "deepreviewer",
      "candidate_a_type": "ai",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 3,
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "3": true
          },
          "3": {
            "1": true,
            "3": true
          }
        },
        "agreement_scores": {
          "1": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 12
  },
  {
    "id": 90,
    "paper_id": "HyN9POiYhN",
    "reference_text": "This paper investigates gender bias in autoregressive large language models (LLMs) by examining bias transfer—the correlation between models’ intrinsic bias (as measured by next-token prediction) and their bias in zero- or few-shot prompting—across a range of experimental settings and open-source models, with a particular focus on the effectiveness of prompt engineering techniques for mitigating such bias. However, the novelty of the work is limited, as there is already a substantial body of literature addressing similar questions regarding zero- and few-shot evaluation of causal LLM bias (see, for example, Ganguli et al., 2023; Bai et al., 2024; Lin et al., 2024; Huang et al., 2023; and the comprehensive survey by Ranjan et al., 2024). The paper does not cite this closely related prior work and is written as if previous studies of LLM bias were restricted to masked language models or fine-tuned autoregressive models, which artificially inflates its contribution. While the specific focus on bias transfer as a metric and the detailed experimental findings may offer some incremental novelty—particularly since prior work such as Ladhak et al. (2023) has only considered bias transfer in the context of summarization tasks and fine-tuning—the overall research area is already crowded. Thus, the main contribution appears to be the application of the bias transfer metric to a broader set of tasks and models, but this advance is modest in light of the extensive existing literature. The paper would benefit from a more thorough engagement with prior work and a clearer articulation of how its findings differ from or build upon established research in the field.",
    "candidate_a_text": "This submission systematically investigates whether gender bias present in pre-trained causal LLMs (such as Mistral, Falcon, and Llama) transfers to downstream tasks (pronoun co-reference resolution) when models are adapted via prompting, rather than fine-tuning. The key empirical finding is a strong, robust correlation (≥0.90) between intrinsic and downstream gender bias in prompt-adapted causal LLMs, in contrast to prior work on fine-tuned masked language models, which found weak or no such transfer. The study’s methodological novelty lies in its focus on prompt-based adaptation in causal LLMs and its systematic variation of prompt and few-shot factors, providing robustness evidence for the main result. While the authors’ claims of being the first to systematically analyze bias transfer in this adaptation regime are largely accurate, the distinction from some recent related work (e.g., Ladhak et al., 2023) could be more clearly articulated. Overall, the submission offers a substantive empirical advance in understanding bias transfer dynamics in modern LLMs, though its conceptual novelty is primarily in the adaptation regime and model type rather than in the general framework of bias transfer analysis.",
    "candidate_b_text": "This paper investigates the transfer of gender bias from pre-trained causal language models to prompted models using the WinoBias dataset, focusing on prompt-adapted causal models, which is timely given the increasing use of prompting in deploying language models. However, the paper's scope is limited to gender bias and the WinoBias dataset, which may not fully capture the complexity of bias transfer in language models, and it does not extensively compare its findings with previous work on bias transfer in masked language models (MLMs). Given the conflicting findings in prior research, a more detailed discussion of how the results relate to and differ from previous work is needed to establish the paper's originality. The study's contribution lies in highlighting the strong correlation between intrinsic biases in pre-trained models and those in prompted models, but the lack of a thorough comparison with existing literature and exploration of a wider range of biases and datasets somewhat limits the significance and uniqueness of the contribution.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: deepreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "deepreviewer",
      "consensus_info": {}
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 13
  },
  {
    "id": 93,
    "paper_id": "CKYsXi0dOV",
    "reference_text": "This paper presents BLIP-3-Video, a novel multimodal language model for video understanding that introduces an innovative temporal encoder to significantly reduce the number of visual tokens needed to represent videos, offering a new approach to efficiency in video understanding models. While the integration of the temporal encoder is highlighted as a key innovation, I question the core novelty of this paper compared to prior works such as LLaMA-VID, Video-LLaVA, LLaVA-VID, and LLaVA-NEXT, as similar architectures have already been explored in these works. Although the experimental results show that 32 tokens achieved better performance on four short video benchmarks, this standard may change with different video lengths, scenarios, and question complexity, raising concerns about the scalability and generalizability of the method. Perhaps a more effective mechanism for accommodating more frames and selecting key information for video question answering from a large number of visual tokens is worth exploring, rather than focusing on a specific numerical value of visually overfitted tokens on a few benchmarks.",
    "candidate_a_text": "BLIP-3-Video presents an incremental advance in token-efficient video representation for vision-language models, primarily through the architectural design and explicit integration of a learnable spatio-temporal pooling module. While the submission claims fundamental novelty and to be the first to demonstrate high-quality video QA with only 16–32 tokens, similar results and approaches have already been reported in recent works such as TESTA, SMAUG, and LLaVA-PruMerge. The use of sequential models like Token Turing Machines as temporal encoders is a direct application of existing methods rather than a conceptual innovation. The main technical contribution is the specific pooling architecture, but the overall approach aligns closely with the field’s ongoing trend toward aggressive token reduction and learnable aggregation. Reviewers should recognize BLIP-3-Video as a well-executed, incremental improvement within an established research paradigm, rather than a fundamentally novel or paradigm-shifting contribution.",
    "candidate_b_text": "This paper introduces BLIP-3-Video, a novel multimodal language model designed for efficient video understanding, with the core innovation lying in its temporal encoder, which significantly reduces the number of visual tokens required to represent a video and directly addresses the computational challenges of processing long videos in large vision-language models. I find that the core idea of using a temporal encoder to reduce the number of visual tokens is a significant contribution, and the exploration of two distinct temporal encoders—spatio-temporal attentional pooling and Token Turing Machines (TTM)—is another strength that allows for a comparison of different approaches to temporal modeling within the same framework. However, the paper's novelty is somewhat limited by its reliance on existing techniques, as the core idea of using a temporal encoder to reduce the number of visual tokens is not entirely new and similar approaches have been explored in prior works. The authors acknowledge this to some extent, but a more detailed comparison with existing methods, such as token pruning or token merging techniques, would help to better contextualize the contributions of the proposed model and highlight its unique aspects. Despite this, the fact that BLIP-3-Video can abstract a video into as few as 32 tokens while maintaining high accuracy, and achieves competitive performance compared to much larger state-of-the-art models, is a remarkable achievement and constitutes a significant step towards more efficient video understanding. Overall, while the approach offers practical and efficiency improvements, the lack of a thorough analysis of how the proposed temporal encoder differs from existing token reduction methods makes it difficult to fully assess the model's unique contributions.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: deepreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "deepreviewer",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "3": true
          },
          "3": {
            "0": true,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 14
  },
  {
    "id": 22,
    "paper_id": "gRmWtOnTLK",
    "reference_text": "This paper considers a method for reconstructing the waveform from Mel-spectrogram or discrete acoustic tokens by generating complex spectrograms and performing reconstruction on a frame level, achieving audio generation much faster than in real time. The paper's novelty is in question, as it mainly combines existing components (multiband rectified flow and ConvNeXt V2) rather than proposing a fundamentally new approach. While this engineering solution may have merit in specific applications, the lack of novel contributions limits the paper's impact. Strengthening the theoretical foundation or providing a unique methodological contribution would be beneficial in highlighting the algorithm’s distinct value.",
    "candidate_a_text": "An efficient diffusion-based vocoder is proposed that generates the complex spectrogram of STFT at the frame level and can be generated in 10 denoising steps. The strength of this paper appears to lie in the application of the latest technique, rectified flow, which enables efficient sampling, and this aspect of the work stands out as a significant contribution. This work introduces three additional loss functions to improve performance, and the additional loss functions appear to consistently improve performance. However, the task addressed in this paper is rather conventional, using standard datasets and common evaluation methods, so the work comes across as a minor variation of existing research and lacks a clear element of originality. In a field where many similar approaches already exist, this work appears to be another study that only slightly improves existing benchmarks. Moreover, the approach is not theoretically groundbreaking either; at first glance, the proposed method appears to be a combination of existing ideas, making its originality and novelty less immediately clear.",
    "candidate_b_text": "This paper presents RFWave, a novel approach for audio waveform reconstruction using a multi-band Rectified Flow model. The integration of Rectified Flow and the use of STFT frames for parallel processing significantly improve the sampling speed, making RFWave highly efficient compared to existing diffusion-based methods. The paper includes extensive experiments comparing RFWave with existing diffusion and GAN-based models, demonstrating its superior performance in terms of quality and computational efficiency.",
    "candidate_a_label": "Human Review 3",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 2,
      "candidate_a_system": 3,
      "candidate_a_type": "human",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 2,
        "consensus_score": 0.5,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          3,
          4
        ],
        "agreement_matrix": {
          "2": {
            "2": true,
            "3": true,
            "4": false
          },
          "3": {
            "2": true,
            "3": true,
            "4": false
          },
          "4": {
            "2": false,
            "3": false,
            "4": true
          }
        },
        "agreement_scores": {
          "2": 0.5,
          "3": 0.5,
          "4": 0.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 15
  },
  {
    "id": 61,
    "paper_id": "ueeqGvQozB",
    "reference_text": "This paper introduces ML4MILP, an original benchmark collection targeted to the MILP domain, aiming to fill the gap of having a large scale, standardized benchmark for evaluating mixed integer linear program solvers. The benchmark is relevant for the ML and DL community, especially as ML-based approaches are becoming popular in this field. The introduction and related work provide a well-written, self-contained overview of existing solvers, techniques, and related benchmarks, highlighting the general lack of a larger standardized benchmark for MILPs. Based on structural and embedding distance between instances, the authors show that existing benchmarks are often more heterogeneous than the MILP benchmark they propose, which allows for some insight into the structure of the proposed and existing benchmarks. However, the overall contribution—introduction of the benchmark and showing the lack of homogeneity of existing classes of instances based on similarity evaluation metrics with respect to structure and neural embedding distances—is somewhat limited in scientific insight and currently results in me having a hard time voting for acceptance at a main ML and DL conference such as ICLR; maybe submitting the paper to a Benchmark and Dataset track of a suitable conference might be more targeted.",
    "candidate_a_text": "This paper proposes a benchmark for evaluating machine learning-based mixed-integer linear programming solvers, consisting of a dataset of 100,000 MILP instances classified into 70 classes, and provides a baseline of different algorithms on the dataset. While the dataset is significantly larger than previous ones, I find that the proposed dataset is not significantly different from the existing ones, and the authors do not provide a clear motivation for why the existing benchmarks are not sufficient. The authors claim that existing benchmarks are not homogeneous, but they do not provide a clear definition of homogeneity in the context of MILP instances, nor sufficient evidence that the proposed dataset is indeed more homogeneous than the existing ones. The argument that the similarity between instances in the same class is higher than in existing benchmarks is not convincing without a clear explanation of how similarity is measured and why it matters. Although the proposed dataset’s larger size is emphasized, the authors do not provide a clear justification for why a larger dataset is necessarily better. Overall, the novelty and significance of the contribution are unclear due to a lack of rigorous comparisons to prior benchmarks, definitions of claimed improvements, and justifications for the benefits claimed.",
    "candidate_b_text": "This paper focuses on developing a benchmark ML4MILP to evaluate machine learning (ML) based methods for solving mixed-integer linear programs of MILPs. I have questions about how this benchmark compares and contrasts against the benchmark created for the ML4CO Neurips competition (Gasse et al., 2022), and how this competition benchmark (and the existence of MIPlib) affect the \"first open-source benchmark dataset\" claim in line 74.",
    "candidate_a_label": "AI System: deepreviewer",
    "candidate_b_label": "Human Review 3",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 2,
      "candidate_a_system": "deepreviewer",
      "candidate_a_type": "ai",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 3,
      "consensus_info": {
        "consensus_review": 2,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "2": {
            "2": true,
            "3": true
          },
          "3": {
            "2": true,
            "3": true
          }
        },
        "agreement_scores": {
          "2": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 16
  },
  {
    "id": 80,
    "paper_id": "p6eQRlaxGo",
    "reference_text": "This paper presents AtomFlow, a flow matching model for designing a protein structure to bind a small molecule ligand, which jointly denoises the structure of the protein and ligand and does not require knowledge of the ligand pose, unlike RFDiffusionAA. The methodology can be described as a flow-matching version of RFDiff-AA and does not score high on originality or novelty from a ML perspective. Further, the flow model architecture and noising process are based on AlphaFlow, with different justification but no difference in practice as far as I can tell. The overall significance of the contribution is unclear as it represents an incremental methodological advance over RFDiff-AA with more or less the same model capabilities. The authors argue that not needing to specify the ligand pose is a big plus, but no meaningful evidence or use case is provided for this distinction.",
    "candidate_a_text": "ATOMFLOW introduces a generative model for protein-ligand complex design that jointly generates both ligand and protein structures from 2D molecular graphs, addressing ligand flexibility and protein-ligand interactions in a unified, end-to-end framework. The main technical advance is the application of SE(3)-equivariant flow-matching at the atomic level, enabling iterative, joint updates of both ligand and protein, which distinguishes it from prior models that either require fixed ligand conformers (e.g., RFDiffusionAA) or are limited to pocket refinement (e.g., PocketGen, FlowSite). The authors’ claim of being the first to enable de novo, all-atom complex generation from 2D ligand graphs is accurate within the generative modeling context, though unified atomic representations have been explored in predictive models like Umol. While the unified \"biotoken\" framework and atomic flow-matching are meaningful extensions, the underlying concepts are increasingly standard in the field; the novelty lies in their integration for this specific generative task. Overall, the submission represents a substantive and well-substantiated advance, though some claims slightly overstate conceptual novelty, and additional comparisons to related predictive and sequence-structure co-design models could further clarify its scope.",
    "candidate_b_text": "This paper presents the ATOMFLOW architecture for the design of protein folds conditioned by the ligand SMILES description. It's a well written technical paper about a novel architecture that can be useful for the bioinformatics community, but there is little technical novelty in the architecture blocks, loss function, or flow matching process (but the architecture is novel and useful). When generating folds for a purine ligand, the results were extremely conservative, with zero novelty and extremely low diversity, preferring the fold that dominantly occurs in the PDB, which suggests a significant bias towards folds that are abundant in the PDB. The designs have scores > 0.5, meaning that the fold structure is the same as in the PDB and no new folds have been discovered. It seems AtomFlow has memorized the space of all protein folds in the PDB and simply selects the one it has seen during training, so I suggest the authors run more cross-validation tests hiding some fold classes from the training and trying to reproduce them in the test.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "Human Review 2",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "ours",
      "candidate_a_type": "ai",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 2,
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 1.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          2,
          3
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "2": true,
            "3": true
          },
          "2": {
            "1": true,
            "2": true,
            "3": true
          },
          "3": {
            "1": true,
            "2": true,
            "3": true
          }
        },
        "agreement_scores": {
          "1": 1.0,
          "2": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 17
  },
  {
    "id": 62,
    "paper_id": "ueeqGvQozB",
    "reference_text": "This paper introduces ML4MILP, an original benchmark collection targeted to the MILP domain, aiming to fill the gap of having a large scale, standardized benchmark for evaluating mixed integer linear program solvers. The benchmark is relevant for the ML and DL community, especially as ML-based approaches are becoming popular in this field. The introduction and related work provide a well-written, self-contained overview of existing solvers, techniques, and related benchmarks, highlighting the general lack of a larger standardized benchmark for MILPs. Based on structural and embedding distance between instances, the authors show that existing benchmarks are often more heterogeneous than the MILP benchmark they propose, which allows for some insight into the structure of the proposed and existing benchmarks. However, the overall contribution—introduction of the benchmark and showing the lack of homogeneity of existing classes of instances based on similarity evaluation metrics with respect to structure and neural embedding distances—is somewhat limited in scientific insight and currently results in me having a hard time voting for acceptance at a main ML and DL conference such as ICLR; maybe submitting the paper to a Benchmark and Dataset track of a suitable conference might be more targeted.",
    "candidate_a_text": "This paper focuses on developing a benchmark ML4MILP to evaluate machine learning (ML) based methods for solving mixed-integer linear programs of MILPs. I have questions about how this benchmark compares and contrasts against the benchmark created for the ML4CO Neurips competition (Gasse et al., 2022), and how this competition benchmark (and the existence of MIPlib) affect the \"first open-source benchmark dataset\" claim in line 74.",
    "candidate_b_text": "This paper proposes a new benchmarking framework for solving mixed integer linear programs (MILPs) using machine learning (ML). The proposed ML4MILP framework is a significant contribution that can advance the development of ML-based methods for solving MILPs. The proposed framework is very comprehensive, including a large-scale dataset, appropriate similarity evaluation metrics, a reclassification algorithm, and a baseline library, ensuring that the framework can be used to evaluate a wide range of methods, from traditional optimization solvers to the latest ML-based approaches. The dataset contains instances from both real-world problems and synthetic instances, ensuring that the methods evaluated on it are robust and can be applied to a variety of practical scenarios.",
    "candidate_a_label": "Human Review 3",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 2,
      "candidate_a_system": 3,
      "candidate_a_type": "human",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 2,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "2": {
            "2": true,
            "3": true
          },
          "3": {
            "2": true,
            "3": true
          }
        },
        "agreement_scores": {
          "2": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 18
  },
  {
    "id": 27,
    "paper_id": "aueXfY0Clv",
    "reference_text": "The proposed Depth Pro model employs a ViT architecture for zero-shot metric monocular depth estimation, targeting applications such as novel view synthesis. While Depth Pro benefits from pretrained ViT backbones, its architecture primarily builds on existing elements rather than introducing fundamentally new mechanisms for depth estimation, which limits its architectural novelty. The paper introduces a two-stage training approach that integrates synthetic and real-world datasets, enhancing depth boundary accuracy, and includes new metrics for evaluating depth boundaries that address a gap in existing benchmarks by focusing on boundary precision, which is critical for applications like view synthesis that demand fine details.",
    "candidate_a_text": "Depth Pro is presented as a foundation model for zero-shot, high-resolution, metric monocular depth estimation without requiring camera intrinsics, emphasizing sharp boundaries and fast inference. While the submission claims several firsts—including zero-shot focal length estimation and new boundary evaluation metrics using matting datasets—many of these contributions are incremental extensions or empirical integrations of strategies already present in recent works such as UniDepth, DMD, Metric3D v2, PatchFusion, PatchRefiner, and SM4Depth. The main substantive advance appears to be the combination of speed, sharpness, and metric accuracy in a single model, with the use of matting datasets for boundary evaluation being a modest but useful addition. However, the claim of being the \"first foundation model\" for this problem is overstated, as several recent models address similar challenges, sometimes with different technical means. Reviewers should recognize Depth Pro as a strong empirical advance within a rapidly evolving field, but should calibrate novelty claims in light of the incremental nature of most contributions and the omission of some highly relevant prior work.",
    "candidate_b_text": "This paper proposes a new method for zero-shot monocular depth estimation that is efficient, fast and accurate, and is also capable of predicting metric-scale depth, which is a challenging task. The experiments demonstrate the superiority of the proposed method over the existing methods.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 2,
      "candidate_a_system": "ours",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 2,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "2": {
            "2": true,
            "3": true
          },
          "3": {
            "2": true,
            "3": true
          }
        },
        "agreement_scores": {
          "2": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 19
  },
  {
    "id": 26,
    "paper_id": "9aIlDR7hjq",
    "reference_text": "The authors propose a frozen alternative to increase the diversity of synthetic training images generated by diffusion models, which conditions the diffusion model not only on few-shot images (done previously) but augmentations (novelty). The method itself is quite simplistic from a novelty perspective (simply adding augmentations to the conditioning). I would consider this a strength if the results were consistent and strong with a clear storyline for effective use-cases; however, I do not see this as being the case. I do not find the CFG scale experiments as adding significant value, as they are consistent with previous work and do not provide more interesting, surprising, or novel results, which in my opinion waters down the impact of the experimental section.",
    "candidate_a_text": "This paper demonstrates that conditioning the generation process on an augmented real image and a text prompt produces effective synthetic datasets, which benefit downstream tasks, particularly for long-tailed (LT) classification and few-shot classification. However, the technical novelty of this paper is unclear. The concept of combining both augmented images and text prompts seems useful for LT and few-shot classification but lacks novelty. If this approach is not technically original, the paper should at least show a broad variety of downstream tasks that benefit from it, which it did not. The contribution is not clearly articulated, as it’s evident that the synthetic dataset is effective, but it’s unclear for which specific tasks it is most useful, with the focus confined to LT and few-shot classification. Expanding the application scenarios would improve the paper’s impact.",
    "candidate_b_text": "This paper proposes a new method of generating synthetic training images by conditioning the generation process on an augmented real image and a text prompt. The idea of using augmented real images as a reference to guide the generation process is interesting. However, the paper lacks a comparison with a strong baseline that fine-tunes the diffusion model on the target dataset using a method like textual inversion, which makes it difficult to assess the true effectiveness of the proposed method.",
    "candidate_a_label": "Human Review 2",
    "candidate_b_label": "AI System: deepreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": 2,
      "candidate_a_type": "human",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "deepreviewer",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 1.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          2,
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "2": true,
            "3": true
          },
          "2": {
            "0": true,
            "2": true,
            "3": true
          },
          "3": {
            "0": true,
            "2": true,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 1.0,
          "2": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 20
  },
  {
    "id": 53,
    "paper_id": "Ax3uliEBVR",
    "reference_text": "The authors propose an equivariant Topological Deep Learning framework that deals with geometric node features and can be generalized to many topological domains including simplicial, cell, combinatorial, and path complexes. The authors add an important piece of work for the Topological Deep Learning (TDL) community as there is not much literature on Equivariant TDL, and the novel benchmark based on geospatial information is novel. However, novelty is the key disadvantage of the paper, as it seems that the work just extends prior works on graphs to TDL; even though the theoretical insights are important, they are mostly an extension from graphs. Furthermore, the property of “heterogeneous interactions” was actually mentioned in prior literature, so it is not fair to claim that ETNNs are set up for this characteristic, but more like TDL in general already possesses this property.",
    "candidate_a_text": "This paper introduces an equivariant model within the framework of topological deep learning, generalizing the equivariant graph neural network architecture from Santorras et al. from the setting of graphs to message passing over combinatorial complexes, and allowing for message passing with cells that have heterogeneous node features over differing ranks. I really like that the authors introduced a novel geometric prediction task into the literature, as many of the benchmarks for TDL were somewhat old and outdated, and the new task appropriately features integration of data over different dimensional regions in a way that showcases the central feature of the paper—reconciling data with features on subspaces of differing dimension, i.e., the ‘heterogeneous interactions’ promised in the abstract. For me personally, I find it hard to understand the framing of this as a part of an entirely new conceptual field of topological deep learning beyond GNNs, and question the genuine novelty of papers like this; unless I’m mistaken, the basic content of proposition (1) is that an ETNN can be reformulated as an EGNN, meaning that the main novelty is the clever choice of ‘lifting' the data into a certain graph and some delineation of the learning based on ‘rank’, and even the proof of theorem (1) is basically a straightforward adaption of the corresponding result for EGNNs. I personally get the sense that the ‘topology’ part—and hence the novelty of these kinds of architectures—is overplayed a little, as it seems that the inclusion of domain-specific data along with the design of the graph is doing most of the work, and I don’t personally see a strong connection with the ‘lifted’ combinatorial complexes used in this paper and topology in the classical sense. The claim that this is the first work to explore combinatorial topological modeling of multi-resolution irregular geospatial data seems overstated given existing literature in Topological Data Analysis applied to geospatial data, and I would appreciate clarification on how this approach differs from or advances beyond these existing works.",
    "candidate_b_text": "The submission introduces ETNNs, a general framework for E(n)-equivariant message passing that extends prior models (notably EGNN and EMPSN) from graphs and simplicial complexes to arbitrary combinatorial complexes, thereby unifying and generalizing existing approaches in equivariant topological deep learning. The main technical novelty lies in this abstraction, which enables modeling of more general higher-order structures and allows geometric features to be incorporated at all cell orders, though the practical benefits of these extensions are only modestly demonstrated in standard domains. Claims of increased expressivity and efficiency over prior models are supported by theoretical and empirical analysis, but the improvements are incremental and may partly result from implementation choices rather than fundamental algorithmic advances. The application to a new geospatial dataset is a useful demonstration of generality, but does not constitute a methodological advance. Overall, the work is a technically sound and well-positioned generalization, but reviewers should be aware that its practical impact and novelty may be somewhat overstated unless further empirical evidence is provided for domains where combinatorial complexes offer clear advantages.",
    "candidate_a_label": "Human Review 3",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 2,
      "candidate_a_system": 3,
      "candidate_a_type": "human",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {
        "consensus_review": 2,
        "consensus_score": 1.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          0,
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "2": true,
            "3": false
          },
          "2": {
            "0": true,
            "2": true,
            "3": true
          },
          "3": {
            "0": false,
            "2": true,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 0.5,
          "2": 1.0,
          "3": 0.5
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 21
  },
  {
    "id": 86,
    "paper_id": "QFaj7InstQ",
    "reference_text": "This paper introduces the Item Language Model (ILM), a framework designed to bridge behavioral embeddings from recommendation systems with language understanding in Large Language Models (LLMs). The core contribution lies in adapting a Querying Transformer (QFormer) architecture with a novel item-item contrastive loss, enabling unified and interleaved processing of both behavioral and textual information for language generation tasks. The approach demonstrates innovation in its use of QFormer with item-item contrastive learning to address the modality gap between recommendation signals and language understanding. While this represents a creative step toward integrating behavioral and semantic information, the novelty is somewhat limited by the existence of related work, such as LC-Rec and BinLLM, which also aim to bridge collaborative and semantic signals within large language models. The main distinction of this paper is the specific adaptation of QFormer and the introduction of the item-item contrastive loss, which is well-justified and empirically validated. However, a more thorough comparison with these recent LLM-based recommendation systems would help to better establish the unique contributions and boundaries of novelty. Overall, the paper offers an interesting and incremental advance in the integration of recommendation and language modeling, but its novelty would be strengthened by a clearer articulation of differences from closely related approaches.",
    "candidate_a_text": "This assessment finds that the \"Item Language Model\" (ILM) submission presents incremental advances in the integration of behavioral embeddings into large language models for recommendation, primarily through the use of a Querying Transformer and an item-item contrastive loss. While these architectural and loss function choices are technically distinct, they represent variations on well-established approaches in a rapidly evolving and competitive field. The conceptual framework and problem space are shared with several recent works (e.g., CoLLM, User-LLM, CALRec), some of which are not cited or directly compared against, limiting the clarity of the submission's true novelty. The evaluation methods and claimed improvements are standard for the area, and the submission does not convincingly demonstrate unique capabilities or tasks beyond prior art. Overall, the work is a routine extension of existing research, and reviewers should recognize its contributions as incremental rather than groundbreaking, with a need for more thorough comparison to closely related methods.",
    "candidate_b_text": "This paper proposes a novel approach by adapting the Querying Transformer model to align behavioral and textual data in recommendation systems, integrating collaborative filtering embeddings with large language models. Although these methods are mentioned in the related work, a more detailed comparison with other methods that integrate collaborative filtering with LLMs, such as CoLLM and OpenP5, would strengthen the paper.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {}
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 22
  },
  {
    "id": 0,
    "paper_id": "oYLayGfWcI",
    "reference_text": "This paper introduces a novel single-stage flow matching model for text-to-music generation, capable of generating and editing audio samples at 48 kHz stereo quality. The authors exploit a regularized flow matching inversion method to facilitate text-based music editing. However, while the results achieved are commendable, the contribution lacks sufficient novelty, as the primary distinction from ReNoise lies in the alteration of noise prediction to velocity prediction. Although the paper claims to introduce the flow matching model for text-to-music generation, it is apparent that its performance on subjective metrics does not match that of Stable Audio, and important editing methods like DITTO or MEDIC are not included in the literature review, nor is there a comparison with MusicMagus in zero-shot editing.",
    "candidate_a_text": "This paper introduces MELODYFLOW, a single-stage text-conditioned flow matching (FM) model designed for instrumental music generation and editing. The authors adapt the ReNoise latent inversion method to the flow matching (FM) framework and compare it with the original implementation and DDIM inversion. They also conduct a variety of music editing tasks.",
    "candidate_b_text": "This paper presents MelodyFlow, a novel Flow-Matching based TTM model capable of generating 30 seconds of 48 kHz audio, and in parallel introduces a regularized inversion method to allow for inference-time editing. However, in general, it is hard to tell which parts of the algorithm from ReNoise are being kept and which are novel, and as there is very little textual explanation of the method (and only consistent referrals back to the ReNoise paper), it is hard to tell where the novelty lies. As this is a claimed core contribution of the paper, more time should be spent to make the differences between the baseline and their method explicitly clear. The differences between the baseline ReNoise and the proposed method seem small, and the core contribution then rests solely on the FM inversion technique, in which its novelty is hard to assess. Optimization methods like Novack et al., 2024 are agnostic to the sampling process (and in fact, the flow-matching equivalent has already been explored), and guidance methods like Zhang et al., 2024 are also agnostic to sampler, so the claim that editing methods are exclusive to diffusion models is not wholly true. The strongest modeling results are only with respect to an internal non-TTM baseline and do not seem to get comparable results with current SOTA methods, and without the modeling contributions, the novelty of the FM inversion technique remains unclear.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "Human Review 1",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_a_type": "ai",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 1,
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 1.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          1,
          4
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": true,
            "4": true
          },
          "1": {
            "0": true,
            "1": true,
            "4": true
          },
          "4": {
            "0": true,
            "1": true,
            "4": true
          }
        },
        "agreement_scores": {
          "0": 1.0,
          "1": 1.0,
          "4": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 23
  },
  {
    "id": 68,
    "paper_id": "QoDDNkx4fP",
    "reference_text": "This paper proposes a novel framework, ETA (Evaluating Then Aligning), which addresses a critical gap in the safety of Vision Language Models (VLMs) by focusing on inference-time alignment. Unlike existing approaches that primarily rely on extensive fine-tuning or are limited to specific types of inputs, ETA offers a fresh perspective by combining multimodal evaluation and bi-level alignment without requiring additional training. This plug-and-play nature makes it a highly original contribution, providing a more flexible and scalable solution for enhancing VLM safety. The significance of this work is substantial, as it introduces a method that does not require fine-tuning and can be easily integrated into existing systems, making it practical for widespread use. By improving safety while maintaining model efficiency and general capabilities, ETA could encourage broader adoption of VLMs.",
    "candidate_a_text": "ETA proposes a modular, plug-and-play, inference-time safety alignment framework for vision-language models (VLMs), combining explicit multimodal evaluation (visual and textual) with bi-level alignment (interference prefix and best-of-N search). Its main contribution is the systematic integration and empirical validation of these established techniques, rather than introducing fundamentally new algorithms. While ETA demonstrates improved safety and utility over prior methods, its novelty is incremental, as similar modular inference-time defenses (e.g., ECSO, AdaShield, MLLM-Protector) exist, and several relevant recent works are omitted from the comparison. The authors’ claims of unique novelty and prior work limitations are somewhat overstated, though their engineering advance is meaningful. Reviewers should weigh ETA’s practical integration and robust evaluation against the incremental nature of its contribution and the need for more comprehensive contextualization within the rapidly evolving field.",
    "candidate_b_text": "This paper proposes a new safeguard mechanism for the Vision Language Model (VLM) during the inference phase. However, although the simplicity of the proposed methods, the novelty seems significantly limited, as the proposed methods are based on the simple application of existing models such as CLIP and Reward Models.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "Human Review 1",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_a_type": "ai",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 1,
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 0.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          1
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": false
          },
          "1": {
            "0": false,
            "1": true
          }
        },
        "agreement_scores": {
          "0": 0.0,
          "1": 0.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 24
  },
  {
    "id": 5,
    "paper_id": "f4b0YVwKUO",
    "reference_text": "This paper proposes FASP (Fast and Accurate Structured Pruning), a structured pruning algorithm for LLMs that emphasizes both pruning efficiency (speed) and accuracy. The main weakness of this paper lies in its novelty. This paper proposes (1) formulation, (2) importance metric, and (3) restoration method, but all of these ideas can be found in previous works [1, 2, 3, 4] with slight modifications in some cases. In detail, the pruning of neurons is used in [1,2,3] and the importance metric of FASP is a straightforward modification of Wanda [4]; it just sums up the importance score of weights in each column to measure the importance of the column. The restoration method of FASP which solves the least-square problem is also used in previous works [1,2]. Therefore, FASP has limited novelty and originality.",
    "candidate_a_text": "FASP is presented as a structured pruning framework for large language models (LLMs), positioned among recent methods like SliceGPT, FLAP, Wanda, and LLM-Pruner, with its main claimed novelty being the explicit, algorithmic interlinking of column/row pruning across sequential layers. The assessment finds that this \"interlinked\" structure is an incremental refinement of existing cross-layer or rotation-based pruning strategies, rather than a fundamentally new approach. FASP’s use of a Wanda-inspired pruning metric and a restoration mechanism are also routine adaptations seen in several recent works, with the restoration step differing mainly in implementation details rather than conceptual novelty. While FASP demonstrates competitive pruning times and practical efficiency, the source of these improvements may be due to implementation optimizations rather than core algorithmic advances. Overall, the submission’s claims of novelty are somewhat overstated, and the work would benefit from more comprehensive comparisons with several omitted, highly relevant recent methods to clarify its true contribution within a rapidly evolving field.",
    "candidate_b_text": "This paper proposes a structured pruning method for LLMs that removes rows and columns of weight matrices, introducing a heuristic metric to identify columns for removal inspired by the Wanda score and adjusting remaining weights via a least-squares problem. However, the method is a simple extension of Wanda, which limits the novelty of the proposed method. While the proposed method is simple and seems to outperform existing methods in terms of perplexity on the WikiText dataset, its originality is constrained by its similarity to prior approaches.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 1.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          2,
          4
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "2": true,
            "4": true
          },
          "2": {
            "0": true,
            "2": true,
            "4": true
          },
          "4": {
            "0": true,
            "2": true,
            "4": true
          }
        },
        "agreement_scores": {
          "0": 1.0,
          "2": 1.0,
          "4": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 25
  },
  {
    "id": 8,
    "paper_id": "Mgf7qdUbX5",
    "reference_text": "This work introduces a GAN-based framework to produce text backdoors, where the generator is designed to fuse triggers into inputs and the discriminator is responsible for identifying the presence of triggers. The contribution is incremental, lacking novelty in both the problem definition and the technical solution. In terms of problem definition, evasive backdoors have been extensively studied, wherein novel approaches, such as \"style backdoors\" that treat semantic styles as backdoor triggers, have rigorous definitions. However, this work merely relies on a black-box model to produce trigger-embedded inputs, without providing intuitions about the nature of the backdoor. The technical solution is simply a combination of existing modules, without offering strong insights or a truly novel design.",
    "candidate_a_text": "This paper presents a new approach, AdvBDGen, to generating adaptable, transferable, and stealthy backdoor triggers for large language models (LLMs), with attacks that can automatically generate backdoor triggers during the alignment stage and are robust to perturbations. However, the key motivation of this work and the novelty of the proposed approach are not very clear to me. To the best of my knowledge, semantic-based backdoor attacks are extensively proposed in previous research, including but not limited to the following work: [1,2,3]. This paper only mentions \"constant triggers\" during the motivation and development of the method, which makes the overall contribution and novelty very confusing. Correspondingly, the relevant semantic-based backdoor attack methods are not considered and compared with in the experiments, making the results not solid enough.",
    "candidate_b_text": "This assessment finds that the submission, AdvBDGen, is positioned within the rapidly evolving field of adaptive, stealthy backdoor attacks on LLMs, specifically advancing prompt-specific, fuzzy trigger generation. Its main technical novelty lies in the use of adversarial generator-discriminator training with dual discriminators (strong/weak) to optimize both stealth and installability of backdoor triggers—a setup not present in prior work, though the general idea of adaptive or paraphrased triggers is well established. While the authors accurately distinguish their training-time attack from test-time jailbreaks and cite relevant literature, they tend to overstate their \"first to\" claims and underplay the sophistication of recent related works (e.g., NOTABLE, Mind the Style of Text, BadChain), omitting direct comparisons that would clarify their true contribution. The empirical improvements in stealth, robustness, and transferability are credible but appear to be incremental, with the main conceptual advance being the dual-discriminator adversarial training framework. Overall, the submission represents a substantive but evolutionary step in the field, and reviewers should be aware of both its technical strengths and the somewhat overstated novelty relative to recent literature.",
    "candidate_a_label": "Human Review 1",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": 1,
      "candidate_a_type": "human",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 1.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          1,
          2
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": true,
            "2": true
          },
          "1": {
            "0": true,
            "1": true,
            "2": true
          },
          "2": {
            "0": true,
            "1": true,
            "2": true
          }
        },
        "agreement_scores": {
          "0": 1.0,
          "1": 1.0,
          "2": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 26
  },
  {
    "id": 6,
    "paper_id": "jl9lHkQrrI",
    "reference_text": "This paper proposes a practical approach for fine-tuning small language models (LLMs) in the industrial asset domain by generating synthetic knowledge documents and question-answer pairs from structured tabular data, leveraging knowledge graphs and prompt engineering techniques. While the authors describe their method as a novel two-step iterative process that integrates a Knowledge Graph (KG) with an LLM to produce extensive qualitative knowledge documents, the methodological novelty appears limited. The approach primarily adapts existing techniques for industrial applications, and it is unclear whether the contribution lies in fundamentally building a new KG or in introducing a new continued fine-tuning strategy. The paper does not clearly differentiate its methodology from prior work, and there is little evidence of significant innovation beyond the practical application to a specific domain. As such, the novelty is minimal from a methodological perspective, and the work would benefit from a more explicit articulation of how its approach advances beyond established practices in LLM fine-tuning and knowledge integration.",
    "candidate_a_text": "This assessment finds that the submission is an incremental extension of established methods for adapting LLMs to specialized domains using synthetic data generated from structured sources, specifically applying these techniques to industrial asset management with ISO standards. While the authors claim novelty in their two-step iterative KG-LLM process and entity expansion for knowledge document generation, similar approaches (KG-to-text, synthetic QA generation) are well-documented in prior work across other domains such as medical and chip design. The main substantive difference lies in the application domain and the use of ISO tables, rather than in methodological innovation. Reported empirical improvements (~4% accuracy) are modest and consistent with typical gains from domain adaptation, and the analysis of diminishing returns with more data is routine. The submission overstates its novelty, omits citation of several directly relevant works, and does not fully acknowledge the breadth of similar synthetic data pipelines in the literature, which reviewers should consider when evaluating the true contribution delta.",
    "candidate_b_text": "This paper introduces a novel approach to enhance the performance of small language models in the industrial asset domain by leveraging structured tabular data. The authors propose a creative solution to enhance small LLMs using synthetic data generated from structured tables in ISO standards, and this is a novel approach in the domain of industrial applications.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {}
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 27
  },
  {
    "id": 15,
    "paper_id": "qrTOtUdz4Z",
    "reference_text": "This paper proposes a novel framework, ConceptGCD, that uses a covariance loss to learn distinctive concepts to facilitate category discovery in the Generalized Category Discovery (GCD) task. The novelty of the proposed framework is limited: the major contribution is the application of covariance loss in GCD. While the framework is well-designed to allow the model to use both \"derivable concepts\" to aid novel class discovery and \"underivable concepts\" customized to novel classes, the main originality lies in leveraging covariance loss to promote diversity in concept learning. The method achieves strong performance across six benchmarks, outperforming previous approaches, but the contribution is primarily incremental in applying covariance loss within the GCD context.",
    "candidate_a_text": "This paper studies the problem of Generalized Category Discovery, which aims to assign unlabeled samples with both known and unknown class clusters. They design a novel two-branch concept-based architecture, which introduces a novel shared derivable concept learning branch that consists of a frozen labeled known classes pre-trained encoder to capture concepts of known classes, which are then used to generate the derivable concept of novel classes. With this shared branch, the model can boost the representation learning of unlabeled samples with concepts learned from known classes. They also propose a concept generation module and a novel covariance loss to derive new concepts of novel classes from known classes, and consequently learn independent underivable concepts for novel classes. For the final model to be fine-tuned jointly, they expand the derivable concept generate layer to learn more independent concepts of novel classes with a proposed knowledge transfer constraint, and a normalization term is introduced to balance the learning process between labeled and unlabeled samples. They elaborately design a three-stage training strategy for the proposed ConceptGCD to alleviate the influence of the noise introduced by the uncertainty of unlabeled samples.",
    "candidate_b_text": "This paper proposes a novel framework for Generalized Category Discovery (GCD), named ConceptGCD, which introduces a new way of learning with known classes by derivable and underivable concepts. The proposed method is novel. It is interesting and effective to introduce the concept of concepts into the GCD field and learn the different concepts separately. The experimental results show that the proposed method outperforms the previous state-of-the-art methods on several GCD datasets.",
    "candidate_a_label": "Human Review 2",
    "candidate_b_label": "AI System: deepreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": 2,
      "candidate_a_type": "human",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "deepreviewer",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 0.5,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          1,
          2
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": true,
            "2": false
          },
          "1": {
            "0": true,
            "1": true,
            "2": false
          },
          "2": {
            "0": false,
            "1": false,
            "2": true
          }
        },
        "agreement_scores": {
          "0": 0.5,
          "1": 0.5,
          "2": 0.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 28
  },
  {
    "id": 57,
    "paper_id": "AAjCYWXC5I",
    "reference_text": "This paper introduces a zero-shot in-context adversarial learning framework for Large Language Models (LLMs) aimed at enhancing research ideation. The approach leverages a multi-agent system inspired by the academic peer review process, with distinct proposer, reviewer, and area chair roles, to iteratively refine research ideas along the axes of novelty and feasibility. This framework fills a notable gap in the field by conceptually adapting adversarial learning to the context of LLM-driven idea generation, an area that has seen limited exploration. The use of a peer review-inspired multi-agent setup to promote iterative improvement in idea generation represents a conceptually novel contribution, distinguishing the work from prior approaches that typically do not model such structured, adversarial interactions among LLM agents. Overall, the paper’s novelty lies in its creative adaptation of adversarial learning principles and academic peer review dynamics to the automated ideation process, offering a fresh perspective and a promising direction for advancing LLM-based research support systems.",
    "candidate_a_text": "This paper introduces a zero-shot in-context adversarial learning framework to enhance research ideation using multi-LLM-agent interactions, where a proposer agent, reviewer agent, and area chair agent iteratively refine research ideas along novelty and feasibility dimensions, mirroring the academic review process. The multi-agent framework is well-designed, highly engaging, and interactive. The authors also propose a relative quality ranking metric to evaluate idea generation quality, showing that this approach significantly improves the novelty and feasibility of generated research ideas.",
    "candidate_b_text": "This paper presents a novel approach to enhancing research ideation using large language models (LLMs) by introducing a \"zero-shot in-context adversarial learning\" framework specifically tailored for research idea generation. The method draws inspiration from generative adversarial networks (GANs) but adapts the adversarial paradigm to the unique challenges posed by LLMs and open-ended ideation tasks. This represents a creative combination of existing concepts applied to a new domain, as the adversarial learning framework is operationalized through a unique multi-agent system in which each agent (Proposer, Reviewer, Area Chair) plays a distinct role in refining research ideas. Additionally, the paper proposes a new evaluation metric, the \"relative quality ranking score,\" designed to assess the novelty and feasibility of LLM-generated research ideas relative to a benchmark of human-generated ideas. This metric addresses the challenge of evaluating open-ended text generation by moving beyond traditional metrics and offering a more nuanced assessment. While the paper positions both the adversarial learning framework and the relative quality ranking metric as novel contributions, the novelty primarily lies in the creative integration and adaptation of existing ideas rather than the introduction of entirely new theoretical constructs. The GAN-inspired framing, while innovative, is more metaphorical than rigorously mathematical, and the multi-agent system mimics established peer review dynamics in a new context. Furthermore, although the relative quality ranking metric is presented as a novel evaluation tool, a more thorough discussion of its relationship to existing metrics for open-ended text generation would strengthen the novelty claim, as it remains unclear whether similar approaches have been explored in prior literature. Overall, the paper offers a fresh and thoughtfully integrated approach to LLM-driven research ideation, but its novelty is best characterized as a creative synthesis and domain-specific adaptation of established ideas, rather than a fundamentally new paradigm.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "Human Review 1",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_a_type": "ai",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 1,
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 0.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          1
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": false
          },
          "1": {
            "0": false,
            "1": true
          }
        },
        "agreement_scores": {
          "0": 0.0,
          "1": 0.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 29
  },
  {
    "id": 51,
    "paper_id": "otXB6odSG8",
    "reference_text": "This paper employs the Neuralode method to perform the Atmospheric Radiation Parameterization task. While it may perform relatively well in weather forecasting, it lacks novel insights for the ML community, as it primarily appears to apply standard ML modules to AI4Science tasks. The methods used are previously published, and although adapting an existing method from area A to area B could reach the level of a Nature/Science paper, it doesn't meet my standards for ICLR. Typically, the main contribution should lie in the methodological design, incorporating modifications based on the specific problem at hand, and the comparison should focus on SOTA methods to highlight its novelty. Comparing only with outdated work makes it difficult to assess the novelty of the proposed method, and simply applying an existing method from area A to area B should truly surprise people, as such transfers are generally not considered easy. I believe this work falls short in both aspects.",
    "candidate_a_text": "This paper presents an intercomparison study of multiple neural network architectures to replace radiative transfer parametrizations inside WRF, ultimately finding an RNN to be best and coupling it to WRF for a 4x speed up at a loss in accuracy of ~1K in surface temperature. There is limited technical novelty in the contribution which makes the work less interesting to the broad readership of ICLR. More specifically, all neural network architectures studied in this work have been previously used, the dataset has been introduced in a different study (Yavich et al. 2024), the concept of emulating radiative transfer has been widely studied and the empirical results are not ground breaking. While the study compares many baselines, it does not compare to any previously published emulators of radiative transfer schemes, which makes it difficult to assess how good the reported metrics are.",
    "candidate_b_text": "This paper explores the application of neural networks for radiative transfer parameterization within weather and climate models, focusing on the Arctic region. I found the authors' exploration of various neural network architectures, including point-wise, profile-wise, and sequential models, to be a significant strength, and their systematic approach demonstrates a clear understanding of the problem's intricacies. The use of a profile-wise recurrent neural network (RNN) to emulate radiative flux propagation is a key aspect of their approach, and the finding that profile-wise RNNs perform best highlights the importance of considering vertical propagation and sequential dependencies in atmospheric data. The core contribution of the paper lies in demonstrating the feasibility and effectiveness of using neural networks, particularly profile-wise RNNs, for radiative transfer parameterization, leading to substantial computational gains within a regional weather model, as evidenced by the 26.5-fold speedup in radiation step computation. While the paper presents a valuable contribution by showcasing the potential of neural networks for accelerating radiative transfer calculations in weather and climate models, it lacks a detailed comparison to other existing parameterization schemes and does not provide a clear justification for the choice of the profile-wise RNN architecture over alternatives. Additionally, limitations in generalizability, potential overfitting due to a high number of parameters, and a lack of rigorous evaluation of overall forecast accuracy restrict the significance and originality of the contribution. Despite these limitations, the systematic evaluation of different neural network architectures and the demonstrated speedup provide a good starting point for future research in this area.",
    "candidate_a_label": "Human Review 2",
    "candidate_b_label": "AI System: deepreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": 2,
      "candidate_a_type": "human",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "deepreviewer",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 1.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          1,
          2
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": true,
            "2": true
          },
          "1": {
            "0": true,
            "1": true,
            "2": true
          },
          "2": {
            "0": true,
            "1": true,
            "2": true
          }
        },
        "agreement_scores": {
          "0": 1.0,
          "1": 1.0,
          "2": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 30
  },
  {
    "id": 10,
    "paper_id": "p6eQRlaxGo",
    "reference_text": "This paper presents AtomFlow, a flow matching model for designing a protein structure to bind a small molecule ligand, which jointly denoises the structure of the protein and ligand and does not require knowledge of the ligand pose, unlike RFDiffusionAA. The methodology can be described as a flow-matching version of RFDiff-AA and does not score high on originality or novelty from a ML perspective. Further, the flow model architecture and noising process are based on AlphaFlow, with different justification but no difference in practice as far as I can tell. The overall significance of the contribution is unclear as it represents an incremental methodological advance over RFDiff-AA with more or less the same model capabilities. The authors argue that not needing to specify the ligand pose is a big plus, but no meaningful evidence or use case is provided for this distinction.",
    "candidate_a_text": "This paper presents the ATOMFLOW architecture for the design of protein folds conditioned by the ligand SMILES description. It's a well written technical paper about a novel architecture that can be useful for the bioinformatics community, but there is little technical novelty in the architecture blocks, loss function, or flow matching process (but the architecture is novel and useful). When generating folds for a purine ligand, the results were extremely conservative, with zero novelty and extremely low diversity, preferring the fold that dominantly occurs in the PDB, which suggests a significant bias towards folds that are abundant in the PDB. The designs have scores > 0.5, meaning that the fold structure is the same as in the PDB and no new folds have been discovered. It seems AtomFlow has memorized the space of all protein folds in the PDB and simply selects the one it has seen during training, so I suggest the authors run more cross-validation tests hiding some fold classes from the training and trying to reproduce them in the test.",
    "candidate_b_text": "This paper presents a deep generative model called ATOMFLOW, which is designed to generate ligand-binding proteins from scratch and operates on the quotient space of all possible alignments of N atoms in R^3, with each structure represented as a series of 3D tokens. The proposed method is technically sound and innovative, and the experimental results demonstrate that ATOMFLOW outperforms the state-of-the-art model, RFDiffusionAA, in terms of self-consistency, binding affinity, diversity, and novelty.",
    "candidate_a_label": "Human Review 2",
    "candidate_b_label": "AI System: deepreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": 2,
      "candidate_a_type": "human",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "deepreviewer",
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 1.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          2,
          3
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "2": true,
            "3": true
          },
          "2": {
            "1": true,
            "2": true,
            "3": true
          },
          "3": {
            "1": true,
            "2": true,
            "3": true
          }
        },
        "agreement_scores": {
          "1": 1.0,
          "2": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 31
  },
  {
    "id": 31,
    "paper_id": "qrTOtUdz4Z",
    "reference_text": "This paper proposes a novel framework, ConceptGCD, that uses a covariance loss to learn distinctive concepts to facilitate category discovery in the Generalized Category Discovery (GCD) task. The novelty of the proposed framework is limited: the major contribution is the application of covariance loss in GCD. While the framework is well-designed to allow the model to use both \"derivable concepts\" to aid novel class discovery and \"underivable concepts\" customized to novel classes, the main originality lies in leveraging covariance loss to promote diversity in concept learning. The method achieves strong performance across six benchmarks, outperforming previous approaches, but the contribution is primarily incremental in applying covariance loss within the GCD context.",
    "candidate_a_text": "This paper proposes a novel framework for Generalized Category Discovery (GCD), named ConceptGCD, which introduces a new way of learning with known classes by derivable and underivable concepts. The proposed method is novel. It is interesting and effective to introduce the concept of concepts into the GCD field and learn the different concepts separately. The experimental results show that the proposed method outperforms the previous state-of-the-art methods on several GCD datasets.",
    "candidate_b_text": "This paper introduces ConceptGCD, a novel framework for Generalized Category Discovery (GCD) that leverages a concept-based approach to improve the discovery of novel classes. The introduction of the ConceptGCD framework, which classifies concepts into derivable and underivable classes and addresses them in a staged manner, is innovative and well-justified.",
    "candidate_a_label": "AI System: deepreviewer",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "deepreviewer",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 0.5,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          1,
          2
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": true,
            "2": false
          },
          "1": {
            "0": true,
            "1": true,
            "2": false
          },
          "2": {
            "0": false,
            "1": false,
            "2": true
          }
        },
        "agreement_scores": {
          "0": 0.5,
          "1": 0.5,
          "2": 0.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 32
  },
  {
    "id": 94,
    "paper_id": "ursX3k1rTO",
    "reference_text": "This paper presents a transformer-based architecture to generate symmetric crystals conditioned on space groups in a two-stage process, and proposes a novel representation of crystal symmetry that could facilitate learning of crystal symmetry with deep learning approaches. The paper also proposes metrics to assess the symmetry of the generated crystals and highlights further gains over baseline approaches. While several works are cited in the related works section, neither described nor highlighted the difference from their approach, making it difficult to assess the uniqueness of the contribution. It is also important to add how many new tokens the method generates or if it just predicts the fixed set of tokens in different combinations (and these combinations result in more template novelty than just sampling existing templates from training data). Finally, in Table 1a, I would like to see the number of novel templates as absolute numbers instead of percentages, and the percentage of novel but structurally invalid generations from your method.",
    "candidate_a_text": "The submission presents a permutation-invariant, symmetry-conditioned autoregressive transformer for crystal structure generation, with its main technical novelty being the omission of positional encoding to enforce permutation invariance. This approach is an incremental refinement over closely related prior work, particularly CrystalFormer, which already uses Wyckoff positions and space group conditioning in a similar transformer architecture. The authors’ claims of being the “first” to combine these elements are overstated, as similar representations and conditioning have been explored in recent literature, and some relevant works (e.g., PARD) are not cited. While the empirical results are competitive, the performance gains may stem from implementation details rather than fundamental conceptual advances. Overall, the submission fits within a rapidly evolving field characterized by incremental improvements, and reviewers should interpret claims of novelty and superiority with caution, seeking more direct comparisons and a fuller discussion of related work.",
    "candidate_b_text": "This paper proposes the Wyckoff Transformer, a generative model designed for creating highly symmetric crystal structures by explicitly leveraging space group symmetry through the use of Wyckoff positions as a discrete, permutation-invariant representation of atomic locations. The Wyckoff Transformer introduces a novel approach to crystal generation by utilizing Wyckoff positions to encode symmetries explicitly, making it unique among generative models. Unlike traditional methods, it avoids positional encoding and uses permutation-invariant tokenization tailored to space group symmetries, a creative and effective innovation for materials science. This approach addresses limitations in prior methods, which struggled to produce symmetry-compliant structures, and demonstrates superior performance in symmetry-conditioned generation, creating a diverse set of stable crystal structures that respect the underlying physical symmetries. The model’s potential for symmetry-conditioned generation highlights a promising direction for future research in material informatics and generative modeling.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "Human Review 0",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "ours",
      "candidate_a_type": "ai",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 0,
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 0.5,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          0,
          4
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": false,
            "4": false
          },
          "1": {
            "0": false,
            "1": true,
            "4": true
          },
          "4": {
            "0": false,
            "1": true,
            "4": true
          }
        },
        "agreement_scores": {
          "0": 0.0,
          "1": 0.5,
          "4": 0.5
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 33
  },
  {
    "id": 82,
    "paper_id": "TxIrMD6lAN",
    "reference_text": "This paper presents a method for continual learning that uses task-specific adapters in conjunction with existing methods like LwF or EWC, introducing different adapter formulations and initialization strategies. However, the proposed methodology is lacking in novelty, as the adapter strategy within the context of expansion-based methods for continual learning has been explored many times before (e.g., [a], [b]), and after the recent popularity of LoRA for LLMs, LoRA and similar adaptation techniques have also been ported over to continual learning many times (e.g., [c], with many more in the literature). [a] in particular is very similar to the proposed method, also using a low-rank parameterization inserted between layers of a network to adapt to each task. Claiming to be “among the first to investigate the role of adapters in incremental learning” is not appropriate. Overall, while there may be some useful findings here, I find this paper to be too similar to prior work, which aren’t properly discussed or compared with. Taking a further step back, this paper takes the common “baseline + small addition” approach, for which I’ve seen dozens of continual learning papers; such methods rarely see much adoption, as even if they do lead to improvements, it’s an impossible task trying to combine them with every other such method, for which there often isn’t much synergy.",
    "candidate_a_text": "This paper presents a network design for incremental learning, consisting of a backbone network for learning invariant features and multiple small adapter networks for modeling task-specific knowledge, which can be integrated with existing incremental learning methods. However, the proposed method, which uses adapters to capture task-specific information, is not novel; many existing works already employ similar approaches. The authors should clarify how their method differs from existing methods and why it is effective.",
    "candidate_b_text": "This paper proposes a novel network design for incremental learning that emphasizes addressing inter-task differences as a key contributor to forgetting, rather than focusing solely on model stability. The approach includes a backbone network for capturing invariant features and adapters—originally introduced for efficient fine-tuning—that serve as feature modifiers for task-specific information, enabling the model to learn new tasks while preserving prior knowledge. However, the overall approach is not entirely novel, as similar concepts have been extensively explored, particularly in meta-learning-based class-incremental learning and dynamic expansion incremental learning approaches, which also train a generalized model and then adapt it to task-specific scenarios. The authors should discuss differences from these approaches in depth, such as those in \"An Incremental Task-Agnostic Meta-learning Approach\" and \"Tkil: Tangent Kernel Optimization for Class-Balanced Incremental Learning.\"",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "Human Review 1",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_a_type": "ai",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 1,
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          1
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": true
          },
          "1": {
            "0": true,
            "1": true
          }
        },
        "agreement_scores": {
          "0": 1.0,
          "1": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 34
  },
  {
    "id": 52,
    "paper_id": "29sul3tAEa",
    "reference_text": "The paper addresses the problem of catastrophic forgetting in continual learning and introduces a pre-trained model-based continual learning framework, HyperAdapter, which utilizes a hypernetwork to generate adapters based on the current input, adapting the pre-trained model to the corresponding task. A key to the method is that HyperAdapter uses representative features from pre-trained models, eliminating the necessity to know the task identities during inference or the dependence on any rehearsal buffers. There is currently a lot of interest in avoiding catastrophic forgetting in the continual learning setting, and the authors have summarised and categorised the main approaches. However, the paper discusses the main approaches at a high level and fails to clearly describe the key novelty of the proposed approach. Additionally, the comparison of the proposed method with how people learn is repeated in a number of places, but the points around this are well known and widely documented. Removing the replication provides space to describe the novelty in more detail and room to discuss the implications of the results.",
    "candidate_a_text": "This paper introduces HyperAdapter, which leverages hypernetworks to generate task-specific adapters for pre-trained models, addressing data privacy concerns and enabling effective knowledge transfer while requiring fewer additional parameters as the number of tasks increases. However, the core idea of using hypernetworks to generate model parameters for continual learning has already been extensively explored in the literature [1-6], and this paper merely applies these existing methods in the context of prompting-based continual learning with pre-trained models, which significantly limits its novelty and contribution. Several of the innovative designs introduced, such as block-wise hyper-adapters, bear strong similarities in motivation and methodology to chunk embeddings and network partitioning discussed in [1], further constraining the novelty of the work. Additionally, one of the claimed main advantages—eliminating the necessity of knowing the task identities during inference—was previously addressed in [1] under the concept of unknown task identity inference, and the query-key matching mechanism used to address this issue is a well-established practice [7-9].",
    "candidate_b_text": "The paper proposes HyperAdapter, a novel pre-trained model-based continual learning framework that uses a hypernetwork to generate adapters based on input, adapting a pre-trained model to specific tasks without a rehearsal buffer. The idea of using hypernetworks to generate adapters for continual learning is interesting. HyperAdapter outperforms existing methods and even exceeds multi-task learning upper bounds, setting a new state-of-the-art for pre-trained model-based continual learning.",
    "candidate_a_label": "Human Review 3",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": 3,
      "candidate_a_type": "human",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 0.5,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          3,
          4
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "3": true,
            "4": false
          },
          "3": {
            "1": true,
            "3": true,
            "4": false
          },
          "4": {
            "1": false,
            "3": false,
            "4": true
          }
        },
        "agreement_scores": {
          "1": 0.5,
          "3": 0.5,
          "4": 0.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 35
  },
  {
    "id": 29,
    "paper_id": "u2QdCiOgwA",
    "reference_text": "This paper proposes a method to prune (specifically structured pruning) Whisper-like speech foundation models, with a novel modification to the Context-Aware Gate Predictor: to handle multiple languages and tasks simultaneously, the authors created vectors representing the language and task, combined them with the speech features, and used them as input to the Gate Predictors. The analysis provided on sparse encoders and decoders is novel, and the extension to multilinguality and multi-task is new and promising. However, most methods applied are borrowed from Peng et al. (2023b), who also propose module-wise structured pruning, and this paper just applies it to multilingual and multi-task scenarios and explores how a large-scale speech foundation model adapts its structure based on context. I do not find anything much novel about the paper; specifically, an extension of an existing method to multilingual and multi-task scenarios is not very interesting to me, and I would appreciate if the authors can point out what is novel in their \"novel context-aware pruning technique\" (except the gating technique), which is difficult for me to understand.",
    "candidate_a_text": "The paper presents a novel dynamic pruning technique for speech foundation models that adapts to contextual factors like speaker characteristics, languages, and tasks during inference. This approach offers a practical solution to reduce inference time without compromising accuracy, which is a valuable contribution. While the study highlights the effectiveness of dynamic pruning and provides insights into the interpretability of pruned network structures, the current version does not fully explore existing research on dynamic pruning in speech foundation models, and it lacks a thorough comparison with other dynamic pruning techniques. Including such comparisons would strengthen the argument for the proposed method and provide a clearer picture of its advantages and limitations.",
    "candidate_b_text": "This work proposes a dynamic pruning method with learned masking that adapts based on language and task contexts, introducing a context-aware pruning mechanism that uses language tags to inform mask generation. The approach is novel, particularly in its dynamic adaptation and the innovative use of language tags, which has strong potential for real-world impact. However, network pruning using learned masks is not particularly novel and has been studied in various domains, including self-supervised models for language and speech. Expanding on these methods in the related work section and clarifying the novelty of this specific approach would strengthen the paper’s positioning. The method’s main contribution lies in its context-aware, adaptive pruning strategy, which offers an efficient and adaptable solution for deploying large speech models in resource-limited environments and could inspire further research into resource-saving models in NLP, computer vision, and other domains.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "Human Review 2",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "openreviewer",
      "candidate_a_type": "ai",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 2,
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 0.5,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          2,
          3
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "2": false,
            "3": true
          },
          "2": {
            "1": false,
            "2": true,
            "3": false
          },
          "3": {
            "1": true,
            "2": false,
            "3": true
          }
        },
        "agreement_scores": {
          "1": 0.5,
          "2": 0.0,
          "3": 0.5
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 36
  },
  {
    "id": 71,
    "paper_id": "N2sN3LESoW",
    "reference_text": "This paper identifies that the binary format of RLHF data labels fails to reflect the actual pairwise difference of human preference and proposes to weight the pairwise samples with respect to the semantic gap in order to provide supervision signals beyond binary labels. The proposed method is simple and has a clear connection to related works. The data-dependent margin and beyond-binary motivation is a good direction for preference optimization, however what the paper presents doesn't fully exploit the potential, as there can be a much wider spectrum of margins that more faithfully match the motivation, such as length difference or response-level LM embedding distance. A more comprehensive study over these options may bring in further contribution in this direction and potentially address the non-improvement for Arena-Hard and MT-Bench.",
    "candidate_a_text": "This paper introduces Gap-Aware Preference Optimization (GaPO), which I find to be a novel and well-motivated approach to preference optimization. The authors correctly identify a key limitation of traditional RLHF methods—their reliance on binary labels that fail to capture nuanced differences in human preferences—and address this by incorporating the degree of semantic gaps into the loss function. GaPO provides a more granular supervisory signal, allowing the model to better understand and reflect the subtleties of human perception, which is a significant contribution that addresses a critical challenge in the field. The method is differentiated from prior work by explicitly quantifying the semantic gap using metrics such as Jaccard Score, ROUGE, and BERTScore, and using this as a basis for loss margin adjustment rather than binary labels. My assessment is that the introduction of GaPO represents a strong and original contribution, particularly in its empirical demonstration of surpassing existing state-of-the-art methods on widely used benchmarks such as AlpacaEval 2.0, with GaPO-ROUGE_L achieving a notable win rate. The paper’s thorough exploration of different forms of the loss function and mapping functions, as well as its analysis of various evaluation metrics, further supports the distinctiveness and robustness of the proposed approach. Overall, the combination of a novel method, its strong empirical results against leading baselines, and its focus on addressing a key shortcoming in preference optimization underscores the significance of the contribution.",
    "candidate_b_text": "This paper proposes a novel approach in RLHF by introducing a gap-aware margin into the preference optimization process, moving beyond binary preference labels by leveraging estimated semantic gaps between responses. The proposed GaPO model is a novel approach that provides an alternative to binary preference optimization by enhancing the model’s ability to accurately capture and reflect the subtleties of human preference intensity. The GaPO model outperformed existing approaches like SimPO and DPO on multiple benchmarks, particularly AlpacaEval 2.0, showing real-world efficacy. The paper also explores different gap forms in GaPO by experimenting with different EF function forms and normalization techniques.",
    "candidate_a_label": "AI System: deepreviewer",
    "candidate_b_label": "Human Review 3",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "deepreviewer",
      "candidate_a_type": "ai",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 3,
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 0.6666666666666666,
        "num_reviews": 4,
        "consensus_type": "majority",
        "other_reviews": [
          0,
          2,
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": true,
            "2": false,
            "3": false
          },
          "1": {
            "0": true,
            "1": true,
            "2": true,
            "3": false
          },
          "2": {
            "0": false,
            "1": true,
            "2": true,
            "3": false
          },
          "3": {
            "0": false,
            "1": false,
            "2": false,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 0.3333333333333333,
          "1": 0.6666666666666666,
          "2": 0.3333333333333333,
          "3": 0.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 37
  },
  {
    "id": 30,
    "paper_id": "YCdag94iZs",
    "reference_text": "This paper introduces a technique called MILCA, designed to perform counting and summing of features, where feature weights are predicted using a fully connected network (FCN) with a projection replacing the softmax layer to produce coefficients within a specified range. In my view, this paper lacks sufficient novelty. The counting-based approach appears to be a straightforward extension within the MIL space, and it does not introduce any new theoretical contributions either.",
    "candidate_a_text": "This paper introduces a novel approach to Multiple Instance Learning (MIL) by incorporating counting and attention mechanisms, where instead of relying on a single aggregated bag embedding for classification, the method identifies representative features across the dataset and encodes each bag as a count of these features, with informative features identified using statistical methods like the Mann Whitney test. While the concepts and issues presented in the paper have been previously discussed, the methods introduced offer a fresh perspective, and the method proposes a seemingly novel approach for encoding bags as a count of dataset-wide features. However, there is limited technical novelty, as the idea of counting in MIL is not novel and was already explored in other works, and the model reuses a lot of existing modules such as the Mann-Whitney test, thus novelty is also limited. The proposed approach seems to have better performance than the baseline on the disease classification using T cells repertoires benchmark, and the paper introduces a new dataset, named Wiki dataset, as an additional contribution. The Table 1 should compare with recent or state-of-the-art methods, otherwise the second novelty claim is not valid.",
    "candidate_b_text": "MILCA is a simple, efficient Multiple Instance Learning (MIL) method that extends counting/summing approaches by introducing learned feature weights and a projection step, aiming to improve interpretability and efficiency over attention-based models. The submission positions itself as an alternative to attention-based and graph-based MIL, but the technical novelty is incremental, mainly involving a different normalization (projection vs. softmax) and learned weighting, both of which have been explored in related motif-based and aggregation methods. Empirical results show modest accuracy improvements (about 3%) and efficiency gains, particularly in high-dimensional, low-sample regimes, though these may be context-dependent and not unique to MILCA. The authors somewhat overstate the conceptual distinction between \"counting\" and \"attention,\" as both are forms of weighted aggregation, and the practical impact of their technical variations may be limited. Overall, MILCA offers a practical, interpretable, and efficient extension of existing counting-based MIL methods, with its main contribution being empirical performance rather than a fundamentally new paradigm.",
    "candidate_a_label": "Human Review 2",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": 2,
      "candidate_a_type": "human",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 1.0,
        "num_reviews": 4,
        "consensus_type": "majority",
        "other_reviews": [
          0,
          2,
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": true,
            "2": false,
            "3": true
          },
          "1": {
            "0": true,
            "1": true,
            "2": true,
            "3": true
          },
          "2": {
            "0": false,
            "1": true,
            "2": true,
            "3": false
          },
          "3": {
            "0": true,
            "1": true,
            "2": false,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 0.6666666666666666,
          "1": 1.0,
          "2": 0.3333333333333333,
          "3": 0.6666666666666666
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 38
  },
  {
    "id": 44,
    "paper_id": "JytL2MrlLT",
    "reference_text": "This paper explores the potential of modernizing the classical Nearest Neighbor approach for tabular data by leveraging a differentiable K-nearest neighbors variant, Neighborhood Components Analysis (NCA), and introduces MODERNNCA, an improved version of NCA that integrates deep learning techniques such as stochastic gradient descent (SGD), nonlinear embeddings, and a Stochastic Neighborhood Sampling (SNS) strategy to boost computational efficiency and model performance. Revisiting a classic nearest-neighbor approach with contemporary deep learning techniques is a novel approach, particularly since NCA had been previously limited by computational efficiency and scalability, and this approach aims to unify insights from both traditional and modern tabular prediction methods. However, the paper’s contribution feels incremental rather than pioneering, as the improvements in MODERNNCA rely on established techniques (SGD, SNS, and nonlinear embeddings) without introducing a fundamentally new concept or method, making the novelty limited and essentially optimizing an existing algorithm rather than providing a unique advancement. The paper also lacks direct comparisons with other KNN-inspired deep learning methods that have similarly benefited from modern optimization strategies, which weakens the argument for MODERNNCA’s distinctiveness and impact.",
    "candidate_a_text": "This paper revisits the Neighborhood Components Analysis (NCA) and adapts it for tabular data learning, proposing ModernNCA as an enhanced approach. While the approach effectively leverages modern deep learning techniques to enhance classical NCA and demonstrates strong empirical results, the core modifications—using a representation space for distance calculations, employing SGD, and mini-batch training—have already been explored in prior research. This raises concerns regarding the originality of the contribution, as the changes appear more like tunings of established techniques rather than introducing a fundamentally new method.",
    "candidate_b_text": "This paper revisits the classic KNN method and explores ways to improve it using modern deep learning techniques. The proposed MODERNNCA is a deep learning version of KNN, which achieves good performance in both classification and regression tasks, essentially serving as a strong deep baseline for tabular tasks. However, the idea of using a deep learning version of KNN for tabular data is not novel, as it has been explored in previous works like TabR.",
    "candidate_a_label": "Human Review 2",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": 2,
      "candidate_a_type": "human",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 1.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          2,
          4
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "2": true,
            "4": true
          },
          "2": {
            "1": true,
            "2": true,
            "4": true
          },
          "4": {
            "1": true,
            "2": true,
            "4": true
          }
        },
        "agreement_scores": {
          "1": 1.0,
          "2": 1.0,
          "4": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 39
  },
  {
    "id": 67,
    "paper_id": "dTGH9vUVdf",
    "reference_text": "The paper introduces FreeVS, an approach to view synthesis for driving scenes that overcomes limitations of existing methods, which primarily focus on synthesizing camera views along pre-recorded vehicle trajectories. The authors proposed a \"psuedo LiDAR controlnet\" for SVD, which is easy yet effective. The benchmark of novel trajectory synthesis looks interesting to me, and the authors proposed two benchmarks for evaluating novel camera synthesis and novel trajectory synthesis. While the baseline methods are not specifically designed for the similar purpose of the paper, there are works that use virtual warping for improving the novel view quality such as [1] [2], that might be better for the baselines. This reminds me of the existing novel trajectory synthesis benchmark [3], and the authors should test their methods on such a dataset and demonstrate the absolute performance gain using the metrics of PSNR, SSIM, etc. I personally like the idea of the paper, but I still have many concerns and would provide a final rating based on the authors' responses.",
    "candidate_a_text": "This paper introduces a novel method for synthesizing camera views on free driving trajectories in real driving scenes. The proposed method is a fully generative approach that can synthesize camera views on novel trajectories without the need for reconstruction, which is a novel and practical contribution to the field. The paper also introduces two new benchmarks for evaluating driving scene novel view synthesis: novel camera synthesis and novel trajectory synthesis, which are more challenging and practical than the traditional evaluation on recorded trajectories.",
    "candidate_b_text": "This paper approaches the task of novel view synthesis of outside-trajectory viewpoints on driving videos by training a conditional video diffusion model on outside-trajectory views created through projection of existing 3D point clouds. Creative use of 3D and off-the-shelf models enables a non-conventional setup, as novel view synthesis is so often limited to input trajectories, making the task fairly straightforward and limited due to constraints on using positions connected to the car. Instead, this work approaches prediction several meters away from car trajectories by utilizing colored LiDAR across multiple views to create point clouds that can be projected into pseudo-images, which is a nontrivial trick to implement effectively. This work shows it can be useful for training a generative model, and I feel the paper should be accepted as it offers good contributions in 3D and video generation to yield an effective method.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "Human Review 3",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "openreviewer",
      "candidate_a_type": "ai",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 3,
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 0.0,
        "num_reviews": 3,
        "consensus_type": "majority",
        "other_reviews": [
          3,
          4
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "3": false,
            "4": false
          },
          "3": {
            "1": false,
            "3": true,
            "4": false
          },
          "4": {
            "1": false,
            "3": false,
            "4": true
          }
        },
        "agreement_scores": {
          "1": 0.0,
          "3": 0.0,
          "4": 0.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 40
  },
  {
    "id": 39,
    "paper_id": "skJLOae8ew",
    "reference_text": "This paper proposes a new pipeline for generating architectural floor plans by applying diffusion models, fine-tuning them to learn implicit design concepts in architectural design, and generating detailed and functional floor plans. However, the technical innovation in this paper is quite insufficient, and the introduction to the U-Net architecture is entirely superfluous. For ICLR, this paper clearly lacks innovation and systematic methodology, and it does not quite meet the threshold for current AI conferences.",
    "candidate_a_text": "This assessment finds that the submission adapts diffusion models—specifically a customized U-Net architecture with integrated upscaling—for efficient, high-resolution architectural floor plan generation, situating it within a well-established trend of domain adaptation and engineering optimization in generative modeling. While the authors claim to be the first to apply diffusion models to this domain and to uniquely capture architectural semantics, these claims are not fully substantiated, as prior works such as HouseDiffusion and Tell2Design have already explored similar territory. The main technical contributions appear to be in the specific engineering choices and integration of upscaling for floor plans, representing an incremental rather than a fundamental advance. The submission omits direct comparison with the most relevant prior work and tends to overstate its novelty, particularly regarding \"firstness\" and semantic capability. Reviewers are advised to focus on the empirical results and robustness of the engineering, but to calibrate expectations regarding conceptual innovation and to request more thorough citation and comparison with existing literature.",
    "candidate_b_text": "This paper introduces a new diffusion model designed for generating architectural floor plans, adapting the U-Net architecture and employing upscaling techniques to enhance efficiency and detail. The application of diffusion models to architectural design is a relatively new and promising field. However, the proposed method lacks novelty, as it primarily adapts an existing diffusion model (U-Net) for floor plan generation without introducing significant innovations. The paper does not cite several important works in the field, such as DreamPlan, HouseDiffuser, and HouseGan++, which further highlights the absence of originality and differentiation from prior work.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "ours",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "3": true
          },
          "3": {
            "0": true,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 41
  },
  {
    "id": 3,
    "paper_id": "CXIiV1iU3G",
    "reference_text": "This paper presents a new approach for parameter generation combining autoregression and diffusion, using SSMs (Mamba) to easily and effectively perform large-scale parameter generation, and introduces a method for parameter tokenization that performs significantly better than tokenization methods used by previous works. However, the approach is very limited in novelty; autoregressive models feeding embeddings into a diffusion model is not new in general.",
    "candidate_a_text": "This assessment finds that the submission presents a meaningful but incremental advance in diffusion-based neural network parameter generation, primarily through the explicit use of a recurrent model to capture correlations among parameter \"tokens\" and a practical demonstration of scaling to very large models (e.g., LLaMA-7B LoRA) on a single GPU. While the authors claim to be the first to achieve such scaling and correlation modeling, prior works like SANE and D2NWG have addressed similar challenges with different technical approaches, and the novelty is more in implementation than in conceptual leap. The submission’s main technical distinction is the recurrent modeling of parameter dependencies, which is a substantive improvement over p-diff and D2NWG, but only incrementally different from SANE’s sequential autoencoder. Claims regarding improved generalization and token-based modeling are less differentiated, as conditional generation and sequential partitioning have been explored in recent literature. Overall, reviewers should recognize the practical value and technical refinement of the work, but also calibrate novelty claims against the field’s rapid, incremental progress and the sophistication of closely related prior art.",
    "candidate_b_text": "This paper proposes a novel method for generating large-scale neural network parameters using a combination of parameter tokenization, a recurrent model, and a diffusion model. The authors compare their approach with several existing methods and demonstrate its superior performance.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 2,
      "candidate_a_system": "ours",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 2,
        "consensus_score": 0.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "2": {
            "2": true,
            "3": false
          },
          "3": {
            "2": false,
            "3": true
          }
        },
        "agreement_scores": {
          "2": 0.0,
          "3": 0.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 42
  },
  {
    "id": 91,
    "paper_id": "RiQRUcjXBD",
    "reference_text": "This paper introduces a system called SciPIP, designed to help researchers come up with new ideas more effectively by retrieving relevant studies from a research database and leveraging a model to brainstorm entirely new ideas, aiming to balance novelty and feasibility. While SciPIP generates promising, innovative concepts and combines literature retrieval with brainstorming, I have concerns about the true originality of the generated ideas. Large language models may rely on knowledge from their training data, potentially producing ideas that are essentially variations of existing research rather than truly novel contributions. The current evaluation mainly relies on comparing generated ideas to existing papers using similarity scores, but this approach has limitations in assessing true novelty and academic value, as high similarity scores might indicate copying or minor tweaks, and low scores do not necessarily signal a breakthrough. Since similarity scores are based on semantic overlap, they do not capture the underlying logic, originality, or technical feasibility, making it difficult to measure the actual contribution or innovation of the ideas. The reliability of using large language models to evaluate originality is questionable, and supplementing the evaluation with expert reviews or alternative methods could better ensure that SciPIP’s outputs demonstrate true innovation and relevance to the research community.",
    "candidate_a_text": "This paper explores an emerging and interesting application of LLM in proposing scientific ideas and creates a new annotated database of 50k recent AI/ML papers, annotated with entities and embeddings for ideas, backgrounds, summary etc. To my knowledge, no comprehensive scientific literature database exists where each paper's ideas are extracted and annotated, and this specific ensemble literature retrieval strategy using entity retrieval, semantic retrieval, co-citation retrieval and clustering is new, to the best of my knowledge. However, the entire retrieval strategy is an ensemble of previously utilized techniques, such as entity matching, semantic embedding search, co-citation (this is implemented in many existing databases such as PubMed), and clustering, and the idea proposal pipeline is only an implementation but with limited originality. In my opinion the most original aspect of this paper is its introduction of the annotated database where each paper has its ideas extracted and processed, though the paper does not talk about quantitative quality control of the database creation process. I am fairly certain this system outperforms vanilla approach to ask LLM to generate new research ideas, at least in the field of NLP, but the lack of sufficiently innovative approaches and the limited scale and comprehensiveness of the work make me doubtful of its contribution to the research community.",
    "candidate_b_text": "This paper introduces SciPIP, a framework that leverages large language models to generate scientific paper ideas by integrating literature retrieval and brainstorming. The dual-path idea proposal method is an interesting approach that combines inspiration from existing literature with pure LLM-based brainstorming, aiming to balance novelty and feasibility, which are critical in scientific idea generation. However, the paper does not provide a detailed comparison of SciPIP with existing tools or methodologies, making it difficult to assess its unique contributions and advantages. Additionally, the idea proposal section needs a clearer description of how novelty and feasibility are quantified and assessed, and the paper does not provide enough detail on the specific metrics or criteria used for evaluating the novelty of generated ideas.",
    "candidate_a_label": "Human Review 3",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": 3,
      "candidate_a_type": "human",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 0,
        "consensus_score": 1.0,
        "num_reviews": 4,
        "consensus_type": "majority",
        "other_reviews": [
          1,
          2,
          3
        ],
        "agreement_matrix": {
          "0": {
            "0": true,
            "1": true,
            "2": true,
            "3": true
          },
          "1": {
            "0": true,
            "1": true,
            "2": true,
            "3": true
          },
          "2": {
            "0": true,
            "1": true,
            "2": true,
            "3": true
          },
          "3": {
            "0": true,
            "1": true,
            "2": true,
            "3": true
          }
        },
        "agreement_scores": {
          "0": 1.0,
          "1": 1.0,
          "2": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 43
  },
  {
    "id": 12,
    "paper_id": "2ofVtMvRil",
    "reference_text": "This study demonstrates that predictive coding can effectively train neural networks to develop hexagonal grid representations from spatial inputs, providing a biologically plausible explanation for the emergence of grid cells in the medial entorhinal cortex. However, my major concern is that the work may lack novelty. The use of non-negative and sparse network designs to produce grid cell-like patterns has been extensively discussed, with prior work reporting that non-negative and sparse properties can generate grid cell-like patterns and theoretically demonstrating why non-negativity is the main driver of grid cell formation, which the author's paper does not address, instead of sparsity. Similar findings have also been reported elsewhere, and earlier work proves that a nonnegativity constraint on firing rates induces a symmetry-breaking mechanism favoring hexagonal firing fields, with further studies exploring the necessary conditions for generating grid cells. Prediction tasks, including path integration, that produce grid cell-like patterns have also been widely reported, especially when the input data takes a place cell-like form, and other studies have used place cell-like input and path integration tasks to train networks and generate grid cells, while some have theoretically analyzed the role of predictive learning in forming low-dimensional representations. In my understanding, tPCN is very similar to a one-step RNN (apart from the difference in local learning rules), so the fact that its training process resembles that of one-step tBPTT is not surprising; as previously noted, the key to forming grid cells lies in the predictive task, not the RNN network itself, and therefore, the similarity between tPCN and RNN does not offer significant insight into the generation of grid cells. For these reasons, I believe this paper does not offer substantial novelty or make a clear contribution to the field.",
    "candidate_a_text": "This paper makes a novel connection between predictive coding networks and grid cells by showing that predictive coding networks can extract grid cell representations from place cell inputs and that temporal predictive coding networks can learn to integrate velocity information to learn grid cell representations. However, there are many models that can learn grid cells, including attractor network models and other predictive models, so it is not clear why predictive coding networks are particularly suited for this task, and the paper does not provide a strong motivation for this connection. While the paper briefly mentions some existing models, it does not provide a comprehensive comparison to them, and a more detailed comparison—including an analysis of the computational requirements and biological plausibility of different models—would help in evaluating the originality and significance of the contribution.",
    "candidate_b_text": "This paper introduces a novel approach to modeling grid cell formation in the medial entorhinal cortex using predictive coding networks (PCNs). I find the use of predictive coding to model grid cell emergence to be a novel and compelling approach, offering a biologically plausible alternative to models that rely on backpropagation, which is unlikely to be implemented in the brain. The paper’s main contribution lies in its novel application of predictive coding to model grid cell emergence, providing a unified learning algorithm for diverse cortical representations. The authors successfully demonstrate that grid cells can arise as latent representations learned through predictive coding in both static and dynamic environments—a significant contribution to the field—and show that the learning rule of temporal predictive coding networks (tPCNs) implicitly approximates truncated backpropagation through time (BPTT). They compare their model with recurrent neural networks trained with BPTT, showing that both models can achieve similar performance in terms of path integration and grid score, while emphasizing the biological plausibility of their approach. However, I note several weaknesses that limit the clarity of the paper’s originality: the work lacks a detailed comparison with prior models, particularly recurrent neural networks and attractor networks, making it difficult to fully appreciate the unique contributions of the proposed model. While the authors mention advantages such as not requiring biologically implausible backpropagation and addressing the need for local learning rules, they do not provide an in-depth analysis of how their model mechanistically diverges from or improves upon existing approaches. This leaves the reader with an incomplete understanding of how the PCN model advances the field beyond existing models, and undermines the assessment of its true novelty and significance. Overall, I believe the paper makes a significant contribution by presenting a novel and biologically plausible model for grid cell formation, but the originality would be better established with a more thorough and mechanism-level comparison to prior work.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: deepreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "openreviewer",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "deepreviewer",
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "3": true
          },
          "3": {
            "1": true,
            "3": true
          }
        },
        "agreement_scores": {
          "1": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 44
  },
  {
    "id": 65,
    "paper_id": "6XUSDvBFkV",
    "reference_text": "This paper proposes a structured binary quantization method to accelerate LLM inference by combining n:m pruning and binary quantization, compressing model weights to an average of less than 1 bit. While the proposed method is interesting and performs better than BiLLM, its novelty is limited: the proposed SI method is very similar to Wanda, with the main difference being the introduction of additional data normalization, and the binary quantization method is quite similar to BiLLM, where the hessian matrix is used to divide weights into salient and non-salient parts, and residual approximation is employed to handle the salient part. The only difference is that STBLLM processes the non-salient weights into three parts instead of two as in BiLLM. Overall, the contribution is incremental.",
    "candidate_a_text": "This assessment finds that the submission, STBLLM, extends the line of 1-bit LLM quantization by introducing structured (N:M) binarization, a new Standardized Importance (SI) metric for weight selection, and a specialized CUDA kernel for hardware acceleration, making it the first to achieve sub-1-bit/weight compression with structured sparsity in LLMs. While the combination of structured binarization and hardware optimization is a notable advance for practical deployment, many of the methodological components—such as adaptive grouping, layerwise adaptation, and importance-based selection—are incremental extensions of established techniques from quantization and pruning literature. The SI metric is presented as a key innovation, but its empirical superiority over Hessian- or activation-based metrics is not fully substantiated, and the novelty of adaptive grouping is somewhat overstated. The authors' characterization of prior work is generally accurate but occasionally downplays the sophistication and effectiveness of existing methods, particularly regarding importance metrics and structured pruning. Overall, the main contribution is the integration of structured binarization and hardware-aware engineering for sub-1-bit LLMs, with the strongest differentiation in practical speedup and memory savings, while the conceptual advances in importance metrics and adaptation are more incremental.",
    "candidate_b_text": "This paper introduces a method to compress LLMs to less than 1-bit precision, which is a very challenging task. The proposed method, STBLLM, is built upon BiLLM, which may limit its novelty. The authors first identify the redundancy in binarized LLMs through the flipping experiment, and then propose a structural binarization method to further compress the model, employing an N:M sparsity technique and a Standardized Importance (SI) metric. While the proposed approach is well-motivated and achieves great performance, it is not a pure quantization method, as it uses pruning to reduce the number of model parameters, and therefore, I think it is not very fair to only compare it with quantization methods.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "AI System: openreviewer",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 2,
      "candidate_a_system": "ours",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "openreviewer",
      "consensus_info": {
        "consensus_review": 2,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "2": {
            "2": true,
            "3": true
          },
          "3": {
            "2": true,
            "3": true
          }
        },
        "agreement_scores": {
          "2": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 45
  },
  {
    "id": 48,
    "paper_id": "c4w1TqcSi0",
    "reference_text": "This paper introduces a framework based on an iterative generate, rank, select, and train paradigm to address inter-agent communication and task inference challenges within LLM-based MAS, building iSFT and iDPO on this iteration paradigm. However, the methods iSFT and iDPO seem to lack innovation. iDPO merely combines MCTS from ToT with DPO, while iSFT simply adds a step of supervised fine-tuning (SFT) after removing the prompt. These methods seem incremental rather than novel, and similar approaches can already be found, such as [1], [2], [3], [4], [5].",
    "candidate_a_text": "**Summary for Reviewer:**\n\nOPTIMA is a multi-agent LLM framework that formally integrates multi-objective reward optimization—balancing task performance, token efficiency, and communication readability—using an iterative generate-rank-select-train paradigm and MCTS-inspired DPO data generation. While the approach is well-positioned at the intersection of multi-agent debate, process-level optimization, preference modeling, and communication efficiency, most of its components and their combinations have been explored in prior work, making the main technical delta the formal unification and application context rather than fundamentally new algorithms. The authors’ claims of novelty, particularly regarding unified optimization and MCTS-inspired DPO in MAS, are somewhat overstated, as similar ideas have appeared in related literature, though OPTIMA’s explicit reward formalism and MAS adaptation are more formalized. The empirical improvements reported are substantial, but may be partly attributable to implementation choices and task selection, and the work would benefit from more direct comparisons to closely related methods (e.g., SimPO, ReST-MCTS*). Overall, OPTIMA is a strong, contemporary integration of recent trends in the field, but its contributions are primarily incremental and formal rather than radically innovative.",
    "candidate_b_text": "This work proposes a framework that improves the effectiveness and efficiency of LLMs in multi-agent dialogue systems by iteratively optimizing data and training LLMs using SFT/DPO, where iSFT uses sampling to generate better data and iDPO uses MCTS to generate paired data, along with a carefully designed reward function to ensure overall system effectiveness and efficiency. While this paper offers a well-structured approach to enhancing the effectiveness and efficiency of MAS, iSFT and iDPO have been extensively explored in prior works. Thus, the main contributions here—reward function design and data improvement mechanism in MAS—offer limited novelty within the existing research landscape. The data generation mechanism for MAS is interesting and may facilitate further improvements in MAS, including frameworks like AutoGen, but the methods are relatively general and do not address the key issues in MAS.",
    "candidate_a_label": "AI System: ours",
    "candidate_b_label": "Human Review 2",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 1,
      "candidate_a_system": "ours",
      "candidate_a_type": "ai",
      "candidate_b_type": "human",
      "candidate_b_system_or_id": 2,
      "consensus_info": {
        "consensus_review": 1,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          2
        ],
        "agreement_matrix": {
          "1": {
            "1": true,
            "2": true
          },
          "2": {
            "1": true,
            "2": true
          }
        },
        "agreement_scores": {
          "1": 1.0,
          "2": 1.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 46
  },
  {
    "id": 54,
    "paper_id": "ueeqGvQozB",
    "reference_text": "This paper introduces ML4MILP, an original benchmark collection targeted to the MILP domain, aiming to fill the gap of having a large scale, standardized benchmark for evaluating mixed integer linear program solvers. The benchmark is relevant for the ML and DL community, especially as ML-based approaches are becoming popular in this field. The introduction and related work provide a well-written, self-contained overview of existing solvers, techniques, and related benchmarks, highlighting the general lack of a larger standardized benchmark for MILPs. Based on structural and embedding distance between instances, the authors show that existing benchmarks are often more heterogeneous than the MILP benchmark they propose, which allows for some insight into the structure of the proposed and existing benchmarks. However, the overall contribution—introduction of the benchmark and showing the lack of homogeneity of existing classes of instances based on similarity evaluation metrics with respect to structure and neural embedding distances—is somewhat limited in scientific insight and currently results in me having a hard time voting for acceptance at a main ML and DL conference such as ICLR; maybe submitting the paper to a Benchmark and Dataset track of a suitable conference might be more targeted.",
    "candidate_a_text": "This paper proposes a benchmark for evaluating machine learning-based mixed-integer linear programming solvers, consisting of a dataset of 100,000 MILP instances classified into 70 classes, and provides a baseline of different algorithms on the dataset. While the dataset is significantly larger than previous ones, I find that the proposed dataset is not significantly different from the existing ones, and the authors do not provide a clear motivation for why the existing benchmarks are not sufficient. The authors claim that existing benchmarks are not homogeneous, but they do not provide a clear definition of homogeneity in the context of MILP instances, nor sufficient evidence that the proposed dataset is indeed more homogeneous than the existing ones. The argument that the similarity between instances in the same class is higher than in existing benchmarks is not convincing without a clear explanation of how similarity is measured and why it matters. Although the proposed dataset’s larger size is emphasized, the authors do not provide a clear justification for why a larger dataset is necessarily better. Overall, the novelty and significance of the contribution are unclear due to a lack of rigorous comparisons to prior benchmarks, definitions of claimed improvements, and justifications for the benefits claimed.",
    "candidate_b_text": "This submission introduces ML4MILP, a large-scale, open-source MILP benchmark featuring over 100,000 instances and a novel, embedding-based instance classification scheme that combines graph statistics and GNN-derived embeddings. Its main methodological advance is the use of GNN-based embeddings for fine-grained instance categorization, which, while new for MILP datasets, is an incremental extension of existing clustering and representation learning techniques. The dataset’s scale and the embedding-based classification provide more nuanced groupings than prior benchmarks (e.g., Distributional MIPLIB, ML4CO), though the underlying problem diversity remains similar. Some claims of “first” or uniquely fine-grained classification are somewhat overstated, as prior datasets do offer domain and hardness labels, and the provision of high-quality solutions and benchmarking protocols largely follow established practice. Overall, the submission’s primary contribution is infrastructural—advancing benchmark scale and classification methodology—rather than introducing fundamentally new algorithmic concepts.",
    "candidate_a_label": "AI System: deepreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 2,
      "candidate_a_system": "deepreviewer",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {
        "consensus_review": 2,
        "consensus_score": 1.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          3
        ],
        "agreement_matrix": {
          "2": {
            "2": true,
            "3": true
          },
          "3": {
            "2": true,
            "3": true
          }
        },
        "agreement_scores": {
          "2": 1.0,
          "3": 1.0
        }
      }
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 47
  },
  {
    "id": 72,
    "paper_id": "m8Rk3HLGFx",
    "reference_text": "This paper presents a multi-view video generation approach based on an input textual prompt or monocular video, incorporating a multi-view synchronization module into a pre-trained text-to-video model to maintain appearance and geometry consistency across multiple viewpoints. The multi-view video generation is a novel task, and this paper shows some promising results in this direction, where the temporal consistency within each single view and spatial consistency across different views are maintained reasonably well. The proposed way of using multi-view images, synthetic multi-view videos, and real-world monocular videos to train the model is novel, providing an alternative approach to solve the data scarcity issue when high-quality real-world multi-view videos are hard to obtain.",
    "candidate_a_text": "This paper presents SynCamMaster, a novel approach for generating synchronized multi-camera videos from diverse viewpoints, addressing a significant gap in the field of video generation. I find several aspects of this paper to be particularly strong, with the most significant being the introduction of SynCamMaster as the first method to address the multi-camera video generation problem—a novel contribution that fills a gap in the literature, as previous works have primarily focused on single-camera video generation or multi-view image generation for static scenes. The proposed multi-view synchronization module (MVS) is another strength, as it effectively integrates camera information into the generation process, and the use of a hybrid training scheme allows the model to learn from a variety of data sources, addressing the challenge of limited multi-camera training data. The empirical results are compelling, demonstrating that SynCamMaster significantly outperforms existing methods in terms of view synchronization and visual quality, and the extension of the method to novel view synthesis highlights its versatility. The release of a multi-view synchronized video dataset is also a valuable contribution. Overall, the paper is well-motivated and makes a substantial contribution by addressing the limitations of previous methods and introducing a novel approach to multi-view video generation.",
    "candidate_b_text": "SynCamMaster is an incremental advance in the rapidly evolving field of multi-view, 3D-consistent, camera-controllable video generation, building directly on recent works like CVD and CamCo. Its main technical contributions are the integration of a plug-and-play camera encoder and a hybrid-data training pipeline that combines multi-view images, single-view videos, and synthetic data to address data scarcity and improve generalization. While the authors claim to be the first to achieve multi-camera real-world video generation, this is not fully substantiated, as CVD and CamCo already address similar problems with comparable technical approaches. The submission’s novelty lies primarily in practical data engineering and module integration, rather than in introducing fundamentally new methodologies or problem settings. Overall, SynCamMaster offers useful implementation improvements and broader applicability, but its conceptual advances are incremental and its claims of major novelty are overstated relative to the current state of the field.",
    "candidate_a_label": "AI System: deepreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 4,
      "candidate_a_system": "deepreviewer",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {
        "consensus_review": 4,
        "consensus_score": 0.0,
        "num_reviews": 2,
        "consensus_type": "majority",
        "other_reviews": [
          6
        ],
        "agreement_matrix": {
          "4": {
            "4": true,
            "6": false
          },
          "6": {
            "4": false,
            "6": true
          }
        },
        "agreement_scores": {
          "4": 0.0,
          "6": 0.0
        }
      }
    },
    "assignment_type": "unique",
    "evaluator_sample_id": 48
  },
  {
    "id": 32,
    "paper_id": "DSsSPr0RZJ",
    "reference_text": "This paper introduces DSBench, a comprehensive benchmark designed to evaluate data science agents on realistic tasks derived from ModelOff and Kaggle competitions. By integrating a wide range of data analysis and modeling challenges, DSBench aims to provide a rigorous and practical environment for assessing agent performance under real-world conditions. The benchmark is further distinguished by the introduction of the Relative Performance Gap (RPG) metric, which seeks to normalize evaluation across diverse modeling tasks. The contribution is notable in that it pushes the boundaries of traditional benchmarking by moving beyond synthetic or narrowly scoped tasks, instead offering a fresh and more holistic approach to evaluating data science agents. DSBench sets a new standard in the field, driving advancements in realistic, end-to-end task performance and supporting the development of intelligent, autonomous data science agents. Overall, the paper’s novelty lies in both the scale and realism of the benchmark, as well as the effort to address evaluation inconsistencies through the RPG metric, marking a significant and original step forward in data science benchmarking.",
    "candidate_a_text": "This paper introduces DSBench, a comprehensive benchmark designed to evaluate the performance of data science agents on realistic tasks sourced from ModelOff and Kaggle competitions. The benchmark consists of 466 data analysis tasks and 74 data modeling tasks, and provides a thorough evaluation of multiple state-of-the-art LLMs, LVLMs, and agents, offering a comprehensive comparison of their performance on these tasks. The benchmark tasks are sourced from real-world competitions, making the evaluation more realistic and relevant to practical applications in the field of data science.",
    "candidate_b_text": "DSBench is a new benchmark for data science agents that distinguishes itself primarily by sourcing tasks from real-world competitions (ModelOff and Kaggle), offering a large and diverse set of data analysis and modeling challenges. While the authors claim comprehensive realism and multimodality, these aspects are already addressed by recent benchmarks such as Spider2-V, OSWorld, and InfiAgent-DABench, making DSBench’s main novelty its specific task sourcing and explicit coverage of both analysis and modeling. The introduction of the Relative Performance Gap (RPG) metric for normalized evaluation across heterogeneous tasks is a useful, though incremental, methodological contribution. Some claims of uniqueness—particularly regarding multimodality, end-to-end workflows, and revealing agent-expert performance gaps—are overstated, as similar features and findings exist in prior work. Overall, DSBench is a timely and relevant addition to the field, but reviewers should recognize that its advances are incremental rather than fundamentally transformative within the current landscape of data science agent benchmarks.",
    "candidate_a_label": "AI System: openreviewer",
    "candidate_b_label": "AI System: ours",
    "metadata": {
      "reference_type": "human_consensus",
      "reference_review_id": 0,
      "candidate_a_system": "openreviewer",
      "candidate_a_type": "ai",
      "candidate_b_type": "ai",
      "candidate_b_system_or_id": "ours",
      "consensus_info": {}
    },
    "assignment_type": "overlap",
    "evaluator_sample_id": 49
  }
]